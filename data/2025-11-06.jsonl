{"id": "2511.02836", "categories": ["cs.CR", "C.2.0; E.3"], "pdf": "https://arxiv.org/pdf/2511.02836", "abs": "https://arxiv.org/abs/2511.02836", "authors": ["Hector E Mozo"], "title": "Quantum-Classical Hybrid Encryption Framework Based on Simulated BB84 and AES-256: Design and Experimental Evaluation", "comment": "12 pages, 7 figures, includes extensive experimental results and\n  proposed architecture", "summary": "This paper presents the design, implementation, and evaluation of a hybrid\nencryption framework that combines quantum key distribution, specifically a\nsimulated BB84 protocol, with AES-256 encryption. The system enables secure\nfile encryption by leveraging quantum principles for key generation and\nclassical cryptography for data protection. It introduces integrity validation\nmechanisms, including HMAC verification and optional post-quantum digital\nsignatures, ensuring robustness even in the presence of quantum-capable\nadversaries. The entire architecture is implemented in Python, with modular\ncomponents simulating quantum key exchange, encryption, and secure packaging.\nExperimental results include visual testing of various attack scenarios, such\nas key tampering, HMAC failure, and file corruption, demonstrating the\neffectiveness and resilience of the approach. The proposed solution serves as a\npractical foundation for quantum-aware cybersecurity systems."}
{"id": "2511.02841", "categories": ["cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.02841", "abs": "https://arxiv.org/abs/2511.02841", "authors": ["Sandro Rodriguez Garzon", "Awid Vaziry", "Enis Mert Kuzu", "Dennis Enrique Gehrmann", "Buse Varkan", "Alexander Gaballa", "Axel Küpper"], "title": "AI Agents with Decentralized Identifiers and Verifiable Credentials", "comment": "This work has been submitted to SCITEPRESS for possible publication", "summary": "LLM-based AI agents still lack the technical means to automatically build\nnuanced and differentiated trust in other agents at the beginning of an\nagent-to-agent dialogue. But autonomous and interoperable trust establishing\nbecomes a fundamental prerequisite once agents start to operate beyond isolated\nenvironments and engage in dialogues across individual or organizational\nboundaries. A promising way to fill this gap in Agentic AI is to equip agents\nwith long-lived digital identities and introduce tamper-proof and flexible\nidentity-bound attestations of agents, provisioned by commonly trusted third\nparties and designed for cross-domain verifiability. This article presents a\nconceptual framework and a prototypical multi-agent system, where each agent is\nendowed with a self-sovereign digital identity. It combines a unique and\nledger-anchored Decentralized Identifier (DID) of an agent with a set of\nthird-party issued Verifiable Credentials (VCs). This enables agents at the\nstart of a dialog to prove ownership of their self-controlled DIDs for\nauthentication purposes and to establish various cross-domain trust\nrelationships through the spontaneous exchange of their self-hosted DID-bound\nVCs. A comprehensive evaluation of the prototypical implementation demonstrates\ntechnical feasibility but also reveals limitations once an agent's LLM is in\nsole charge to control the respective security procedures."}
{"id": "2511.02868", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02868", "abs": "https://arxiv.org/abs/2511.02868", "authors": ["M. Z. Haider", "M. U Ghouri", "Tayyaba Noreen", "M. Salman"], "title": "Proof-of-Spiking-Neurons(PoSN): Neuromorphic Consensus for Next-Generation Blockchains", "comment": null, "summary": "Blockchain systems face persistent challenges of scalability, latency, and\nenergy inefficiency. Existing consensus protocols such as Proof-of-Work (PoW)\nand Proof-of-Stake (PoS) either consume excessive resources or risk\ncentralization. This paper proposes \\textit{Proof-of-Spiking-Neurons (PoSN)}, a\nneuromorphic consensus protocol inspired by spiking neural networks. PoSN\nencodes transactions as spike trains, elects leaders through competitive firing\ndynamics, and finalizes blocks via neural synchronization, enabling parallel\nand event-driven consensus with minimal energy overhead. A hybrid system\narchitecture is implemented on neuromorphic platforms, supported by simulation\nframeworks such as Nengo and PyNN. Experimental results show significant gains\nin energy efficiency, throughput, and convergence compared to PoB and PoR. PoSN\nestablishes a foundation for sustainable, adaptive blockchains suitable for\nIoT, edge, and large-scale distributed systems."}
{"id": "2511.02898", "categories": ["cs.CR", "cs.CY", "68M14, 91B30, 91A80", "K.6.5; K.4.1"], "pdf": "https://arxiv.org/pdf/2511.02898", "abs": "https://arxiv.org/abs/2511.02898", "authors": ["Roberto Garrone"], "title": "Designing Proportionate Cybersecurity Frameworks for European Micro-Enterprises: Lessons from the Squad 2025 Case", "comment": "Comments: 5 pages, 2 tables. The paper proposes a proportionate,\n  awareness-first cybersecurity approach for micro- and small enterprises,\n  inspired by the EU Squad 2025 initiative, highlighting how simple preventive\n  measures can align with - but not replace - formal compliance under NIS2 and\n  related regulations", "summary": "Micro and small enterprises (SMEs) account for most European businesses yet\nremain highly vulnerable to cyber threats. This paper analyses the design logic\nof a recent European policy initiative -- the Squad 2025 Playbook on\nCybersecurity Awareness for Micro-SMEs -- to extract general principles for\nproportionate, resource-aware cybersecurity governance. The author participated\nin the Squad 2025 team and originally proposed the seven-step preventive\nstructure that later shaped the Playbook's design, subsequently refined\ncollaboratively within the project. The framework was guided by the author's\ndesign premise that raising cybersecurity awareness among micro- and\nsmall-enterprise actors represents the most efficient short-term lever for\nincreasing sensitivity to cybercrime and promoting protective behaviours.\nWithout reproducing any proprietary material, the paper reconstructs the\nconceptual architecture of that approach within the broader context of ENISA\nguidance, ISO 27005, and the NIS2 Directive. It proposes a generic\nseven-dimension preventive model suitable for micro-enterprise adoption and\ndiscusses implications for policy transfer, awareness training, and maturity\nassessment."}
{"id": "2511.02924", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.02924", "abs": "https://arxiv.org/abs/2511.02924", "authors": ["Haranath Rakshit", "Rajkumar Bhandari", "Subhasis Banerjee"], "title": "Lightweight Session-Key Rekeying Framework for Secure IoT-Edge Communication", "comment": "24 pages, 8 figures, includes graphical abstract and highlights.\n  Experimental validation on ESP32 and Raspberry Pi 5", "summary": "The proliferation of Internet of Things (IoT) networks demands security\nmechanisms that protect constrained devices without the computational cost of\npublic-key cryptography. Conventional Pre-Shared Key (PSK) encryption, while\nefficient, remains vulnerable due to static key reuse, replay attacks, and the\nlack of forward secrecy. This paper presents the Dynamic Session Enhanced Key\nProtocol (DSEKP) - a lightweight session-key rekeying framework, a fully\nsymmetric extension to PSK that derives per-session AES-GCM keys using the\nHMAC-based Key Derivation Function (HKDF-SHA256) and authenticates session\nestablishment through an HMAC proof in a single init-ack exchange. DSEKP was\nimplemented on an ESP32 IoT sensor node and a Raspberry Pi 5 edge server\ncommunicating through a Mosquitto MQTT broker, and benchmarked against a static\nPSK baseline over more than 6,500 encrypted packets per configuration. The\nresults demonstrate nearly identical throughput and reliability, with moderate\noverhead - mean latency increased by 27% and payload size by 10% - while\ndelivering per-session forward secrecy and built-in replay protection. These\nfindings confirm that dynamic symmetric rekeying can substantially strengthen\nIoT-Edge links with minimal computational and bandwidth cost, offering a\npractical migration path from static PSK to session-aware, scalable, and\nreproducible IoT security."}
{"id": "2511.02993", "categories": ["cs.CR", "cs.HC", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02993", "abs": "https://arxiv.org/abs/2511.02993", "authors": ["Yixuan Gao", "Tanvir Ahmed", "Zekun Chang", "Thijs Roumen", "Rajalakshmi Nandakumar"], "title": "PrivyWave: Privacy-Aware Wireless Sensing of Heartbeat", "comment": "20 pages, 5 figures", "summary": "Wireless sensing technologies can now detect heartbeats using radio frequency\nand acoustic signals, raising significant privacy concerns. Existing privacy\nsolutions either protect from all sensing systems indiscriminately preventing\nany utility or operate post-data collection, failing to enable selective access\nwhere authorized devices can monitor while unauthorized ones cannot. We present\na key-based physical obfuscation system, PrivyWave, that addresses this\nchallenge by generating controlled decoy heartbeat signals at\ncryptographically-determined frequencies. Unauthorized sensors receive a\nmixture of real and decoy signals that are indistinguishable without the secret\nkey, while authorized sensors use the key to filter out decoys and recover\naccurate measurements. Our evaluation with 13 participants demonstrates\neffective protection across both sensing modalities: for mmWave radar,\nunauthorized sensors show 21.3 BPM mean absolute error while authorized sensors\nmaintain a much smaller 5.8 BPM; for acoustic sensing, unauthorized error\nincreases to 42.0 BPM while authorized sensors achieve 9.7 BPM. The system\noperates across multiple sensing modalities without per-modality customization\nand provides cryptographic obfuscation guarantees. Performance benchmarks show\nrobust protection across different distances (30-150 cm), orientations\n(120{\\deg} field of view), and diverse indoor environments, establishing\nphysical-layer obfuscation as a viable approach for selective privacy in\npervasive health monitoring."}
{"id": "2511.03020", "categories": ["cs.CR", "cs.LG", "68M25, 68T05 68M25, 68T05", "C.2.0; K.6.5; I.2.6; C.2.0; K.6.5"], "pdf": "https://arxiv.org/pdf/2511.03020", "abs": "https://arxiv.org/abs/2511.03020", "authors": ["Fatimo Adenike Adeniya"], "title": "Exploratory Analysis of Cyberattack Patterns on E-Commerce Platforms Using Statistical Methods", "comment": "32 pages, 9 figures, 6 tables; MSc Research Dissertation, York St\n  John University, London Campus", "summary": "Cyberattacks on e-commerce platforms have grown in sophistication,\nthreatening consumer trust and operational continuity. This research presents a\nhybrid analytical framework that integrates statistical modelling and machine\nlearning for detecting and forecasting cyberattack patterns in the e-commerce\ndomain. Using the Verizon Community Data Breach (VCDB) dataset, the study\napplies Auto ARIMA for temporal forecasting and significance testing, including\na Mann-Whitney U test (U = 2579981.5, p = 0.0121), which confirmed that holiday\nshopping events experienced significantly more severe cyberattacks than\nnon-holiday periods. ANOVA was also used to examine seasonal variation in\nthreat severity, while ensemble machine learning models (XGBoost, LightGBM, and\nCatBoost) were employed for predictive classification. Results reveal recurrent\nattack spikes during high-risk periods such as Black Friday and holiday\nseasons, with breaches involving Personally Identifiable Information (PII)\nexhibiting elevated threat indicators. Among the models, CatBoost achieved the\nhighest performance (accuracy = 85.29%, F1 score = 0.2254, ROC AUC = 0.8247).\nThe framework uniquely combines seasonal forecasting with interpretable\nensemble learning, enabling temporal risk anticipation and breach-type\nclassification. Ethical considerations, including responsible use of sensitive\ndata and bias assessment, were incorporated. Despite class imbalance and\nreliance on historical data, the study provides insights for proactive\ncybersecurity resource allocation and outlines directions for future real-time\nthreat detection research."}
{"id": "2511.03213", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03213", "abs": "https://arxiv.org/abs/2511.03213", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "title": "Bayesian Advantage of Re-Identification Attack in the Shuffle Model", "comment": "Accepted by CSF 2026 -- 39th IEEE Computer Security Foundations\n  Symposium", "summary": "The shuffle model, which anonymizes data by randomly permuting user messages,\nhas been widely adopted in both cryptography and differential privacy. In this\nwork, we present the first systematic study of the Bayesian advantage in\nre-identifying a user's message under the shuffle model. We begin with a basic\nsetting: one sample is drawn from a distribution $P$, and $n - 1$ samples are\ndrawn from a distribution $Q$, after which all $n$ samples are randomly\nshuffled. We define $\\beta_n(P, Q)$ as the success probability of a\nBayes-optimal adversary in identifying the sample from $P$, and define the\nadditive and multiplicative Bayesian advantages as $\\mathsf{Adv}_n^{+}(P, Q) =\n\\beta_n(P,Q) - \\frac{1}{n}$ and $\\mathsf{Adv}_n^{\\times}(P, Q) = n \\cdot\n\\beta_n(P,Q)$, respectively.\n  We derive exact analytical expressions and asymptotic characterizations of\n$\\beta_n(P, Q)$, along with evaluations in several representative scenarios.\nFurthermore, we establish (nearly) tight mutual bounds between the additive\nBayesian advantage and the total variation distance.\n  Finally, we extend our analysis beyond the basic setting and present, for the\nfirst time, an upper bound on the success probability of Bayesian attacks in\nshuffle differential privacy. Specifically, when the outputs of $n$ users--each\nprocessed through an $\\varepsilon$-differentially private local randomizer--are\nshuffled, the probability that an attacker successfully re-identifies any\ntarget user's message is at most $e^{\\varepsilon}/n$."}
{"id": "2511.03229", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03229", "abs": "https://arxiv.org/abs/2511.03229", "authors": ["Yong Huang", "Zhibo Dong", "Xiaoguang Yang", "Dalong Zhang", "Qingxian Wang", "Zhihua Wang"], "title": "Smartphone User Fingerprinting on Wireless Traffic", "comment": "To appear in IEEE Transactions on Mobile Computing. arXiv admin note:\n  text overlap with arXiv:2408.07263", "summary": "Due to the openness of the wireless medium, smartphone users are susceptible\nto user privacy attacks, where user privacy information is inferred from\nencrypted Wi-Fi wireless traffic. Existing attacks are limited to recognizing\nmobile apps and their actions and cannot infer the smartphone user identity, a\nfundamental part of user privacy. To overcome this limitation, we propose\nU-Print, a novel attack system that can passively recognize smartphone apps,\nactions, and users from over-the-air MAC-layer frames. We observe that\nsmartphone users usually prefer different add-on apps and in-app actions,\nyielding different changing patterns in Wi-Fi traffic. U-Print first extracts\nmulti-level traffic features and exploits customized temporal convolutional\nnetworks to recognize smartphone apps and actions, thus producing users'\nbehavior sequences. Then, it leverages the silhouette coefficient method to\ndetermine the number of users and applies the k-means clustering to profile and\nidentify smartphone users. We implement U-Print using a laptop with a Kali\ndual-band wireless network card and evaluate it in three real-world\nenvironments. U-Print achieves an overall accuracy of 98.4% and an F1 score of\n0.983 for user inference. Moreover, it can correctly recognize up to 96% of\napps and actions in the closed world and more than 86% in the open world."}
{"id": "2511.03247", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03247", "abs": "https://arxiv.org/abs/2511.03247", "authors": ["Amy Chang", "Nicholas Conley", "Harish Santhanalakshmi Ganesan", "Adam Swanda"], "title": "Death by a Thousand Prompts: Open Model Vulnerability Analysis", "comment": null, "summary": "Open-weight models provide researchers and developers with accessible\nfoundations for diverse downstream applications. We tested the safety and\nsecurity postures of eight open-weight large language models (LLMs) to identify\nvulnerabilities that may impact subsequent fine-tuning and deployment. Using\nautomated adversarial testing, we measured each model's resilience against\nsingle-turn and multi-turn prompt injection and jailbreak attacks. Our findings\nreveal pervasive vulnerabilities across all tested models, with multi-turn\nattacks achieving success rates between 25.86\\% and 92.78\\% -- representing a\n$2\\times$ to $10\\times$ increase over single-turn baselines. These results\nunderscore a systemic inability of current open-weight models to maintain\nsafety guardrails across extended interactions. We assess that alignment\nstrategies and lab priorities significantly influence resilience:\ncapability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher\nmulti-turn susceptibility, whereas safety-oriented designs such as Google Gemma\n3 exhibit more balanced performance.\n  The analysis concludes that open-weight models, while crucial for innovation,\npose tangible operational and ethical risks when deployed without layered\nsecurity controls. These findings are intended to inform practitioners and\ndevelopers of the potential risks and the value of professional AI security\nsolutions to mitigate exposure. Addressing multi-turn vulnerabilities is\nessential to ensure the safe, reliable, and responsible deployment of\nopen-weight LLMs in enterprise and public domains. We recommend adopting a\nsecurity-first design philosophy and layered protections to ensure resilient\ndeployments of open-weight models."}
{"id": "2511.03248", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03248", "abs": "https://arxiv.org/abs/2511.03248", "authors": ["Junhao Li", "Jiahao Chen", "Zhou Feng", "Chunyi Zhou"], "title": "Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation Framework", "comment": "14 pages, 3 figures; Accepted by MMM 2026; Complete version in\n  progress", "summary": "Recent advances in multi-modal Large Language Models (M-LLMs) have\ndemonstrated a powerful ability to synthesize implicit information from\ndisparate sources, including images and text. These resourceful data from\nsocial media also introduce a significant and underexplored privacy risk: the\ninference of sensitive personal attributes from seemingly daily media content.\nHowever, the lack of benchmarks and comprehensive evaluations of\nstate-of-the-art M-LLM capabilities hinders the research of private attribute\nprofiling on social media. Accordingly, we propose (1) PRISM, the first\nmulti-modal, multi-dimensional and fine-grained synthesized dataset\nincorporating a comprehensive privacy landscape and dynamic user history; (2)\nan Efficient evaluation framework that measures the cross-modal privacy\ninference capabilities of advanced M-LLM. Specifically, PRISM is a large-scale\nsynthetic benchmark designed to evaluate cross-modal privacy risks. Its key\nfeature is 12 sensitive attribute labels across a diverse set of multi-modal\nprofiles, which enables targeted privacy analysis. These profiles are generated\nvia a sophisticated LLM agentic workflow, governed by a prior distribution to\nensure they realistically mimic social media users. Additionally, we propose a\nMulti-Agent Inference Framework that leverages a pipeline of specialized LLMs\nto enhance evaluation capabilities. We evaluate the inference capabilities of\nsix leading M-LLMs (Qwen, Gemini, GPT-4o, GLM, Doubao, and Grok) on PRISM. The\ncomparison with human performance reveals that these MLLMs significantly\noutperform in accuracy and efficiency, highlighting the threat of potential\nprivacy risks and the urgent need for robust defenses."}
{"id": "2511.03271", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03271", "abs": "https://arxiv.org/abs/2511.03271", "authors": ["Yize Liu", "Yunyun Hou", "Aina Sui"], "title": "Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs", "comment": null, "summary": "Large Language Models (LLMs) have been widely deployed across various\napplications, yet their potential security and ethical risks have raised\nincreasing concerns. Existing research employs red teaming evaluations,\nutilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs.\nHowever, these approaches often lack exploration of successful dialogue\ntrajectories within the attack space, and they tend to overlook the\nconsiderable overhead associated with the attack process. To address these\nlimitations, this paper first introduces a theoretical model based on\ndynamically weighted graph topology, abstracting the multi-turn attack process\nas a path planning problem. Based on this framework, we propose ABC, an\nenhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a\ncollaborative search mechanism with employed, onlooker, and scout bees. This\nalgorithm significantly improves the efficiency of optimal attack path search\nwhile substantially reducing the average number of queries required. Empirical\nevaluations on three open-source and two proprietary language models\ndemonstrate the effectiveness of our approach, achieving attack success rates\nabove 90\\% across the board, with a peak of 98\\% on GPT-3.5-Turbo, and\noutperforming existing baselines. Furthermore, it achieves comparable success\nwith only 26 queries on average, significantly reducing red teaming overhead\nand highlighting its superior efficiency."}
{"id": "2511.03319", "categories": ["cs.CR", "cs.CY", "cs.IR", "cs.IT", "math.IT", "H.4; K.2; K.4; J.4; J.5; D.2"], "pdf": "https://arxiv.org/pdf/2511.03319", "abs": "https://arxiv.org/abs/2511.03319", "authors": ["Giulio Caldarelli", "Massimiliano Ornaghi"], "title": "Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles", "comment": "Not peer reviewed", "summary": "The oracle problem refers to the inability of an agent to know if the\ninformation coming from an oracle is authentic and unbiased. In ancient times,\nphilosophers and historians debated on how to evaluate, increase, and secure\nthe reliability of oracle predictions, particularly those from Delphi, which\npertained to matters of state. Today, we refer to data carriers for automatic\nmachines as oracles, but establishing a secure channel between these oracles\nand the real world still represents a challenge. Despite numerous efforts, this\nproblem remains mostly unsolved, and the recent advent of blockchain oracles\nhas added a layer of complexity because of the decentralization of blockchains.\nThis paper conceptually connects Delphic and modern blockchain oracles,\ndeveloping a comparative framework. Leveraging blockchain oracle taxonomy,\nlexical analysis is also performed on 167 Delphic queries to shed light on the\nrelationship between oracle answer quality and question type. The presented\nframework aims first at revealing commonalities between classical and\ncomputational oracles and then at enriching the oracle analysis within each\nfield. This study contributes to the computer science literature by proposing\nstrategies to improve the reliability of blockchain oracles based on insights\nfrom Delphi and to classical literature by introducing a framework that can\nalso be applied to interpret and classify other ancient oracular mechanisms."}
{"id": "2511.03341", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03341", "abs": "https://arxiv.org/abs/2511.03341", "authors": ["Haomin Li", "Fangxin Liu", "Chenyang Guan", "Zongwu Wang", "Li Jiang", "Haibing Guan"], "title": "LaMoS: Enabling Efficient Large Number Modular Multiplication through SRAM-based CiM Acceleration", "comment": "Accepted by 2026 Design, Automation and Test in Europe Conference\n  (DATE 2026)", "summary": "Barrett's algorithm is one of the most widely used methods for performing\nmodular multiplication, a critical nonlinear operation in modern privacy\ncomputing techniques such as homomorphic encryption (HE) and zero-knowledge\nproofs (ZKP). Since modular multiplication dominates the processing time in\nthese applications, computational complexity and memory limitations\nsignificantly impact performance. Computing-in-Memory (CiM) is a promising\napproach to tackle this problem. However, existing schemes currently suffer\nfrom two main problems: 1) Most works focus on low bit-width modular\nmultiplication, which is inadequate for mainstream cryptographic algorithms\nsuch as elliptic curve cryptography (ECC) and the RSA algorithm, both of which\nrequire high bit-width operations; 2) Recent efforts targeting large number\nmodular multiplication rely on inefficient in-memory logic operations,\nresulting in high scaling costs for larger bit-widths and increased latency. To\naddress these issues, we propose LaMoS, an efficient SRAM-based CiM design for\nlarge-number modular multiplication, offering high scalability and area\nefficiency. First, we analyze the Barrett's modular multiplication method and\nmap the workload onto SRAM CiM macros for high bit-width cases. Additionally,\nwe develop an efficient CiM architecture and dataflow to optimize large-number\nmodular multiplication. Finally, we refine the mapping scheme for better\nscalability in high bit-width scenarios using workload grouping. Experimental\nresults show that LaMoS achieves a $7.02\\times$ speedup and reduces high\nbit-width scaling costs compared to existing SRAM-based CiM designs."}
{"id": "2511.03486", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03486", "abs": "https://arxiv.org/abs/2511.03486", "authors": ["David Soler", "Carlos Dafonte", "Manuel Fernández-Veiga", "Ana Fernández Vilas", "Francisco J. Nóvoa"], "title": "Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging", "comment": "31 pages, 4 figures. Submitted to IEEE Transactions on Emerging\n  Topics in Computing", "summary": "Instant messaging has become one of the most used methods of communication\nonline, which has attracted significant attention to its underlying\ncryptographic protocols and security guarantees. Techniques to increase privacy\nsuch as End-to-End Encryption and pseudonyms have been introduced. However,\nonline spaces such as messaging groups still require moderation to prevent\nmisbehaving users from participating in them, particularly in anonymous\ncontexts.. In Anonymous Blocklisting (AB) schemes, users must prove during\nauthentication that none of their previous pseudonyms has been blocked,\npreventing misbehaving users from creating new pseudonyms. In this work we\npropose an alternative \\textit{Federated Anonymous Blocklisting} (FAB) in which\nthe centralised Service Provider is replaced by small distributed Realms, each\nwith its own blocklist. Realms can establish trust relationships between each\nother, such that when users authenticate to a realm, they must prove that they\nare not banned in any of its trusted realms. We provide an implementation of\nour proposed scheme; unlike existing AB constructions, the performance of ours\ndoes not depend on the current size of the blocklist nor requires processing\nnew additions to the blocklist. We also demonstrate its applicability to\nreal-world messaging groups by integrating our FAB scheme into the Messaging\nLayer Security protocol."}
{"id": "2511.03538", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03538", "abs": "https://arxiv.org/abs/2511.03538", "authors": ["Jaydip Sen"], "title": "Security and Privacy Management of IoT Using Quantum Computing", "comment": "This is a preprint of the chapter. It will be published by Springer,\n  Singapore, in \"Quantum Computing, Sensing and Communications for IoT\" edited\n  by Suyel Namasudra, Kemal Akkaya and Nirmalya Kar. Link to the final\n  authenticated version will be shared as soon as the chapter is published. The\n  current version has 55 pages, 15 figures, and 10 tables", "summary": "The convergence of the Internet of Things (IoT) and quantum computing is\nredefining the security paradigm of interconnected digital systems. Classical\ncryptographic algorithms such as RSA, Elliptic Curve Cryptography (ECC), and\nAdvanced Encryption Standard (AES) have long provided the foundation for\nsecuring IoT communication. However, the emergence of quantum algorithms such\nas Shor's and Grover's threatens to render these techniques vulnerable,\nnecessitating the development of quantum-resilient alternatives. This chapter\nexamines the implications of quantum computing for IoT security and explores\nstrategies for building cryptographically robust systems in the post-quantum\nera. It presents an overview of Post-Quantum Cryptographic (PQC) families,\nincluding lattice-based, code-based, hash-based, and multivariate approaches,\nanalyzing their potential for deployment in resource-constrained IoT\nenvironments. In addition, quantum-based methods such as Quantum Key\nDistribution (QKD) and Quantum Random Number Generators (QRNGs) are discussed\nfor their ability to enhance confidentiality and privacy through physics-based\nsecurity guarantees. The chapter also highlights issues of privacy management,\nregulatory compliance, and standardization, emphasizing the need for\ncollaborative efforts across academia, industry, and governance. Overall, it\nprovides a comprehensive perspective on security IoT ecosystems against quantum\nthreats and ensures resilience in the next generation of intelligent networks."}
{"id": "2511.03641", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "68T01, 68727, 68T30, 68T35, 68T37, 68T50"], "pdf": "https://arxiv.org/pdf/2511.03641", "abs": "https://arxiv.org/abs/2511.03641", "authors": ["Thomas Souverain"], "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology", "comment": "17 pages, 2 Tables and 2 Pictures", "summary": "To foster trustworthy Artificial Intelligence (AI) within the European Union,\nthe AI Act requires providers to mark and detect the outputs of their\ngeneral-purpose models. The Article 50 and Recital 133 call for marking methods\nthat are ''sufficiently reliable, interoperable, effective and robust''. Yet,\nthe rapidly evolving and heterogeneous landscape of watermarks for Large\nLanguage Models (LLMs) makes it difficult to determine how these four standards\ncan be translated into concrete and measurable evaluations. Our paper addresses\nthis challenge, anchoring the normativity of European requirements in the\nmultiplicity of watermarking techniques. Introducing clear and distinct\nconcepts on LLM watermarking, our contribution is threefold. (1) Watermarking\nCategorisation: We propose an accessible taxonomy of watermarking methods\naccording to the stage of the LLM lifecycle at which they are applied - before,\nduring, or after training, and during next-token distribution or sampling. (2)\nWatermarking Evaluation: We interpret the EU AI Act's requirements by mapping\neach criterion with state-of-the-art evaluations on robustness and\ndetectability of the watermark, and of quality of the LLM. Since\ninteroperability remains largely untheorised in LLM watermarking research, we\npropose three normative dimensions to frame its assessment. (3) Watermarking\nComparison: We compare current watermarking methods for LLMs against the\noperationalised European criteria and show that no approach yet satisfies all\nfour standards. Encouraged by emerging empirical tests, we recommend further\nresearch into watermarking directly embedded within the low-level architecture\nof LLMs."}
{"id": "2511.03675", "categories": ["cs.CR", "cs.AI", "K.4.1; C.2.0; K.6.5; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.03675", "abs": "https://arxiv.org/abs/2511.03675", "authors": ["Geoff McDonald", "Jonathan Bar Or"], "title": "Whisper Leak: a side-channel attack on Large Language Models", "comment": "14 pages, 7 figures", "summary": "Large Language Models (LLMs) are increasingly deployed in sensitive domains\nincluding healthcare, legal services, and confidential communications, where\nprivacy is paramount. This paper introduces Whisper Leak, a side-channel attack\nthat infers user prompt topics from encrypted LLM traffic by analyzing packet\nsize and timing patterns in streaming responses. Despite TLS encryption\nprotecting content, these metadata patterns leak sufficient information to\nenable topic classification. We demonstrate the attack across 28 popular LLMs\nfrom major providers, achieving near-perfect classification (often >98% AUPRC)\nand high precision even at extreme class imbalance (10,000:1 noise-to-target\nratio). For many models, we achieve 100% precision in identifying sensitive\ntopics like \"money laundering\" while recovering 5-20% of target conversations.\nThis industry-wide vulnerability poses significant risks for users under\nnetwork surveillance by ISPs, governments, or local adversaries. We evaluate\nthree mitigation strategies - random padding, token batching, and packet\ninjection - finding that while each reduces attack effectiveness, none provides\ncomplete protection. Through responsible disclosure, we have collaborated with\nproviders to implement initial countermeasures. Our findings underscore the\nneed for LLM providers to address metadata leakage as AI systems handle\nincreasingly sensitive information."}
