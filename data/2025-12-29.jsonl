{"id": "2512.21354", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.21354", "abs": "https://arxiv.org/abs/2512.21354", "authors": ["Bin Wang", "Jiazheng Quan", "Xingrui Yu", "Hansen Hu", "Yuhao", "Ivor Tsang"], "title": "Reflection-Driven Control for Trustworthy Code Agents", "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Contemporary large language model (LLM) agents are remarkably capable, but they still lack reliable safety controls and can produce unconstrained, unpredictable, and even actively harmful outputs. To address this, we introduce Reflection-Driven Control, a standardized and pluggable control module that can be seamlessly integrated into general agent architectures. Reflection-Driven Control elevates \"self-reflection\" from a post hoc patch into an explicit step in the agent's own reasoning process: during generation, the agent continuously runs an internal reflection loop that monitors and evaluates its own decision path. When potential risks are detected, the system retrieves relevant repair examples and secure coding guidelines from an evolving reflective memory, injecting these evidence-based constraints directly into subsequent reasoning steps. We instantiate Reflection-Driven Control in the setting of secure code generation and systematically evaluate it across eight classes of security-critical programming tasks. Empirical results show that Reflection-Driven Control substantially improves the security and policy compliance of generated code while largely preserving functional correctness, with minimal runtime and token overhead. Taken together, these findings indicate that Reflection-Driven Control is a practical path toward trustworthy AI coding agents: it enables designs that are simultaneously autonomous, safer by construction, and auditable."}
{"id": "2512.21358", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.21358", "abs": "https://arxiv.org/abs/2512.21358", "authors": ["Natasha Fernandes", "Annabelle McIver", "Parastoo Sadeghi"], "title": "Composition Theorems for f-Differential Privacy", "comment": "32 pages, 11 figures", "summary": "\"f differential privacy\" (fDP) is a recent definition for privacy privacy which can offer improved predictions of \"privacy loss\". It has been used to analyse specific privacy mechanisms, such as the popular Gaussian mechanism. In this paper we show how fDP's foundation in statistical hypothesis testing implies equivalence to the channel model of Quantitative Information Flow. We demonstrate this equivalence by a Galois connection between two partially ordered sets. This equivalence enables novel general composition theorems for fDP, supporting improved analysis for complex privacy designs."}
{"id": "2512.21362", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.21362", "abs": "https://arxiv.org/abs/2512.21362", "authors": ["Behnam Farnaghinejad", "Antonio Porsia", "Annachiara Ruospo", "Alessandro Savino", "Stefano Di Carlo", "Ernesto Sanchez"], "title": "Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide", "comment": null, "summary": "Security in modern RISC-V processors demands more than functional correctness: It requires resilience to side-channel attacks. This paper evaluates the vulnerability of the side channel of the CVA6 RISC-V core by analyzing software-based AES encryption uses an RTL-level power profiling framework called VeriSide. This work represents that this design's Correlation Power Analysis (CPA) reveals significant leakage, enabling key recovery. These findings underscore the importance of early-stage RTL assessments in shaping future secure RISC-V designs."}
{"id": "2512.21367", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21367", "abs": "https://arxiv.org/abs/2512.21367", "authors": ["Mark Ballard", "Guanqun Song", "Ting Zhu"], "title": "Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO", "comment": null, "summary": "The rapid proliferation of satellite constellations, particularly in Low Earth Orbit (LEO), has fundamentally altered the global space infrastructure, shifting the risk landscape from purely kinetic collisions to complex cyber-physical threats. While traditional safety frameworks focus on debris mitigation, ground-based adversaries increasingly exploit radio-frequency links, supply chain vulnerabilities, and software update pathways to degrade space assets. This paper presents a comparative analysis of satellite cybersecurity across LEO, Medium Earth Orbit (MEO), and Geostationary Earth Orbit (GEO) regimes. By synthesizing data from 60 publicly documented security incidents with key vulnerability proxies--including Telemetry, Tracking, and Command (TT&C) anomalies, encryption weaknesses, and environmental stressors--we characterize how orbital altitude dictates attack feasibility and impact. Our evaluation reveals distinct threat profiles: GEO systems are predominantly targeted via high-frequency uplink exposure, whereas LEO constellations face unique risks stemming from limited power budgets, hardware constraints, and susceptibility to thermal and radiation-induced faults. We further bridge the gap between security and sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation, undermining efforts toward carbon-neutral space operations. The results demonstrate that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits."}
{"id": "2512.21368", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21368", "abs": "https://arxiv.org/abs/2512.21368", "authors": ["Arsalan Vahi"], "title": "Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security", "comment": null, "summary": "The successful deployment of the Internet of Things (IoT) applications relies heavily on their robust security, and lightweight cryptography is considered an emerging solution in this context. While existing surveys have been examining lightweight cryptographic techniques from the perspective of hardware and software implementations or performance evaluation, there is a significant gap in addressing different security aspects specific to the IoT environment. This study aims to bridge this gap. This research presents a thorough survey focused on the security evaluation of symmetric lightweight ciphers commonly used in IoT systems. The objective of this study is to provide a holistic understanding of lightweight ciphers, emphasizing their security strength, which is an essential consideration for real-time and resource-constrained applications. Furthermore, we propose two taxonomies: one for classifying IoT applications based on their inherent characteristics, and another for evaluating security levels based on key size. Our findings indicate that key size is a critical parameter in the security of lightweight ciphers. Ciphers employing keys shorter than 128 bits are considered less secure or even insecure for protecting sensitive data"}
{"id": "2512.21371", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21371", "abs": "https://arxiv.org/abs/2512.21371", "authors": ["Yifan Yao", "Baojuan Wang", "Jinhao Duan", "Kaidi Xu", "ChuanKai Guo", "Zhibo Eric Sun", "Yue Zhang"], "title": "The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes", "comment": null, "summary": "Chat-based cybercrime has emerged as a pervasive threat, with attackers leveraging real-time messaging platforms to conduct scams that rely on trust-building, deception, and psychological manipulation. Traditional defense mechanisms, which operate on static rules or shallow content filters, struggle to identify these conversational threats, especially when attackers use multimedia obfuscation and context-aware dialogue.\n  In this work, we ask a provocative question inspired by the classic Imitation Game: Can machines convincingly pose as human victims to turn deception against cybercriminals? We present LURE (LLM-based User Response Engagement), the first system to deploy Large Language Models (LLMs) as active agents, not as passive classifiers, embedded within adversarial chat environments.\n  LURE combines automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. Applied to the setting of illicit video chat scams on Telegram, our system engaged 53 actors across 98 groups. In over 56 percent of interactions, the LLM maintained multi-round conversations without being noticed as a bot, effectively \"winning\" the imitation game. Our findings reveal key behavioral patterns in scam operations, such as payment flows, upselling strategies, and platform migration tactics."}
{"id": "2512.21374", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21374", "abs": "https://arxiv.org/abs/2512.21374", "authors": ["Daniyal Ganiuly", "Nurzhau Bolatbek", "Assel Smaiyl"], "title": "Security Risks Introduced by Weak Authentication in Smart Home IoT Systems", "comment": null, "summary": "Smart home IoT systems rely on authentication mechanisms to ensure that only authorized entities can control devices and access sensitive functionality. In practice, these mechanisms must balance security with usability, often favoring persistent connectivity and minimal user interaction. This paper presents an empirical analysis of authentication enforcement in deployed smart home IoT devices, focusing on how authentication state is established, reused, and validated during normal operation and under routine network conditions. A set of widely deployed consumer devices, including smart plugs, lighting devices, cameras, and a hub based ecosystem, was evaluated in a controlled residential environment using passive network measurement and controlled interaction through official mobile applications. Authentication behavior was examined during initial pairing, over extended periods of operation, after common network changes, and under replay attempts from a different local network host. The results show that authentication state established during pairing is consistently reused across control actions, persists for extended periods without explicit expiration, and remains valid after network events such as reconnection, address reassignment, and router reboot. Replay experiments demonstrate that previously observed authentication artifacts can often be reused to issue control commands from another host on the same local network with high success rates. These behaviors were observed across multiple device categories and ecosystems. The findings indicate that current smart home IoT authentication mechanisms rely on long lived trust relationships with limited binding to session freshness, network context, or controller identity."}
{"id": "2512.21377", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21377", "abs": "https://arxiv.org/abs/2512.21377", "authors": ["Adwa Alangari", "Ohoud Alharbi"], "title": "A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games", "comment": null, "summary": "This systematic literature review surveys technical defenses against software-based cheating in online multiplayer games. Categorizing existing approach-es into server-side detection, client-side anti-tamper, kernel-level anti-cheat drivers, and hardware-assisted TEEs. Each category is evaluated in terms of detection effectiveness, perfor-mance overhead, privacy im-pact, and scalability. The analy-sis highlights key trade-offs, particularly between the high visibility of kernel-level solutions and their privacy and stability risks, versus the low intrusive-ness but limited insight of server-side methods. Overall, the re-view emphasizes the ongoing arms race with cheaters and the need for robust, adversary-resistant anti-cheat designs."}
{"id": "2512.21404", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21404", "abs": "https://arxiv.org/abs/2512.21404", "authors": ["Tianwei Lan", "Farid Naït-Abdesselam"], "title": "LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors", "comment": null, "summary": "The rapid growth in both the scale and complexity of Android malware has driven the widespread adoption of machine learning (ML) techniques for scalable and accurate malware detection. Despite their effectiveness, these models remain vulnerable to adversarial attacks that introduce carefully crafted feature-level perturbations to evade detection while preserving malicious functionality. In this paper, we present LAMLAD, a novel adversarial attack framework that exploits the generative and reasoning capabilities of large language models (LLMs) to bypass ML-based Android malware classifiers. LAMLAD employs a dual-agent architecture composed of an LLM manipulator, which generates realistic and functionality-preserving feature perturbations, and an LLM analyzer, which guides the perturbation process toward successful evasion. To improve efficiency and contextual awareness, LAMLAD integrates retrieval-augmented generation (RAG) into the LLM pipeline. Focusing on Drebin-style feature representations, LAMLAD enables stealthy and high-confidence attacks against widely deployed Android malware detection systems. We evaluate LAMLAD against three representative ML-based Android malware detectors and compare its performance with two state-of-the-art adversarial attack methods. Experimental results demonstrate that LAMLAD achieves an attack success rate (ASR) of up to 97%, requiring on average only three attempts per adversarial sample, highlighting its effectiveness, efficiency, and adaptability in practical adversarial settings. Furthermore, we propose an adversarial training-based defense strategy that reduces the ASR by more than 30% on average, significantly enhancing model robustness against LAMLAD-style attacks."}
{"id": "2512.21524", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21524", "abs": "https://arxiv.org/abs/2512.21524", "authors": ["Lichao Wu", "Mohamadreza Rostami", "Huimin Li", "Nikhilesh Singh", "Ahmad-Reza Sadeghi"], "title": "GoldenFuzz: Generative Golden Reference Hardware Fuzzing", "comment": "Accepted by NDSS'26", "summary": "Modern hardware systems, driven by demands for high performance and application-specific functionality, have grown increasingly complex, introducing large surfaces for bugs and security-critical vulnerabilities. Fuzzing has emerged as a scalable solution for discovering such flaws. Yet, existing hardware fuzzers suffer from limited semantic awareness, inefficient test refinement, and high computational overhead due to reliance on slow device simulation.\n  In this paper, we present GoldenFuzz, a novel two-stage hardware fuzzing framework that partially decouples test case refinement from coverage and vulnerability exploration. GoldenFuzz leverages a fast, ISA-compliant Golden Reference Model (GRM) as a ``digital twin'' of the Device Under Test (DUT). It fuzzes the GRM first, enabling rapid, low-cost test case refinement, accelerating deep architectural exploration and vulnerability discovery on DUT. During the fuzzing pipeline, GoldenFuzz iteratively constructs test cases by concatenating carefully chosen instruction blocks that balance the subtle inter- and intra-instructions quality. A feedback-driven mechanism leveraging insights from both high- and low-coverage samples further enhances GoldenFuzz's capability in hardware state exploration. Our evaluation of three RISC-V processors, RocketChip, BOOM, and CVA6, demonstrates that GoldenFuzz significantly outperforms existing fuzzers in achieving the highest coverage with minimal test case length and computational overhead. GoldenFuzz uncovers all known vulnerabilities and discovers five new ones, four of which are classified as highly severe with CVSS v3 severity scores exceeding seven out of ten. It also identifies two previously unknown vulnerabilities in the commercial BA51-H core extension."}
{"id": "2512.21525", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21525", "abs": "https://arxiv.org/abs/2512.21525", "authors": ["Keshav Sinha", "Sumitra", "Richa Kumari", "Akashdeep Bhardwaj", "Shawon Rahman"], "title": "Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption", "comment": "In terms of content, the paper meets the requirements of the journal. This paper provides an opportunity for the author to conduct a more detailed experiment and present the results. By doing so, the author's idea and algorithm can be improved. The experiment can be conducted under a variety of conditions", "summary": "In todays security landscape, every user wants to access large amounts of data with confidentiality and authorization. To maintain confidentiality, various researchers have proposed several techniques. However, to access secure data, researchers use access control lists to grant authentication and provide authorization. The above several steps will increase the server's computation overhead and response time. To cope with these two problems, we proposed multiparty execution on the server. In this paper, we introduce two different approaches. The first approach is encryption, utilizing the Involution Function Based Stream Cipher to encrypt the file data. The second approach is key distribution, using the Shamir secret sharing scheme to divide and distribute the symmetric key to every user. The decryption process required key reconstruction, which used second order Lagrange interpolation to reconstruct the secret keys from the hidden points. The process will reduce the server's computational overhead. The results are evaluated based on the encryption and decryption time, throughput, computational overhead, and security analysis. In the future, the proposed mechanism will be used to share large-scale, secure data within the organization."}
{"id": "2512.21561", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21561", "abs": "https://arxiv.org/abs/2512.21561", "authors": ["Xiaoming Chen", "Haoze Chen", "Fei Xu", "Meifeng Gao", "Jianguo Xie", "Cheng Ye", "An Hua", "Jiao Zhao", "Minghan Li", "Feilong Li", "Yajun Miao", "Wei Qi"], "title": "Security Boundaries of Quantum Key Reuse: A Quantitative Evaluation Method for QKD Key Rotation Interval and Security Benefits Combined with Block Ciphers", "comment": "19 pages, 7 figures", "summary": "With the rapid development of quantum computing, classical cryptography systems are facing increasing security threats, making it urgent to build architectures resilient to quantum attacks. Although Quantum Key Distribution (QKD) technology provides information-theoretic security, its limited bandwidth requires it to be combined with classical cryptography-particularly block ciphers such as AES and SM4-in practical deployments.However, when a single key is used to process multiple multi-block files, the resulting reduction in security strength has not yet been systematically quantified.In this work, we focus on the use of both QKD keys and block ciphers, and construct a precise calculation model for the key rotation interval. We further propose a quantitative method to evaluate the security benefit of using QKD keys for block cipher. Building on concrete security models and the security properties of various block cipher modes (CTR, CBC, and ECBC-MAC), we derive the maximum number of files that can be safely encrypted under a single key, denoted Q*, and quantify the benefits of key rotation interval in enhancing security levels. Using SM4 as a case study, our results show that, under an 80-bit security target, uniformly performing k key rotations can increase the security strength by log2(k) to 2log2(k) bits. This study provides theoretical support and a basis for parameter optimization for the integrated application of QKD keys with classical cryptographic algorithms and the engineering deployment of cryptographic systems."}
{"id": "2512.21663", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.21663", "abs": "https://arxiv.org/abs/2512.21663", "authors": ["Aditya Mitra", "Sibi Chakkaravarthy Sethuraman"], "title": "Verifiable Passkey: The Decentralized Authentication Standard", "comment": null, "summary": "Passwordless authentication has revolutionized the way we authenticate across various websites and services. FIDO2 Passkeys, is one of the most-widely adopted standards of passwordless authentication that promises phishing-resistance. However, like any other authentication system, passkeys require the user details to be saved on a centralized server, also known as Relying Party (RP) Server. This has led users to create a new passkey for every new online account. While this just works for a limited number of online accounts, the limited storage space of secure storage modules like TPM or a physical security key limits the number of passkeys a user can have. For example, Yubico Yubikey 5 (firmware 5.0 - 5.6) offers to store only 25 passkeys, while firmware 5.7+ allows to store upto 100 [1]. To overcome this problem, one of the widely adopted approaches is to use Federated Authentication with Single Sign On (SSO). This allows the user to create a passkey for the Identity Provider (IdP) and use the IdP to authenticate to all service providers. This proves to be a significant privacy risk since the IdP can potentially track users across different services. To overcome these limitations, this paper introduces a novel standard 'Verifiable Passkey' that allows the user to use Passkeys created for a Verifiable Credential issuer across any platform without risking privacy or user tracking."}
{"id": "2512.21681", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.21681", "abs": "https://arxiv.org/abs/2512.21681", "authors": ["Tian Li", "Bo Lin", "Shangwen Wang", "Yusong Tan"], "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation", "comment": null, "summary": "Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implications remain dangerously underexplored. This paper conducts the first systematic exploration of a critical and stealthy threat: backdoor attacks targeting the retriever component, which represents a significant supply-chain vulnerability. It is infeasible to assess this threat realistically, as existing attack methods are either too ineffective to pose a real danger or are easily detected by state-of-the-art defense mechanisms spanning both latent-space analysis and token-level inspection, which achieve consistently high detection rates. To overcome this barrier and enable a realistic analysis, we first developed VenomRACG, a new class of potent and stealthy attack that serves as a vehicle for our investigation. Its design makes poisoned samples statistically indistinguishable from benign code, allowing the attack to consistently maintain low detectability across all evaluated defense mechanisms. Armed with this capability, our exploration reveals a severe vulnerability: by injecting vulnerable code equivalent to only 0.05% of the entire knowledge base size, an attacker can successfully manipulate the backdoored retriever to rank the vulnerable code in its top-5 results in 51.29% of cases. This translates to severe downstream harm, causing models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while leaving the system's general performance intact. Our findings establish that retriever backdooring is not a theoretical concern but a practical threat to the software development ecosystem that current defenses are blind to, highlighting the urgent need for robust security measures."}
{"id": "2512.21698", "categories": ["cs.CR", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.21698", "abs": "https://arxiv.org/abs/2512.21698", "authors": ["A V Uday Kiran Kandala"], "title": "Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding", "comment": null, "summary": "This work introduces a unified raster domain steganographic framework, termed as the Glyph Perturbation Cardinality (GPC) framework, capable of embedding heterogeneous data such as text, images, audio, and video directly into the pixel space of rendered textual glyphs. Unlike linguistic or structural text based steganography, the proposed method operates exclusively after font rasterization, modifying only the bitmap produced by a deterministic text rendering pipeline. Each glyph functions as a covert encoding unit, where a payload value is expressed through the cardinality of minimally perturbed interior ink pixels. These minimal intensity increments remain visually imperceptible while forming a stable and decodable signal. The framework is demonstrated for text to text embedding and generalized to multimodal inputs by normalizing image intensities, audio derived scalar features, and video frame values into bounded integer sequences distributed across glyphs. Decoding is achieved by re-rasterizing the cover text, subtracting canonical glyph rasters, and recovering payload values via pixel count analysis. The approach is computationally lightweight, and grounded in deterministic raster behavior, enabling ordinary text to serve as a visually covert medium for multimodal data embedding."}
{"id": "2512.21737", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21737", "abs": "https://arxiv.org/abs/2512.21737", "authors": ["Deepak", "Rahul Balout", "Anupam Golder", "Suparna Kundu", "Angshuman Karmakar", "Debayan Das"], "title": "Machine Learning Power Side-Channel Attack on SNOW-V", "comment": "This paper has already been accepted in the VLSID 2026 Conference", "summary": "This paper demonstrates a power analysis-based Side-Channel Analysis (SCA) attack on the SNOW-V encryption algorithm, which is a 5G mobile communication security standard candidate. Implemented on an STM32 microcontroller, power traces captured with a ChipWhisperer board were analyzed, with Test Vector Leakage Assessment (TVLA) confirming exploitable leakage. Profiling attacks using Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) achieved efficient key recovery, with FCN achieving > 5X lower minimum traces to disclosure (MTD) compared to the state-of-the-art Correlational Power Analysis (CPA) assisted with LDA. The results highlight the vulnerability of SNOW-V to machine learning-based SCA and the need for robust countermeasures."}
{"id": "2512.21762", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21762", "abs": "https://arxiv.org/abs/2512.21762", "authors": ["Kurtis Chow", "Omar Samiullah", "Vinesh Sridhar", "Hewen Zhang"], "title": "Assessing the Effectiveness of Membership Inference on Generative Music", "comment": "10 pages, 3 figures, 3 tables", "summary": "Generative AI systems are quickly improving, now able to produce believable output in several modalities including images, text, and audio. However, this fast development has prompted increased scrutiny concerning user privacy and the use of copyrighted works in training. A recent attack on machine-learning models called membership inference lies at the crossroads of these two concerns. The attack is given as input a set of records and a trained model and seeks to identify which of those records may have been used to train the model. On one hand, this attack can be used to identify user data used to train a model, which may violate their privacy especially in sensitive applications such as models trained on medical data. On the other hand, this attack can be used by rights-holders as evidence that a company used their works without permission to train a model.\n  Remarkably, it appears that no work has studied the effect of membership inference attacks (MIA) on generative music. Given that the music industry is worth billions of dollars and artists would stand to gain from being able to determine if their works were being used without permission, we believe this is a pressing issue to study. As such, in this work we begin a preliminary study into whether MIAs are effective on generative music. We study the effect of several existing attacks on MuseGAN, a popular and influential generative music model. Similar to prior work on generative audio MIAs, our findings suggest that music data is fairly resilient to known membership inference techniques."}
{"id": "2512.21813", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21813", "abs": "https://arxiv.org/abs/2512.21813", "authors": ["Nimra Akram", "Atif Ahmad", "Sean B Maynard"], "title": "Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning", "comment": "10 pages", "summary": "The Advanced Dynamic Security Learning (DSL) Process Model is an Industry 4.0 cybersecurity incident response architecture proposed in this paper. This model addresses proactive and reflective cybersecurity governance across complex cyber-physical systems by combining Argyris and Schön's double-loop learning theory with Crossan's 4I organizational learning framework. Given that 65% of industrial companies suffer ransomware attacks annually and many of them lack cybersecurity awareness, this reveals the gravity of cyber threats. Feedforward and feedback learning loops in this paradigm help promote strategic transformation and ongoing growth. The DSL model helps Industry 4.0 organizations adapt to growing challenges posed by the projected 18.8 billion IoT devices by bridging operational obstacles and promoting systemic resilience. This research presents a scalable, methodical cybersecurity maturity approach based on a comprehensive analysis of the literature and a qualitative study."}
{"id": "2512.21827", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21827", "abs": "https://arxiv.org/abs/2512.21827", "authors": ["Xuanyu Chen", "Yue Zheng", "Junqing Zhang", "Guanxiong Shen", "Chip-Hong Chang"], "title": "Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment", "comment": null, "summary": "The Internet of Drones (IoD) is an emerging and crucial paradigm enabling advanced applications that require seamless, secure communication across heterogeneous and untrusted domains. In such environments, access control and the transmission of sensitive data pose significant security challenges for IoD systems, necessitating the design of lightweight mutual authentication and key exchange protocols. Existing solutions are often hampered by high computation overhead, reliance on third parties, the requirement for secret storage in resource-constrained drones, and the need for a strictly controlled enrollment environment. These limitations make them impractical for dynamic cross-domain deployment. To address these limitations, we propose a lightweight mutual authentication mechanism that integrates Radio Frequency Fingerprint (RFF) and Physical Unclonable Function (PUF) technologies for secure drone-to-drone (D2D) and drone-to-ground station server (D2G) communication. RFF-based device identification is used to achieve over-the-air (OTA) enrollment, while the PUF serves as the root of trust for establishing mutual authentication among communication parties. Additionally, the on-the-fly key generation capability of the PUF is co-designed with One-Time-Pad (OTP) encryption to realize ephemeral keying and eliminate the need for storing secrets within drones. Both informal security analysis and ProVerif-based formal security verification comprehensively demonstrate the resilience of our protocol against common security attacks. The proposed protocol also outperforms existing IoD authentication schemes in terms of security features, as well as computation, communication, and storage overhead."}
{"id": "2512.22060", "categories": ["cs.CR", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.22060", "abs": "https://arxiv.org/abs/2512.22060", "authors": ["Sunil Arora", "John Hastings"], "title": "Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management", "comment": "9 pages, 2 tables, 1 figure", "summary": "Natural Language Processing (NLP) systems are increasingly used in sensitive domains such as healthcare, finance, and government, where they handle large volumes of personal and regulated data. However, these systems introduce distinct risks related to security, privacy, and regulatory compliance that are not fully addressed by existing AI governance frameworks. This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a comprehensive six-phase model designed to ensure the secure operation of NLP systems from development to retirement. The framework, developed through a systematic PRISMA-based review of 45 peer-reviewed and regulatory sources, aligns with leading standards, including NIST AI RMF, ISO/IEC 42001:2023, the EU AI Act, and MITRE ATLAS. It integrates established methods for bias detection, privacy protection (differential privacy, federated learning), secure deployment, explainability, and secure model decommissioning. A healthcare case study illustrates how SC-NLP-LMF detects emerging terminology drift (e.g., COVID-related language) and guides compliant model updates. The framework offers organizations a practical, lifecycle-wide structure for developing, deploying, and maintaining secure and accountable NLP systems in high-risk environments."}
{"id": "2512.22076", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.22076", "abs": "https://arxiv.org/abs/2512.22076", "authors": ["Nir Somech", "Guy Katz"], "title": "ReSMT: An SMT-Based Tool for Reverse Engineering", "comment": null, "summary": "Software obfuscation techniques make code more difficult\n  to understand, without changing its functionality. Such techniques\n  are often used by authors of malicious software to avoid\n  detection. Reverse Engineering\n  of obfuscated code, i.e., the process of overcoming obfuscation and\n  answering questions about the functionality of the code, is\n  notoriously difficult; and while various tools and methods exist for\n  this purpose, the process remains complex and slow, especially when\n  dealing with layered or customized obfuscation techniques.\n  Here, we present a novel, automated tool for addressing some of the\n  challenges in reverse engineering of obfuscated code. Our tool,\n  called ReSMT, converts the obfuscated assembly code into a complex\n  system of logical assertions that represent the code functionality,\n  and then applies SMT solving and simulation tools to inspect the\n  obfuscated code's execution. The approach is mostly automatic,\n  alleviating the need for highly specialized deobfuscation skills.\n  In an elaborate case study that we conducted, ReSMT successfully\n  tackled complex obfuscated code, and was able to solve reverse-engineering\n  queries about it. We believe that these results showcase the potential\n  and usefulness of our proposed approach."}
{"id": "2512.22090", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.22090", "abs": "https://arxiv.org/abs/2512.22090", "authors": ["Quentin Michaud", "Sara Ramezanian", "Dhouha Ayed", "Olivier Levillain", "Joaquin Garcia-Alfaro"], "title": "Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge", "comment": null, "summary": "Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem."}
