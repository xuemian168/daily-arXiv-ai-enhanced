{"id": "2511.04707", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04707", "abs": "https://arxiv.org/abs/2511.04707", "authors": ["Rishi Rajesh Shah", "Chen Henry Wu", "Shashwat Saxena", "Ziqian Zhong", "Alexander Robey", "Aditi Raghunathan"], "title": "Jailbreaking in the Haystack", "comment": null, "summary": "Recent advances in long-context language models (LMs) have enabled\nmillion-token inputs, expanding their capabilities across complex tasks like\ncomputer-use agents. Yet, the safety implications of these extended contexts\nremain unclear. To bridge this gap, we introduce NINJA (short for\nNeedle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by\nappending benign, model-generated content to harmful user goals. Critical to\nour method is the observation that the position of harmful goals play an\nimportant role in safety. Experiments on standard safety benchmark, HarmBench,\nshow that NINJA significantly increases attack success rates across\nstate-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,\nand Gemini. Unlike prior jailbreaking methods, our approach is low-resource,\ntransferable, and less detectable. Moreover, we show that NINJA is\ncompute-optimal -- under a fixed compute budget, increasing context length can\noutperform increasing the number of trials in best-of-N jailbreak. These\nfindings reveal that even benign long contexts -- when crafted with careful\ngoal positioning -- introduce fundamental vulnerabilities in modern LMs.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04711", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04711", "abs": "https://arxiv.org/abs/2511.04711", "authors": ["Wenyuan Yang", "Yichen Sun", "Changzheng Chen", "Zhixuan Chu", "Jiaheng Zhang", "Yiming Li", "Dacheng Tao"], "title": "SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking", "comment": "The first two authors contributed equally to this work. 27 pages", "summary": "Large-scale vision-language models, especially CLIP, have demonstrated\nremarkable performance across diverse downstream tasks. Soft prompts, as\ncarefully crafted modules that efficiently adapt vision-language models to\nspecific tasks, necessitate effective copyright protection. In this paper, we\ninvestigate model copyright protection by auditing whether suspicious\nthird-party models incorporate protected soft prompts. While this can be viewed\nas a special case of model ownership auditing, our analysis shows that existing\ntechniques are ineffective due to prompt learning's unique characteristics.\nNon-intrusive auditing is inherently prone to false positives when independent\nmodels share similar data distributions with victim models. Intrusive\napproaches also fail: backdoor methods designed for CLIP cannot embed\nfunctional triggers, while extending traditional DNN backdoor techniques to\nprompt learning suffers from harmfulness and ambiguity challenges. We find that\nthese failures in intrusive auditing stem from the same fundamental reason:\nwatermarking operates within the same decision space as the primary task yet\npursues opposing objectives. Motivated by these findings, we propose sequential\nwatermarking for soft prompts (SWAP), which implants watermarks into a\ndifferent and more complex space. SWAP encodes watermarks through a specific\norder of defender-specified out-of-distribution classes, inspired by the\nzero-shot prediction capability of CLIP. This watermark, which is embedded in a\nmore complex space, keeps the original prediction label unchanged, making it\nless opposed to the primary task. We further design a hypothesis-test-guided\nverification protocol for SWAP and provide theoretical analyses of success\nconditions. Extensive experiments on 11 datasets demonstrate SWAP's\neffectiveness, harmlessness, and robustness against potential adaptive attacks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04716", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04716", "abs": "https://arxiv.org/abs/2511.04716", "authors": ["Mingliang Hou", "Yinuo Wang", "Teng Guo", "Zitao Liu", "Wenzhou Dou", "Jiaqi Zheng", "Renqiang Luo", "Mi Tian", "Weiqi Luo"], "title": "P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models", "comment": null, "summary": "Cognitive diagnosis models (CDMs) are pivotal for creating fine-grained\nlearner profiles in modern intelligent education platforms. However, these\nmodels are trained on sensitive student data, raising significant privacy\nconcerns. While membership inference attacks (MIA) have been studied in various\ndomains, their application to CDMs remains a critical research gap, leaving\ntheir privacy risks unquantified. This paper is the first to systematically\ninvestigate MIA against CDMs. We introduce a novel and realistic grey box\nthreat model that exploits the explainability features of these platforms,\nwhere a model's internal knowledge state vectors are exposed to users through\nvisualizations such as radar charts. We demonstrate that these vectors can be\naccurately reverse-engineered from such visualizations, creating a potent\nattack surface. Based on this threat model, we propose a profile-based MIA\n(P-MIA) framework that leverages both the model's final prediction\nprobabilities and the exposed internal knowledge state vectors as features.\nExtensive experiments on three real-world datasets against mainstream CDMs show\nthat our grey-box attack significantly outperforms standard black-box\nbaselines. Furthermore, we showcase the utility of P-MIA as an auditing tool by\nsuccessfully evaluating the efficacy of machine unlearning techniques and\nrevealing their limitations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04728", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04728", "abs": "https://arxiv.org/abs/2511.04728", "authors": ["Daniyal Ganiuly", "Assel Smaiyl"], "title": "Trustworthiness Calibration Framework for Phishing Email Detection Using Large Language Models", "comment": "10 pages, 5 figures", "summary": "Phishing emails continue to pose a persistent challenge to online\ncommunication, exploiting human trust and evading automated filters through\nrealistic language and adaptive tactics. While large language models (LLMs)\nsuch as GPT-4 and LLaMA-3-8B achieve strong accuracy in text classification,\ntheir deployment in security systems requires assessing reliability beyond\nbenchmark performance. To address this, this study introduces the\nTrustworthiness Calibration Framework (TCF), a reproducible methodology for\nevaluating phishing detectors across three dimensions: calibration,\nconsistency, and robustness. These components are integrated into a bounded\nindex, the Trustworthiness Calibration Index (TCI), and complemented by the\nCross-Dataset Stability (CDS) metric that quantifies stability of\ntrustworthiness across datasets. Experiments conducted on five corpora, such as\nSecureMail 2025, Phishing Validation 2024, CSDMC2010, Enron-Spam, and Nazario,\nusing DeBERTa-v3-base, LLaMA-3-8B, and GPT-4 demonstrate that GPT-4 achieves\nthe strongest overall trust profile, followed by LLaMA-3-8B and\nDeBERTa-v3-base. Statistical analysis confirms that reliability varies\nindependently of raw accuracy, underscoring the importance of trust-aware\nevaluation for real-world deployment. The proposed framework establishes a\ntransparent and reproducible foundation for assessing model dependability in\nLLM-based phishing detection.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04860", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04860", "abs": "https://arxiv.org/abs/2511.04860", "authors": ["Reworr", "Artem Petrov", "Dmitrii Volkov"], "title": "GPT-5 at CTFs: Case Studies From Top-Tier Cybersecurity Events", "comment": null, "summary": "OpenAI and DeepMind's AIs recently got gold at the IMO math olympiad and ICPC\nprogramming competition. We show frontier AI is similarly good at hacking by\nletting GPT-5 compete in elite CTF cybersecurity competitions.\n  In one of this year's hardest events, it outperformed 93% of humans finishing\n25th: between the world's #3-ranked team (24th place) and #7-ranked team (26th\nplace).\n  This report walks through our methodology, results, and their implications,\nand dives deep into 3 problems and solutions we found particularly interesting.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04882", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.04882", "abs": "https://arxiv.org/abs/2511.04882", "authors": ["Joon Kim", "Chengwei Duan", "Sandip Ray"], "title": "Bit-Flipping Attack Exploration and Countermeasure in 5G Network", "comment": "Presented at the IEEE MASS 2025 REUNS Workshop", "summary": "5G communication technology has become a vital component in a wide range of\napplications due to its unique advantages such as high data rate and low\nlatency. While much of the existing research has focused on optimizing its\nefficiency and performance, security considerations have not received\ncomparable attention, potentially leaving critical vulnerabilities unexplored.\nIn this work, we investigate the vulnerability of 5G systems to bit-flipping\nattacks, which is an integrity attack where an adversary intercepts 5G network\ntraffic and modifies specific fields of an encrypted message without\ndecryption, thus mutating the message while remaining valid to the receiver.\nNotably, these attacks do not require the attacker to know the plaintext, and\nonly the semantic meaning or position of certain fields would be enough to\neffect targeted modifications. We conduct our analysis on OpenAirInterface\n(OAI), an open-source 5G platform that follows the 3GPP Technical\nSpecifications, to rigorously test the real-world feasibility and impact of\nbit-flipping attacks under current 5G encryption mechanisms. Finally, we\npropose a keystream-based shuffling defense mechanism to mitigate the effect of\nsuch attacks by raising the difficulty of manipulating specific encrypted\nfields, while introducing no additional communication overhead compared to the\nNAS Integrity Algorithm (NIA) in 5G. Our findings reveal that enhancements to\n5G security are needed to better protect against attacks that alter data during\ntransmission at the network level.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04925", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04925", "abs": "https://arxiv.org/abs/2511.04925", "authors": ["Rethish Nair Rajendran", "Sathish Krishna Anumula", "Dileep Kumar Rai", "Sachin Agrawal"], "title": "Zero Trust Security Model Implementation in Microservices Architectures Using Identity Federation", "comment": null, "summary": "The microservice bombshells that have been linked with the microservice\nexpansion have altered the application architectures, offered agility and\nscalability in terms of complexity in security trade-offs. Feeble legacy-based\nperimeter-based policies are unable to offer safeguard to distributed workloads\nand temporary interaction among and in between the services. The article itself\nis a case on the need of the Zero Trust Security Model of micro services\necosystem, particularly, the fact that human and workloads require identity\nfederation. It is proposed that the solution framework will be based on\nindustry-standard authentication and authorization and end-to-end trust\nidentity technologies, including Authorization and OpenID connect (OIDC),\nAuthorization and OAuth 2.0 token exchange, and Authorization and SPIFFE/ SPIRE\nworkload identities. Experimental evaluation is a unique demonstration of a\nsuperior security position of making use of a smaller attack surface, harmony\npolicy enforcement, as well as interoperability across multi- domain\nenvironments. The research results overlay that the federated identity combined\nwith the Zero Trust basics not only guarantee the rules relating to\nauthentication and authorization but also fully complies with the latest\nDevSecOps standards of microservice deployment, which is automated, scaled, and\nresilient. The current project offers a stringent roadmap to the organizations\nthat desire to apply Zero Trust in cloud-native technologies but will as well\nguarantee adherence and interoperability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.04946", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04946", "abs": "https://arxiv.org/abs/2511.04946", "authors": ["Lei Chen", "Erci Xu", "Yiming Sun", "Shengyu Fan", "Xianglong Deng", "Guiming Shi", "Guang Fan", "Liang Kong", "Yilan Zhu", "Shoumeng Yan", "Mingzhe Zhang"], "title": "The Future of Fully Homomorphic Encryption System: from a Storage I/O Perspective", "comment": "https://link.springer.com/chapter/10.1007/978-981-95-1021-4_25", "summary": "Fully Homomorphic Encryption (FHE) allows computations to be performed on\nencrypted data, significantly enhancing user privacy. However, the I/O\nchallenges associated with deploying FHE applications remains understudied. We\nanalyze the impact of storage I/O on the performance of FHE applications and\nsummarize key lessons from the status quo. Key results include that storage I/O\ncan degrade the performance of ASICs by as much as 357$\\times$ and reduce GPUs\nperformance by up to 22$\\times$.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05097", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05097", "abs": "https://arxiv.org/abs/2511.05097", "authors": ["Romain Lefeuvre", "Charly Reux", "Stefano Zacchiroli", "Olivier Barais", "Benoit Combemale"], "title": "Chasing One-day Vulnerabilities Across Open Source Forks", "comment": null, "summary": "Tracking vulnerabilities inherited from third-party open-source components is\na well-known challenge, often addressed by tracing the threads of dependency\ninformation. However, vulnerabilities can also propagate through forking: a\nrepository forked after the introduction of a vulnerability, but before it is\npatched, may remain vulnerable in the fork well after being fixed in the\noriginal project. Current approaches for vulnerability analysis lack the\ncommit-level granularity needed to track vulnerability introductions and fixes\nacross forks, potentially leaving one-day vulnerabilities undetected. This\npaper presents a novel approach to help developers identify one-day\nvulnerabilities in forked repositories. Leveraging the global graph of public\ncode, as captured by the Software Heritage archive, the approach propagates\nvulnerability information at the commit level and performs automated impact\nanalysis. This enables automatic detection of forked projects that have not\nincorporated fixes, leaving them potentially vulnerable. Starting from 7162\nrepositories that, according to OSV, include vulnerable commits in their\ndevelopment histories, we identify 2.2 M forks, containing at least one\nvulnerable commit. Then we perform a strict filtering, allowing us to find 356\n___vulnerability, fork___ pairs impacting active and popular GitHub forks, we\nmanually evaluate 65 pairs, finding 3 high-severity vulnerabilities,\ndemonstrating the impact and applicability of this approach.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05100", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05100", "abs": "https://arxiv.org/abs/2511.05100", "authors": ["Arslan Mumtaz", "Mridula Singh"], "title": "TRICK: Time and Range Integrity ChecK using Low Earth Orbiting Satellite for Securing GNSS", "comment": null, "summary": "Global Navigation Satellite Systems (GNSS) provide Positioning, Navigation,\nand Timing (PNT) information to over 4 billion devices worldwide. Despite its\npervasive use in safety critical and high precision applications, GNSS remains\nvulnerable to spoofing attacks. Cryptographic enhancements, such as the use of\nTESLA protocol in Galileo, to provide navigation message authentication do not\nmitigate time of arrival manipulations. In this paper, we propose TRICK, a\nprimitive for secure positioning that closes this gap by introducing a\nfundamentally new approach that only requires two way communications with a\nsingle reference node along with multiple broadcast signals. Unlike classical\nVerifiable Multilateration (VM), which requires establishing two way\ncommunication with each reference nodes, our solution relies on only two\nmeasurements with a trusted Low Earth Orbiting (LEO) satellite and combines\nbroadcast navigation signals. We rigorously prove that combining the LEO\nsatellite based two way range measurements and multiple one way ranges such as\nfrom broadcast signals of GNSS into ellipsoidal constraint restores the same\nguarantees as offered by VM whilst using minimal infrastructure and message\nexchanges. Through detailed analysis, we show that our approach reliably\ndetects spoofing attempts while adding negligible computation overhead.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05102", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05102", "abs": "https://arxiv.org/abs/2511.05102", "authors": ["Disesdi Susanna Cox", "Niklas Bunzel"], "title": "Quantifying the Risk of Transferred Black Box Attacks", "comment": null, "summary": "Neural networks have become pervasive across various applications, including\nsecurity-related products. However, their widespread adoption has heightened\nconcerns regarding vulnerability to adversarial attacks. With emerging\nregulations and standards emphasizing security, organizations must reliably\nquantify risks associated with these attacks, particularly regarding\ntransferred adversarial attacks, which remain challenging to evaluate\naccurately. This paper investigates the complexities involved in resilience\ntesting against transferred adversarial attacks. Our analysis specifically\naddresses black-box evasion attacks, highlighting transfer-based attacks due to\ntheir practical significance and typically high transferability between neural\nnetwork models. We underline the computational infeasibility of exhaustively\nexploring high-dimensional input spaces to achieve complete test coverage. As a\nresult, comprehensive adversarial risk mapping is deemed impractical. To\nmitigate this limitation, we propose a targeted resilience testing framework\nthat employs surrogate models strategically selected based on Centered Kernel\nAlignment (CKA) similarity. By leveraging surrogate models exhibiting both high\nand low CKA similarities relative to the target model, the proposed approach\nseeks to optimize coverage of adversarial subspaces. Risk estimation is\nconducted using regression-based estimators, providing organizations with\nrealistic and actionable risk quantification.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05110", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.05110", "abs": "https://arxiv.org/abs/2511.05110", "authors": ["Xingzhi Zhang", "Buyi Lv", "Yimin Lu", "Kai Bu"], "title": "PhantomFetch: Obfuscating Loads against Prefetcher Side-Channel Attacks", "comment": null, "summary": "The IP-stride prefetcher has recently been exploited to leak secrets through\nside-channel attacks. It, however, cannot be simply disabled for security with\nprefetching speedup as a sacrifice. The state-of-the-art defense tries to\nretain the prefetching effect by hardware modification. In this paper, we\npresent PhantomFetch as the first prefetching-retentive and hardware-agnostic\ndefense. It avoids potential remanufacturing cost and enriches applicability to\noff-the-shelf devices. The key idea is to directly break the exploitable\ncoupling between trained prefetcher entries and the victim's secret-dependent\nloads by obfuscating the sensitive load effects of the victim. The experiment\nresults show that PhantomFetch can secure the IP-stride prefetcher with only\nnegligible overhead.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05111", "categories": ["cs.CR", "cs.IT", "math.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.05111", "abs": "https://arxiv.org/abs/2511.05111", "authors": ["Do Hyun Kim", "Ahmet Cetinkaya"], "title": "Confidentiality in a Card-Based Protocol Under Repeated Biased Shuffles", "comment": "17 pages, 2 figures", "summary": "In this paper, we provide a probabilistic analysis of the confidentiality in\na card-based protocol. We focus on Bert den Boer's original Five Card Trick to\ndevelop our approach. Five Card Trick was formulated as a secure two-party\ncomputation method, where two players use colored cards with identical backs to\ncalculate the logical AND operation on the bits that they choose. In this\nmethod, the players first arrange the cards privately, and then shuffle them\nthrough a random cut. Finally, they reveal the shuffled arrangement to\ndetermine the result of the operation. An unbiased random cut is essential to\nprevent players from exposing their chosen bits to each other. However, players\ntypically choose to move cards within the deck even though not moving any cards\nshould be equally likely. This unconscious behavior results in a biased,\nnonuniform shuffling-distribution in the sense that some arrangements of cards\nare slightly more probable after the cut. Such a nonuniform distribution\ncreates an opportunity for a malicious player to gain advantage in guessing the\nother player's choice. We provide the conditional probabilities of such guesses\nas a way to quantify the information leakage. Furthermore, we utilize the\neigenstructure of a Markov chain to derive tight bounds on the number of times\nthe biased random cuts must be repeated to reduce the leakage to an acceptable\nlevel. We also discuss the generalization of our approach to the setting where\nshuffling is conducted by a malicious player.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05119", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05119", "abs": "https://arxiv.org/abs/2511.05119", "authors": ["V\u00edctor Mayoral-Vilches", "Luis Javier Navarrete-Lozano", "Francesco Balassone", "Mar\u00eda Sanz-G\u00f3mez", "Crist\u00f3bal Ricardo Veas Ch\u00e1vez", "Maite del Mundo de Torres"], "title": "Cybersecurity AI in OT: Insights from an AI Top-10 Ranker in the Dragos OT CTF 2025", "comment": null, "summary": "Operational Technology (OT) cybersecurity increasingly relies on rapid\nresponse across malware analysis, network forensics, and reverse engineering\ndisciplines. We examine the performance of Cybersecurity AI (CAI), powered by\nthe \\texttt{alias1} model, during the Dragos OT CTF 2025 -- a 48-hour\nindustrial control system (ICS) competition with more than 1,000 teams. Using\nCAI telemetry and official leaderboard data, we quantify CAI's trajectory\nrelative to the leading human-operated teams. CAI reached Rank~1 between\ncompetition hours 7.0 and 8.0, crossed 10,000 points at 5.42~hours\n(1,846~pts/h), and completed 32 of the competition's 34 challenges before\nautomated operations were paused at hour~24 with a final score of 18,900 points\n(6th place). The top-3 human teams solved 33 of 34 challenges, collectively\nleaving only the 600-point ``Kiddy Tags -- 1'' unsolved; they were also the\nonly teams to clear the 1,000-point ``Moot Force'' binary. The top-5 human\nteams averaged 1,347~pts/h to the same milestone, marking a 37\\% velocity\nadvantage for CAI. We analyse time-resolved scoring, category coverage, and\nsolve cadence. The evidence indicates that a mission-configured AI agent can\nmatch or exceed expert human crews in early-phase OT incident response while\nremaining subject to practical limits in sustained, multi-day operations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05133", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.05133", "abs": "https://arxiv.org/abs/2511.05133", "authors": ["Urslla Uchechi Izuazu", "Mounir Bensalem", "Admela Jukan"], "title": "A Secured Intent-Based Networking (sIBN) with Data-Driven Time-Aware Intrusion Detection", "comment": "This paper is uploaded here for research community, thus it is for\n  non-commercial purposes", "summary": "While Intent-Based Networking (IBN) promises operational efficiency through\nautonomous and abstraction-driven network management, a critical unaddressed\nissue lies in IBN's implicit trust in the integrity of intent ingested by the\nnetwork. This inherent assumption of data reliability creates a blind spot\nexploitable by Man-in-the-Middle (MitM) attacks, where an adversary intercepts\nand alters intent before it is enacted, compelling the network to orchestrate\nmalicious configurations. This study proposes a secured IBN (sIBN) system with\ndata driven intrusion detection method designed to secure legitimate user\nintent from adversarial tampering. The proposed intent intrusion detection\nsystem uses a ML model applied for network behavioral anomaly detection to\nreveal temporal patterns of intent tampering. This is achieved by leveraging a\nset of original behavioral metrics and newly engineered time-aware features,\nwith the model's hyperparameters fine-tuned through the randomized search\ncross-validation (RSCV) technique. Numerical results based on real-world data\nsets, show the effectiveness of sIBN, achieving the best performance across\nstandard evaluation metrics, in both binary and multi classification tasks,\nwhile maintaining low error rates.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05156", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI", "C.2.3"], "pdf": "https://arxiv.org/pdf/2511.05156", "abs": "https://arxiv.org/abs/2511.05156", "authors": ["Azhar Hussain Mozumder", "M. John Basha", "Chayapathi A. R"], "title": "SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for Secure and Efficient Software-Defined Networks", "comment": "20 pages, 12 figures", "summary": "With more and more existing networks being transformed to Software-Defined\nNetworking (SDN), they need to be more secure and demand smarter ways of\ntraffic control. This work, SmartSecChain-SDN, is a platform that combines\nmachine learning based intrusion detection, blockchain-based storage of logs,\nand application-awareness-based priority in SDN networks. To detect network\nintrusions in a real-time, precision and low-false positives setup, the\nframework utilizes the application of advanced machine learning algorithms,\nnamely Random Forest, XGBoost, CatBoost, and CNN-BiLSTM. SmartSecChain-SDN is\nbased on the Hyperledger Fabric, which is a permissioned blockchain technology,\nto provide secure, scalable, and privacy-preserving storage and, thus,\nguarantee that the Intrusion Detection System (IDS) records cannot be altered\nand can be analyzed comprehensively. The system also has Quality of Service\n(QoS) rules and traffic shaping based on applications, which enables\nprioritization of critical services, such as VoIP, video conferencing, and\nbusiness applications, as well as de-prioritization of non-essential traffic,\nsuch as downloads and updates. Mininet can simulate real-time SDN scenarios\nbecause it is used to prototype whole architectures. It is also compatible with\ncontrollers OpenDaylight and Ryu. It has tested the framework using the InSDN\ndataset and proved that it can identify different kinds of cyberattacks and\nhandle bandwidth allocation efficiently under circumstances of resource\nconstraints. SmartSecChain-SDN comprehensively addresses SDN system protection,\nsecuring and enhancing. The proposed study offers an innovative, extensible way\nto improve cybersecurity, regulatory compliance, and the administration of\nnext-generation programmable networks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05193", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05193", "abs": "https://arxiv.org/abs/2511.05193", "authors": ["Zhibo Dong", "Yong Huang", "Shubao Sun", "Wentao Cui", "Zhihua Wang"], "title": "BLADE: Behavior-Level Anomaly Detection Using Network Traffic in Web Services", "comment": "Accepted by IEEE MSN 2025", "summary": "With their widespread popularity, web services have become the main targets\nof various cyberattacks. Existing traffic anomaly detection approaches focus on\nflow-level attacks, yet fail to recognize behavior-level attacks, which appear\nbenign in individual flows but reveal malicious purpose using multiple network\nflows. To transcend this limitation, we propose a novel unsupervised traffic\nanomaly detection system, BLADE, capable of detecting not only flow-level but\nalso behavior-level attacks in web services. Our key observation is that\napplication-layer operations of web services exhibit distinctive communication\npatterns at the network layer from a multi-flow perspective. BLADE first\nexploits a flow autoencoder to learn a latent feature representation and\ncalculates its reconstruction losses per flow. Then, the latent representation\nis assigned a pseudo operation label using an unsupervised clustering method.\nNext, an anomaly score is computed based on the reconstruction losses. Finally,\nthe triplets of timestamps, pseudo labels, and anomaly scores from multiple\nflows are aggregated and fed into a one-class classifier to characterize the\nbehavior patterns of legitimate web operations, enabling the detection of\nflow-level and behavior-level anomalies. BLADE is extensively evaluated on both\nthe custom dataset and the CIC-IDS2017 dataset. The experimental results\ndemonstrate BLADE's superior performance, achieving high F1 scores of 0.9732\nand 0.9801, respectively, on the two datasets, and outperforming traditional\nsingle-flow anomaly detection baselines.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05359", "categories": ["cs.CR", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.05359", "abs": "https://arxiv.org/abs/2511.05359", "authors": ["Amr Gomaa", "Ahmed Salem", "Sahar Abdelnabi"], "title": "ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations", "comment": null, "summary": "As language models evolve into autonomous agents that act and communicate on\nbehalf of users, ensuring safety in multi-agent ecosystems becomes a central\nchallenge. Interactions between personal assistants and external service\nproviders expose a core tension between utility and protection: effective\ncollaboration requires information sharing, yet every exchange creates new\nattack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating\nprivacy and security risks in agent-agent interactions. ConVerse spans three\npractical domains (travel, real estate, insurance) with 12 user personas and\nover 864 contextually grounded attacks (611 privacy, 253 security). Unlike\nprior single-agent settings, it models autonomous, multi-turn agent-to-agent\nconversations where malicious requests are embedded within plausible discourse.\nPrivacy is tested through a three-tier taxonomy assessing abstraction quality,\nwhile security attacks target tool use and preference manipulation. Evaluating\nseven state-of-the-art models reveals persistent vulnerabilities; privacy\nattacks succeed in up to 88% of cases and security breaches in up to 60%, with\nstronger models leaking more. By unifying privacy and security within\ninteractive multi-agent contexts, ConVerse reframes safety as an emergent\nproperty of communication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
