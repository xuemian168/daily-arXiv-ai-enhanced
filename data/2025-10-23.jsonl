{"id": "2510.18990", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.18990", "abs": "https://arxiv.org/abs/2510.18990", "authors": ["Thomas Hofweber", "Jefrey Bergl", "Ian Reyes", "Amir Sadovnik"], "title": "The Black Tuesday Attack: how to crash the stock market with adversarial examples to financial forecasting models", "comment": "15 pages, 2 figures", "summary": "We investigate and defend the possibility of causing a stock market crash via\nsmall manipulations of individual stock values that together realize an\nadversarial example to financial forecasting models, causing these models to\nmake the self-fulfilling prediction of a crash. Such a crash triggered by an\nadversarial example would likely be hard to detect, since the model's\npredictions would be accurate and the interventions that would cause it are\nminor. This possibility is a major risk to financial stability and an\nopportunity for hostile actors to cause great economic damage to an adversary.\nThis threat also exists against individual stocks and the corresponding\nvaluation of individual companies. We outline how such an attack might proceed,\nwhat its theoretical basis is, how it can be directed towards a whole economy\nor an individual company, and how one might defend against it. We conclude that\nthis threat is vastly underappreciated and requires urgent research on how to\ndefend against it."}
{"id": "2510.19026", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19026", "abs": "https://arxiv.org/abs/2510.19026", "authors": ["Behnam Rezaei Bezanjani", "Seyyed Hamid Ghafouri", "Reza Gholamrezaei"], "title": "Fusion of Machine Learning and Blockchain-based Privacy-Preserving Approach for Health Care Data in the Internet of Things", "comment": "28 pages", "summary": "In recent years, the rapid integration of Internet of Things (IoT) devices\ninto the healthcare sector has brought about revolutionary advancements in\npatient care and data management. While these technological innovations hold\nimmense promise, they concurrently raise critical security concerns,\nparticularly in safeguarding medical data against potential cyber threats. The\nsensitive nature of health-related information requires robust measures to\nensure the confidentiality, integrity, and availability of patient data in\nIoT-enabled medical environments. Addressing the imperative need for enhanced\nsecurity in IoT-based healthcare systems, we propose a comprehensive method\nencompassing three distinct phases. In the first phase, we implement\nBlockchain-Enabled Request and Transaction Encryption to strengthen data\ntransaction security, providing an immutable and transparent framework. In the\nsecond phase, we introduce a Request Pattern Recognition Check that leverages\ndiverse data sources to identify and block potential unauthorized access\nattempts. Finally, the third phase incorporates Feature Selection and a BiLSTM\nnetwork to enhance the accuracy and efficiency of intrusion detection using\nadvanced machine learning techniques. We compared the simulation results of the\nproposed method with three recent related methods: AIBPSF-IoMT, OMLIDS-PBIoT,\nand AIMMFIDS. The evaluation criteria include detection rate, false alarm rate,\nprecision, recall, and accuracy - crucial benchmarks for assessing the overall\nperformance of intrusion detection systems. Our findings show that the proposed\nmethod outperforms existing approaches across all evaluated criteria,\ndemonstrating its effectiveness in improving the security of IoT-based\nhealthcare systems."}
{"id": "2510.19121", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19121", "abs": "https://arxiv.org/abs/2510.19121", "authors": ["Behnam Seyedi", "Octavian Postolache"], "title": "Securing IoT Communications via Anomaly Traffic Detection: Synergy of Genetic Algorithm and Ensemble Method", "comment": "24 pages", "summary": "The rapid growth of the Internet of Things (IoT) has transformed industries\nby enabling seamless data exchange among connected devices. However, IoT\nnetworks remain vulnerable to security threats such as denial of service (DoS)\nattacks, anomalous traffic, and data manipulation due to decentralized\narchitectures and limited resources. To address these issues, this paper\nproposes an advanced anomaly detection framework with three main phases. First,\ndata preprocessing is performed using the Median KS Test to remove noise,\nhandle missing values, and balance datasets for cleaner input. Second, a\nfeature selection phase employs a Genetic Algorithm combined with eagle\ninspired search strategies to identify the most relevant features, reduce\ndimensionality, and improve efficiency without sacrificing accuracy. Finally,\nan ensemble classifier integrates Decision Tree, Random Forest, and XGBoost\nalgorithms to achieve accurate and reliable anomaly detection. The proposed\nmodel demonstrates high adaptability and scalability across diverse IoT\nenvironments. Experimental results show that it outperforms existing methods by\nachieving 98 percent accuracy, 95 percent detection rate, and reductions in\nfalse positive (10 percent) and false negative (5 percent) rates. These results\nconfirm the framework effectiveness and robustness in improving IoT network\nsecurity against evolving cyber threats."}
{"id": "2510.19145", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19145", "abs": "https://arxiv.org/abs/2510.19145", "authors": ["Sanskar Amgain", "Daniel Lobo", "Atri Chatterjee", "Swarup Bhunia", "Fnu Suya"], "title": "HAMLOCK: HArdware-Model LOgically Combined attacK", "comment": null, "summary": "The growing use of third-party hardware accelerators (e.g., FPGAs, ASICs) for\ndeep neural networks (DNNs) introduces new security vulnerabilities.\nConventional model-level backdoor attacks, which only poison a model's weights\nto misclassify inputs with a specific trigger, are often detectable because the\nentire attack logic is embedded within the model (i.e., software), creating a\ntraceable layer-by-layer activation path.\n  This paper introduces the HArdware-Model Logically Combined Attack (HAMLOCK),\na far stealthier threat that distributes the attack logic across the\nhardware-software boundary. The software (model) is now only minimally altered\nby tuning the activations of few neurons to produce uniquely high activation\nvalues when a trigger is present. A malicious hardware Trojan detects those\nunique activations by monitoring the corresponding neurons' most significant\nbit or the 8-bit exponents and triggers another hardware Trojan to directly\nmanipulate the final output logits for misclassification.\n  This decoupled design is highly stealthy, as the model itself contains no\ncomplete backdoor activation path as in conventional attacks and hence, appears\nfully benign. Empirically, across benchmarks like MNIST, CIFAR10, GTSRB, and\nImageNet, HAMLOCK achieves a near-perfect attack success rate with a negligible\nclean accuracy drop. More importantly, HAMLOCK circumvents the state-of-the-art\nmodel-level defenses without any adaptive optimization. The hardware Trojan is\nalso undetectable, incurring area and power overheads as low as 0.01%, which is\neasily masked by process and environmental noise. Our findings expose a\ncritical vulnerability at the hardware-software interface, demanding new\ncross-layer defenses against this emerging threat."}
{"id": "2510.19169", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19169", "abs": "https://arxiv.org/abs/2510.19169", "authors": ["Thomas Wang", "Haowen Li"], "title": "OpenGuardrails: An Open-Source Context-Aware AI Guardrails Platform", "comment": null, "summary": "As large language models (LLMs) become increasingly integrated into\nreal-world applications, safeguarding them against unsafe, malicious, or\nprivacy-violating content is critically important. We present OpenGuardrails,\nthe first open-source project to provide both a context-aware safety and\nmanipulation detection model and a deployable platform for comprehensive AI\nguardrails. OpenGuardrails protects against content-safety risks,\nmodel-manipulation attacks (e.g., prompt injection, jailbreaking,\ncode-interpreter abuse, and the generation/execution of malicious code), and\ndata leakage. Content-safety and model-manipulation detection are implemented\nby a unified large model, while data-leakage identification and redaction are\nperformed by a separate lightweight NER pipeline (e.g., Presidio-style models\nor regex-based detectors). The system can be deployed as a security gateway or\nan API-based service, with enterprise-grade, fully private deployment options.\nOpenGuardrails achieves state-of-the-art (SOTA) performance on safety\nbenchmarks, excelling in both prompt and response classification across\nEnglish, Chinese, and multilingual tasks. All models are released under the\nApache 2.0 license for public use."}
{"id": "2510.19207", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19207", "abs": "https://arxiv.org/abs/2510.19207", "authors": ["Yizhu Wang", "Sizhe Chen", "Raghad Alkhudair", "Basel Alomair", "David Wagner"], "title": "Defending Against Prompt Injection with DataFilter", "comment": null, "summary": "When large language model (LLM) agents are increasingly deployed to automate\ntasks and interact with untrusted external data, prompt injection emerges as a\nsignificant security threat. By injecting malicious instructions into the data\nthat LLMs access, an attacker can arbitrarily override the original user task\nand redirect the agent toward unintended, potentially harmful actions. Existing\ndefenses either require access to model weights (fine-tuning), incur\nsubstantial utility loss (detection-based), or demand non-trivial system\nredesign (system-level). Motivated by this, we propose DataFilter, a test-time\nmodel-agnostic defense that removes malicious instructions from the data before\nit reaches the backend LLM. DataFilter is trained with supervised fine-tuning\non simulated injections and leverages both the user's instruction and the data\nto selectively strip adversarial content while preserving benign information.\nAcross multiple benchmarks, DataFilter consistently reduces the prompt\ninjection attack success rates to near zero while maintaining the LLMs'\nutility. DataFilter delivers strong security, high utility, and plug-and-play\ndeployment, making it a strong practical defense to secure black-box commercial\nLLMs against prompt injection. Our DataFilter model is released at\nhttps://huggingface.co/JoyYizhu/DataFilter for immediate use, with the code to\nreproduce our results at https://github.com/yizhu-joy/DataFilter."}
{"id": "2510.19264", "categories": ["cs.CR", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19264", "abs": "https://arxiv.org/abs/2510.19264", "authors": ["R. Can Aygun", "Yehuda Afek", "Anat Bremler-Barr", "Leonard Kleinrock"], "title": "LAPRAD: LLM-Assisted PRotocol Attack Discovery", "comment": "IFIP Networking 2025 Proceedings (Accepted on 05.05.2025)", "summary": "With the goal of improving the security of Internet protocols, we seek\nfaster, semi-automatic methods to discover new vulnerabilities in protocols\nsuch as DNS, BGP, and others. To this end, we introduce the LLM-Assisted\nProtocol Attack Discovery (LAPRAD) methodology, enabling security researchers\nwith some DNS knowledge to efficiently uncover vulnerabilities that would\notherwise be hard to detect.\n  LAPRAD follows a three-stage process. In the first, we consult an LLM\n(GPT-o1) that has been trained on a broad corpus of DNS-related sources and\nprevious DDoS attacks to identify potential exploits. In the second stage, a\ndifferent LLM automatically constructs the corresponding attack configurations\nusing the ReACT approach implemented via LangChain (DNS zone file generation).\nFinally, in the third stage, we validate the attack's functionality and\neffectiveness.\n  Using LAPRAD, we uncovered three new DDoS attacks on the DNS protocol and\nrediscovered two recently reported ones that were not included in the LLM's\ntraining data. The first new attack employs a bait-and-switch technique to\ntrick resolvers into caching large, bogus DNSSEC RRSIGs, reducing their serving\ncapacity to as little as 6%. The second exploits large DNSSEC encryption\nalgorithms (RSA-4096) with multiple keys, thereby bypassing a recently\nimplemented default RRSet limit. The third leverages ANY-type responses to\nproduce a similar effect.\n  These variations of a cache-flushing DDoS attack, called SigCacheFlush,\ncircumvent existing patches, severely degrade resolver query capacity, and\nimpact the latest versions of major DNS resolver implementations."}
{"id": "2510.19295", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19295", "abs": "https://arxiv.org/abs/2510.19295", "authors": ["Konstantinos A. Lizos", "Leandros Maglaras", "Elena Petrovik", "Saied M. Abd El-atty", "Georgios Tsachtsiris", "Mohamed Amine Ferrag"], "title": "Reliability and Resilience of AI-Driven Critical Network Infrastructure under Cyber-Physical Threats", "comment": "11 pages", "summary": "The increasing reliance on AI-driven 5G/6G network infrastructures for\nmission-critical services highlights the need for reliability and resilience\nagainst sophisticated cyber-physical threats. These networks are highly exposed\nto novel attack surfaces due to their distributed intelligence, virtualized\nresources, and cross-domain integration. This paper proposes a fault-tolerant\nand resilience-aware framework that integrates AI-driven anomaly detection,\nadaptive routing, and redundancy mechanisms to mitigate cascading failures\nunder cyber-physical attack conditions. A comprehensive validation is carried\nout using NS-3 simulations, where key performance indicators such as\nreliability, latency, resilience index, and packet loss rate are analyzed under\nvarious attack scenarios. The deduced results demonstrate that the proposed\nframework significantly improves fault recovery, stabilizes packet delivery,\nand reduces service disruption compared to baseline approaches."}
{"id": "2510.19300", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19300", "abs": "https://arxiv.org/abs/2510.19300", "authors": ["Abdollah Rahimi", "Mehdi Jafari Shahbazzadeh", "Amid Khatibi"], "title": "An Adaptive Intelligent Thermal-Aware Routing Protocol for Wireless Body Area Networks", "comment": null, "summary": "Wireless Body Area Networks (WBANs) have gained significant attention due to\ntheir applications in healthcare monitoring, sports, military communication,\nand remote patient care. These networks consist of wearable or implanted\nsensors that continuously collect and transmit physiological data, requiring\nefficient and reliable communication. However, WBANs face challenges such as\nlimited energy, dynamic topology, and sensitivity to node temperature, which\ndemand specialized routing strategies. Traditional shortest-path routing often\ncauses congestion and overheating in specific nodes, leading to early failures.\nTo address these problems, this paper proposes an intelligent temperature-aware\nand reliability-based routing approach that enhances WBAN performance. The\nproposed method works in two phases: (1) network setup and intelligent path\nselection, and (2) dynamic traffic management and hotspot avoidance. In the\nfirst phase, nodes share information such as residual energy, temperature, link\nreliability, and delay to build an optimized topology using a multi-criteria\ndecision algorithm. The second phase continuously monitors real-time conditions\nand reroutes traffic away from overheated or depleted nodes. Simulation results\nshow that the proposed approach improves throughput by 13 percent, reduces\nend-to-end delay by 10 percent, decreases energy consumption by 25 percent, and\nlowers routing load by 30 percent compared to existing methods."}
{"id": "2510.19303", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19303", "abs": "https://arxiv.org/abs/2510.19303", "authors": ["Petar Radanliev"], "title": "Collaborative penetration testing suite for emerging generative AI algorithms", "comment": null, "summary": "Problem Space: AI Vulnerabilities and Quantum Threats Generative AI\nvulnerabilities: model inversion, data poisoning, adversarial inputs. Quantum\nthreats Shor Algorithm breaking RSA ECC encryption. Challenge Secure generative\nAI models against classical and quantum cyberattacks. Proposed Solution\nCollaborative Penetration Testing Suite Five Integrated Components: DAST SAST\nOWASP ZAP, Burp Suite, SonarQube, Fortify. IAST Contrast Assess integrated with\nCI CD pipeline. Blockchain Logging Hyperledger Fabric for tamper-proof logs.\nQuantum Cryptography Lattice based RLWE protocols. AI Red Team Simulations\nAdversarial ML & Quantum-assisted attacks. Integration Layer: Unified workflow\nfor AI, cybersecurity, and quantum experts. Key Results 300+ vulnerabilities\nidentified across test environments. 70% reduction in high-severity issues\nwithin 2 weeks. 90% resolution efficiency for blockchain-logged\nvulnerabilities. Quantum-resistant cryptography maintained 100% integrity in\ntests. Outcome: Quantum AI Security Protocol integrating Blockchain Quantum\nCryptography AI Red Teaming."}
{"id": "2510.19324", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19324", "abs": "https://arxiv.org/abs/2510.19324", "authors": ["Loay Abdelrazek", "Leyli Kara√ßay", "Marin Orlic"], "title": "Authorization of Knowledge-base Agents in an Intent-based Management Function", "comment": null, "summary": "As networks move toward the next-generation 6G, Intent-based Management (IbM)\nsystems are increasingly adopted to simplify and automate network management by\ntranslating high-level intents into low-level configurations. Within these\nsystems, agents play a critical role in monitoring current state of the\nnetwork, gathering data, and enforcing actions across the network to fulfill\nthe intent. However, ensuring secure and fine-grained authorization of agents\nremains a significant challenge, especially in dynamic and multi-tenant\nenvironments. Traditional models such as Role-Based Access Control (RBAC),\nAttribute-Based Access Control (ABAC) and Relational-Based Access Control\n(RelBAC) often lack the flexibility to accommodate the evolving context and\ngranularity required by intentbased operations. In this paper, we propose an\nenhanced authorization framework that integrates contextual and functional\nattributes with agent roles to achieve dynamic, policy-driven access control.\nBy analyzing agent functionalities, our approach ensures that agents are\ngranted only the minimal necessary privileges towards knowledge graphs."}
{"id": "2510.19390", "categories": ["cs.CR", "cs.ET", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19390", "abs": "https://arxiv.org/abs/2510.19390", "authors": ["Max O. Al-Hasso", "Marko von der Leyen"], "title": "A Probabilistic Computing Approach to the Closest Vector Problem for Lattice-Based Factoring", "comment": "18 pages, 5 figures", "summary": "The closest vector problem (CVP) is a fundamental optimization problem in\nlattice-based cryptography and its conjectured hardness underpins the security\nof lattice-based cryptosystems. Furthermore, Schnorr's lattice-based factoring\nalgorithm reduces integer factoring (the foundation of current cryptosystems,\nincluding RSA) to the CVP. Recent work has investigated the inclusion of a\nheuristic CVP approximation `refinement' step in the lattice-based factoring\nalgorithm, using quantum variational algorithms to perform the heuristic\noptimization. This coincides with the emergence of probabilistic computing as a\nhardware accelerator for randomized algorithms including tasks in combinatorial\noptimization. In this work we investigate the application of probabilistic\ncomputing to the heuristic optimization task of CVP approximation refinement in\nlattice-based factoring. We present the design of a probabilistic computing\nalgorithm for this task, a discussion of `prime lattice' parameters, and\nexperimental results showing the efficacy of probabilistic computing for\nsolving the CVP as well as its efficacy as a subroutine for lattice-based\nfactoring. The main results found that (a) this approach is capable of finding\nthe maximal available CVP approximation refinement in time linear in problem\nsize and (b) probabilistic computing used in conjunction with the lattice\nparameters presented can find the composite prime factors of a semiprime number\nusing up to 100x fewer lattice instances than similar quantum and classical\nmethods."}
{"id": "2510.19418", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19418", "abs": "https://arxiv.org/abs/2510.19418", "authors": ["Mete Harun Akcay", "Buse Gul Atli", "Siddharth Prakash Rao", "Alexandros Bakas"], "title": "From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data", "comment": "10 pages, 3 figures, 6 tables. In submission", "summary": "As the volume of stored data continues to grow, identifying and protecting\nsensitive information within large repositories becomes increasingly\nchallenging, especially when shared with multiple users with different roles\nand permissions. This work presents a system architecture for trusted data\nsharing with policy-driven access control, enabling selective protection of\nsensitive regions while maintaining scalability. The proposed architecture\nintegrates four core modules that combine automated detection of sensitive\nregions, post-correction, key management, and access control. Sensitive regions\nare secured using a hybrid scheme that employs symmetric encryption for\nefficiency and Attribute-Based Encryption for policy enforcement. The system\nsupports efficient key distribution and isolates key storage to strengthen\noverall security. To demonstrate its applicability, we evaluate the system on\nvisual datasets, where Privacy-Sensitive Objects in images are automatically\ndetected, reassessed, and selectively encrypted prior to sharing in a data\nrepository. Experimental results show that our system provides effective PSO\ndetection, increases macro-averaged F1 score (5%) and mean Average Precision\n(10%), and maintains an average policy-enforced decryption time of less than 1\nsecond per image. These results demonstrate the effectiveness, efficiency and\nscalability of our proposed solution for fine-grained access control."}
{"id": "2510.19420", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.MA", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19420", "abs": "https://arxiv.org/abs/2510.19420", "authors": ["Chengcan Wu", "Zhixin Zhang", "Mingqian Xu", "Zeming Wei", "Meng Sun"], "title": "Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation", "comment": null, "summary": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) have become a\npopular paradigm of AI applications. However, trustworthiness issues in MAS\nremain a critical concern. Unlike challenges in single-agent systems, MAS\ninvolve more complex communication processes, making them susceptible to\ncorruption attacks. To mitigate this issue, several defense mechanisms have\nbeen developed based on the graph representation of MAS, where agents represent\nnodes and communications form edges. Nevertheless, these methods predominantly\nfocus on static graph defense, attempting to either detect attacks in a fixed\ngraph structure or optimize a static topology with certain defensive\ncapabilities. To address this limitation, we propose a dynamic defense paradigm\nfor MAS graph structures, which continuously monitors communication within the\nMAS graph, then dynamically adjusts the graph topology, accurately disrupts\nmalicious communications, and effectively defends against evolving and diverse\ndynamic attacks. Experimental results in increasingly complex and dynamic MAS\nenvironments demonstrate that our method significantly outperforms existing MAS\ndefense mechanisms, contributing an effective guardrail for their trustworthy\napplications. Our code is available at\nhttps://github.com/ChengcanWu/Monitoring-LLM-Based-Multi-Agent-Systems."}
{"id": "2510.19440", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19440", "abs": "https://arxiv.org/abs/2510.19440", "authors": ["Rundong Jiang", "Jun Hu", "Zhiyuan Xie", "Yunqi Song", "Shiyou Xu"], "title": "Transmitter Identification via Volterra Series Based Radio Frequency Fingerprint", "comment": null, "summary": "The growing number of wireless devices increases the need for secure network\naccess. Radio Frequency Fingerprinting (RFF), a physical-layer authentication\nmethod, offers a promising solution as it requires no cryptography and resists\nspoofing. However, existing RFF approaches often lack a unified theory and\neffective feature extraction. Many methods use handcrafted signal features or\ndirect neural network classification, leading to limited generalization and\ninterpretability. In this work, we model the transmitter as a black box and\nanalyze its impact on transmitted signals. By treating the deviation from an\nideal signal as hardware-induced distortion, we represent the received signal\nusing a Volterra series, using its kernels to capture linear and nonlinear\nhardware traits. To manage the high dimensionality of these kernels, we\napproximate them via wavelet decomposition and estimate coefficients through\nleast-squares fitting. The resulting wavelet coefficients provide compact yet\ninformative hardware representations, which are classified using a\ncomplex-valued neural network. Experiments on a public LoRa dataset show\nstate-of-the-art performance, with over 98% accuracy in static channels and\nabove 90% under multipath and Doppler effects. The proposed approach improves\nboth interpretability and generalization across varying channel conditions."}
{"id": "2510.19462", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19462", "abs": "https://arxiv.org/abs/2510.19462", "authors": ["Zhonghao Zhan", "Amir Al Sadi", "Krinos Li", "Hamed Haddadi"], "title": "AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices", "comment": null, "summary": "In this work, we study security of Model Context Protocol (MCP) agent\ntoolchains and their applications in smart homes. We introduce AegisMCP, a\nprotocol-level intrusion detector. Our contributions are: (i) a minimal attack\nsuite spanning instruction-driven escalation, chain-of-tool exfiltration,\nmalicious MCP server registration, and persistence; (ii) NEBULA-Schema\n(Network-Edge Behavioral Learning for Untrusted LLM Agents), a reusable\nprotocol-level instrumentation that represents MCP activity as a streaming\nheterogeneous temporal graph over agents, MCP servers, tools, devices, remotes,\nand sessions; and (iii) a CPU-only streaming detector that fuses novelty,\nsession-DAG structure, and attribute cues for near-real-time edge inference,\nwith optional fusion of local prompt-guardrail signals. On an emulated\nsmart-home testbed spanning multiple MCP stacks and a physical bench, AegisMCP\nachieves sub-second per-window model inference and end-to-end alerting. The\nlatency of AegisMCP is consistently sub-second on Intel N150-class edge\nhardware, while outperforming traffic-only and sequence baselines; ablations\nconfirm the importance of DAG and install/permission signals. We release code,\nschemas, and generators for reproducible evaluation."}
{"id": "2510.19491", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19491", "abs": "https://arxiv.org/abs/2510.19491", "authors": ["Jonas Gebele", "Timm Mutzel", "Burak Oez", "Florian Matthes"], "title": "Cross-Chain Sealed-Bid Auctions Using Confidential Compute Blockchains", "comment": null, "summary": "Sealed-bid auctions ensure fair competition and efficient allocation but are\noften deployed on centralized infrastructure, enabling opaque manipulation.\nPublic blockchains eliminate central control, yet their inherent transparency\nconflicts with the confidentiality required for sealed bidding. Prior attempts\nstruggle to reconcile privacy, verifiability, and scalability without relying\non trusted intermediaries, multi-round protocols, or expensive cryptography. We\npresent a sealed-bid auction protocol that executes sensitive bidding logic on\na Trusted Execution Environment (TEE)-backed confidential compute blockchain\nwhile retaining settlement and enforcement on a public chain. Bidders commit\nfunds to enclave-generated escrow addresses, ensuring confidentiality and\nbinding commitments. After the deadline, any party can trigger resolution: the\nconfidential blockchain determines the winner through verifiable off-chain\ncomputation and issues signed settlement transactions for execution on the\npublic chain. Our design provides security, privacy, and scalability without\ntrusted third parties or protocol modifications. We implement it on SUAVE with\nEthereum settlement, evaluate its scalability and trust assumptions, and\ndemonstrate deployment with minimal integration on existing infrastructure"}
{"id": "2510.19537", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19537", "abs": "https://arxiv.org/abs/2510.19537", "authors": ["Mahitha Pulivathi"], "title": "Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption Parameter Optimisation", "comment": null, "summary": "Deep learning is widely applied to modern problems through neural networks,\nbut the growing computational and energy demands of these models have driven\ninterest in more efficient approaches. Spiking Neural Networks (SNNs), the\nthird generation of neural networks, mimic the brain's event-driven behaviour,\noffering improved performance and reduced power use. At the same time, concerns\nabout data privacy during cloud-based model execution have led to the adoption\nof cryptographic methods. This article introduces BioEncryptSNN, a spiking\nneural network based encryption-decryption framework for secure and\nnoise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN\nconverts ciphertext into spike trains and exploits temporal neural dynamics to\nmodel encryption and decryption, optimising parameters such as key length,\nspike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048,\nand DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x\nfaster encryption and decryption than PyCryptodome's AES implementation. The\nframework demonstrates scalability and adaptability across symmetric and\nasymmetric ciphers, positioning SNNs as a promising direction for secure,\nenergy-efficient computing."}
{"id": "2510.19676", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19676", "abs": "https://arxiv.org/abs/2510.19676", "authors": ["Nowfel Mashnoor", "Mohammad Akyash", "Hadi Kamali", "Kimia Azar"], "title": "CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage", "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in generative\ntasks, including register-transfer level (RTL) hardware synthesis. However,\ntheir tendency to memorize training data poses critical risks when proprietary\nor security-sensitive designs are unintentionally exposed during inference.\nWhile prior work has examined memorization in natural language, RTL introduces\nunique challenges: In RTL, structurally different implementations (e.g.,\nbehavioral vs. gate-level descriptions) can realize the same hardware, leading\nto intellectual property (IP) leakage (full or partial) even without verbatim\noverlap. Conversely, even small syntactic variations (e.g., operator precedence\nor blocking vs. non-blocking assignments) can drastically alter circuit\nbehavior, making correctness preservation especially challenging. In this work,\nwe systematically study memorization in RTL code generation and propose\nCircuitGuard, a defense strategy that balances leakage reduction with\ncorrectness preservation. CircuitGuard (1) introduces a novel RTL-aware\nsimilarity metric that captures both structural and functional equivalence\nbeyond surface-level overlap, and (2) develops an activation-level steering\nmethod that identifies and attenuates transformer components most responsible\nfor memorization. Our empirical evaluation demonstrates that CircuitGuard\nidentifies (and isolates) 275 memorization-critical features across layers\n18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic\nsimilarity to proprietary patterns while maintaining generation quality.\nCircuitGuard further shows 78-85% cross-domain transfer effectiveness, enabling\nrobust memorization mitigation across circuit categories without retraining."}
{"id": "2510.19761", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19761", "abs": "https://arxiv.org/abs/2510.19761", "authors": ["Mohamed ElShehaby", "Ashraf Matrawy"], "title": "Exploring the Effect of DNN Depth on Adversarial Attacks in Network Intrusion Detection Systems", "comment": null, "summary": "Adversarial attacks pose significant challenges to Machine Learning (ML)\nsystems and especially Deep Neural Networks (DNNs) by subtly manipulating\ninputs to induce incorrect predictions. This paper investigates whether\nincreasing the layer depth of deep neural networks affects their robustness\nagainst adversarial attacks in the Network Intrusion Detection System (NIDS)\ndomain. We compare the adversarial robustness of various deep neural networks\nacross both \\ac{NIDS} and computer vision domains (the latter being widely used\nin adversarial attack experiments). Our experimental results reveal that in the\nNIDS domain, adding more layers does not necessarily improve their performance,\nyet it may actually significantly degrade their robustness against adversarial\nattacks. Conversely, in the computer vision domain, adding more layers exhibits\na more modest impact on robustness. These findings can guide the development of\nrobust neural networks for (NIDS) applications and highlight the unique\ncharacteristics of network security domains within the (ML) landscape."}
{"id": "2510.19772", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19772", "abs": "https://arxiv.org/abs/2510.19772", "authors": ["Jad Zarzour", "Matthew Jablonski"], "title": "Under Pressure: Security Analysis and Process Impacts of a Commercial Smart Air Compressor", "comment": null, "summary": "The integration of Industrial Internet of Things (IIoT) devices into\nmanufacturing environments has accelerated the transition to Industry 4.0, but\nhas also introduced new cybersecurity risks. This paper conducts a\ncomprehensive security analysis of a commercial smart air compressor, revealing\ncritical vulnerabilities including hardcoded credentials, unauthenticated APIs,\nand an insecure update mechanism. It includes a formal threat model,\ndemonstrates practical attack scenarios in a testbed environment, and evaluates\ntheir subsequent impact on an industrial process, leading to denial of service\nand the corruption of critical process telemetry. In addition, an analysis of\nthe device's supply chain reveals how product integration from multiple vendors\nand limited security considerations can expose a device to threats. The\nfindings underscore the necessity of incorporating cybersecurity principles\ninto both IIoT device design and supply chain governance to enhance resilience\nagainst emerging industrial cyber threats."}
