<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 21]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [The Black Tuesday Attack: how to crash the stock market with adversarial examples to financial forecasting models](https://arxiv.org/abs/2510.18990)
*Thomas Hofweber,Jefrey Bergl,Ian Reyes,Amir Sadovnik*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate and defend the possibility of causing a stock market crash via
small manipulations of individual stock values that together realize an
adversarial example to financial forecasting models, causing these models to
make the self-fulfilling prediction of a crash. Such a crash triggered by an
adversarial example would likely be hard to detect, since the model's
predictions would be accurate and the interventions that would cause it are
minor. This possibility is a major risk to financial stability and an
opportunity for hostile actors to cause great economic damage to an adversary.
This threat also exists against individual stocks and the corresponding
valuation of individual companies. We outline how such an attack might proceed,
what its theoretical basis is, how it can be directed towards a whole economy
or an individual company, and how one might defend against it. We conclude that
this threat is vastly underappreciated and requires urgent research on how to
defend against it.

</details>


### [2] [Fusion of Machine Learning and Blockchain-based Privacy-Preserving Approach for Health Care Data in the Internet of Things](https://arxiv.org/abs/2510.19026)
*Behnam Rezaei Bezanjani,Seyyed Hamid Ghafouri,Reza Gholamrezaei*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent years, the rapid integration of Internet of Things (IoT) devices
into the healthcare sector has brought about revolutionary advancements in
patient care and data management. While these technological innovations hold
immense promise, they concurrently raise critical security concerns,
particularly in safeguarding medical data against potential cyber threats. The
sensitive nature of health-related information requires robust measures to
ensure the confidentiality, integrity, and availability of patient data in
IoT-enabled medical environments. Addressing the imperative need for enhanced
security in IoT-based healthcare systems, we propose a comprehensive method
encompassing three distinct phases. In the first phase, we implement
Blockchain-Enabled Request and Transaction Encryption to strengthen data
transaction security, providing an immutable and transparent framework. In the
second phase, we introduce a Request Pattern Recognition Check that leverages
diverse data sources to identify and block potential unauthorized access
attempts. Finally, the third phase incorporates Feature Selection and a BiLSTM
network to enhance the accuracy and efficiency of intrusion detection using
advanced machine learning techniques. We compared the simulation results of the
proposed method with three recent related methods: AIBPSF-IoMT, OMLIDS-PBIoT,
and AIMMFIDS. The evaluation criteria include detection rate, false alarm rate,
precision, recall, and accuracy - crucial benchmarks for assessing the overall
performance of intrusion detection systems. Our findings show that the proposed
method outperforms existing approaches across all evaluated criteria,
demonstrating its effectiveness in improving the security of IoT-based
healthcare systems.

</details>


### [3] [Securing IoT Communications via Anomaly Traffic Detection: Synergy of Genetic Algorithm and Ensemble Method](https://arxiv.org/abs/2510.19121)
*Behnam Seyedi,Octavian Postolache*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid growth of the Internet of Things (IoT) has transformed industries
by enabling seamless data exchange among connected devices. However, IoT
networks remain vulnerable to security threats such as denial of service (DoS)
attacks, anomalous traffic, and data manipulation due to decentralized
architectures and limited resources. To address these issues, this paper
proposes an advanced anomaly detection framework with three main phases. First,
data preprocessing is performed using the Median KS Test to remove noise,
handle missing values, and balance datasets for cleaner input. Second, a
feature selection phase employs a Genetic Algorithm combined with eagle
inspired search strategies to identify the most relevant features, reduce
dimensionality, and improve efficiency without sacrificing accuracy. Finally,
an ensemble classifier integrates Decision Tree, Random Forest, and XGBoost
algorithms to achieve accurate and reliable anomaly detection. The proposed
model demonstrates high adaptability and scalability across diverse IoT
environments. Experimental results show that it outperforms existing methods by
achieving 98 percent accuracy, 95 percent detection rate, and reductions in
false positive (10 percent) and false negative (5 percent) rates. These results
confirm the framework effectiveness and robustness in improving IoT network
security against evolving cyber threats.

</details>


### [4] [HAMLOCK: HArdware-Model LOgically Combined attacK](https://arxiv.org/abs/2510.19145)
*Sanskar Amgain,Daniel Lobo,Atri Chatterjee,Swarup Bhunia,Fnu Suya*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The growing use of third-party hardware accelerators (e.g., FPGAs, ASICs) for
deep neural networks (DNNs) introduces new security vulnerabilities.
Conventional model-level backdoor attacks, which only poison a model's weights
to misclassify inputs with a specific trigger, are often detectable because the
entire attack logic is embedded within the model (i.e., software), creating a
traceable layer-by-layer activation path.
  This paper introduces the HArdware-Model Logically Combined Attack (HAMLOCK),
a far stealthier threat that distributes the attack logic across the
hardware-software boundary. The software (model) is now only minimally altered
by tuning the activations of few neurons to produce uniquely high activation
values when a trigger is present. A malicious hardware Trojan detects those
unique activations by monitoring the corresponding neurons' most significant
bit or the 8-bit exponents and triggers another hardware Trojan to directly
manipulate the final output logits for misclassification.
  This decoupled design is highly stealthy, as the model itself contains no
complete backdoor activation path as in conventional attacks and hence, appears
fully benign. Empirically, across benchmarks like MNIST, CIFAR10, GTSRB, and
ImageNet, HAMLOCK achieves a near-perfect attack success rate with a negligible
clean accuracy drop. More importantly, HAMLOCK circumvents the state-of-the-art
model-level defenses without any adaptive optimization. The hardware Trojan is
also undetectable, incurring area and power overheads as low as 0.01%, which is
easily masked by process and environmental noise. Our findings expose a
critical vulnerability at the hardware-software interface, demanding new
cross-layer defenses against this emerging threat.

</details>


### [5] [OpenGuardrails: An Open-Source Context-Aware AI Guardrails Platform](https://arxiv.org/abs/2510.19169)
*Thomas Wang,Haowen Li*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As large language models (LLMs) become increasingly integrated into
real-world applications, safeguarding them against unsafe, malicious, or
privacy-violating content is critically important. We present OpenGuardrails,
the first open-source project to provide both a context-aware safety and
manipulation detection model and a deployable platform for comprehensive AI
guardrails. OpenGuardrails protects against content-safety risks,
model-manipulation attacks (e.g., prompt injection, jailbreaking,
code-interpreter abuse, and the generation/execution of malicious code), and
data leakage. Content-safety and model-manipulation detection are implemented
by a unified large model, while data-leakage identification and redaction are
performed by a separate lightweight NER pipeline (e.g., Presidio-style models
or regex-based detectors). The system can be deployed as a security gateway or
an API-based service, with enterprise-grade, fully private deployment options.
OpenGuardrails achieves state-of-the-art (SOTA) performance on safety
benchmarks, excelling in both prompt and response classification across
English, Chinese, and multilingual tasks. All models are released under the
Apache 2.0 license for public use.

</details>


### [6] [Defending Against Prompt Injection with DataFilter](https://arxiv.org/abs/2510.19207)
*Yizhu Wang,Sizhe Chen,Raghad Alkhudair,Basel Alomair,David Wagner*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When large language model (LLM) agents are increasingly deployed to automate
tasks and interact with untrusted external data, prompt injection emerges as a
significant security threat. By injecting malicious instructions into the data
that LLMs access, an attacker can arbitrarily override the original user task
and redirect the agent toward unintended, potentially harmful actions. Existing
defenses either require access to model weights (fine-tuning), incur
substantial utility loss (detection-based), or demand non-trivial system
redesign (system-level). Motivated by this, we propose DataFilter, a test-time
model-agnostic defense that removes malicious instructions from the data before
it reaches the backend LLM. DataFilter is trained with supervised fine-tuning
on simulated injections and leverages both the user's instruction and the data
to selectively strip adversarial content while preserving benign information.
Across multiple benchmarks, DataFilter consistently reduces the prompt
injection attack success rates to near zero while maintaining the LLMs'
utility. DataFilter delivers strong security, high utility, and plug-and-play
deployment, making it a strong practical defense to secure black-box commercial
LLMs against prompt injection. Our DataFilter model is released at
https://huggingface.co/JoyYizhu/DataFilter for immediate use, with the code to
reproduce our results at https://github.com/yizhu-joy/DataFilter.

</details>


### [7] [LAPRAD: LLM-Assisted PRotocol Attack Discovery](https://arxiv.org/abs/2510.19264)
*R. Can Aygun,Yehuda Afek,Anat Bremler-Barr,Leonard Kleinrock*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the goal of improving the security of Internet protocols, we seek
faster, semi-automatic methods to discover new vulnerabilities in protocols
such as DNS, BGP, and others. To this end, we introduce the LLM-Assisted
Protocol Attack Discovery (LAPRAD) methodology, enabling security researchers
with some DNS knowledge to efficiently uncover vulnerabilities that would
otherwise be hard to detect.
  LAPRAD follows a three-stage process. In the first, we consult an LLM
(GPT-o1) that has been trained on a broad corpus of DNS-related sources and
previous DDoS attacks to identify potential exploits. In the second stage, a
different LLM automatically constructs the corresponding attack configurations
using the ReACT approach implemented via LangChain (DNS zone file generation).
Finally, in the third stage, we validate the attack's functionality and
effectiveness.
  Using LAPRAD, we uncovered three new DDoS attacks on the DNS protocol and
rediscovered two recently reported ones that were not included in the LLM's
training data. The first new attack employs a bait-and-switch technique to
trick resolvers into caching large, bogus DNSSEC RRSIGs, reducing their serving
capacity to as little as 6%. The second exploits large DNSSEC encryption
algorithms (RSA-4096) with multiple keys, thereby bypassing a recently
implemented default RRSet limit. The third leverages ANY-type responses to
produce a similar effect.
  These variations of a cache-flushing DDoS attack, called SigCacheFlush,
circumvent existing patches, severely degrade resolver query capacity, and
impact the latest versions of major DNS resolver implementations.

</details>


### [8] [Reliability and Resilience of AI-Driven Critical Network Infrastructure under Cyber-Physical Threats](https://arxiv.org/abs/2510.19295)
*Konstantinos A. Lizos,Leandros Maglaras,Elena Petrovik,Saied M. Abd El-atty,Georgios Tsachtsiris,Mohamed Amine Ferrag*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The increasing reliance on AI-driven 5G/6G network infrastructures for
mission-critical services highlights the need for reliability and resilience
against sophisticated cyber-physical threats. These networks are highly exposed
to novel attack surfaces due to their distributed intelligence, virtualized
resources, and cross-domain integration. This paper proposes a fault-tolerant
and resilience-aware framework that integrates AI-driven anomaly detection,
adaptive routing, and redundancy mechanisms to mitigate cascading failures
under cyber-physical attack conditions. A comprehensive validation is carried
out using NS-3 simulations, where key performance indicators such as
reliability, latency, resilience index, and packet loss rate are analyzed under
various attack scenarios. The deduced results demonstrate that the proposed
framework significantly improves fault recovery, stabilizes packet delivery,
and reduces service disruption compared to baseline approaches.

</details>


### [9] [An Adaptive Intelligent Thermal-Aware Routing Protocol for Wireless Body Area Networks](https://arxiv.org/abs/2510.19300)
*Abdollah Rahimi,Mehdi Jafari Shahbazzadeh,Amid Khatibi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wireless Body Area Networks (WBANs) have gained significant attention due to
their applications in healthcare monitoring, sports, military communication,
and remote patient care. These networks consist of wearable or implanted
sensors that continuously collect and transmit physiological data, requiring
efficient and reliable communication. However, WBANs face challenges such as
limited energy, dynamic topology, and sensitivity to node temperature, which
demand specialized routing strategies. Traditional shortest-path routing often
causes congestion and overheating in specific nodes, leading to early failures.
To address these problems, this paper proposes an intelligent temperature-aware
and reliability-based routing approach that enhances WBAN performance. The
proposed method works in two phases: (1) network setup and intelligent path
selection, and (2) dynamic traffic management and hotspot avoidance. In the
first phase, nodes share information such as residual energy, temperature, link
reliability, and delay to build an optimized topology using a multi-criteria
decision algorithm. The second phase continuously monitors real-time conditions
and reroutes traffic away from overheated or depleted nodes. Simulation results
show that the proposed approach improves throughput by 13 percent, reduces
end-to-end delay by 10 percent, decreases energy consumption by 25 percent, and
lowers routing load by 30 percent compared to existing methods.

</details>


### [10] [Collaborative penetration testing suite for emerging generative AI algorithms](https://arxiv.org/abs/2510.19303)
*Petar Radanliev*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Problem Space: AI Vulnerabilities and Quantum Threats Generative AI
vulnerabilities: model inversion, data poisoning, adversarial inputs. Quantum
threats Shor Algorithm breaking RSA ECC encryption. Challenge Secure generative
AI models against classical and quantum cyberattacks. Proposed Solution
Collaborative Penetration Testing Suite Five Integrated Components: DAST SAST
OWASP ZAP, Burp Suite, SonarQube, Fortify. IAST Contrast Assess integrated with
CI CD pipeline. Blockchain Logging Hyperledger Fabric for tamper-proof logs.
Quantum Cryptography Lattice based RLWE protocols. AI Red Team Simulations
Adversarial ML & Quantum-assisted attacks. Integration Layer: Unified workflow
for AI, cybersecurity, and quantum experts. Key Results 300+ vulnerabilities
identified across test environments. 70% reduction in high-severity issues
within 2 weeks. 90% resolution efficiency for blockchain-logged
vulnerabilities. Quantum-resistant cryptography maintained 100% integrity in
tests. Outcome: Quantum AI Security Protocol integrating Blockchain Quantum
Cryptography AI Red Teaming.

</details>


### [11] [Authorization of Knowledge-base Agents in an Intent-based Management Function](https://arxiv.org/abs/2510.19324)
*Loay Abdelrazek,Leyli Karaçay,Marin Orlic*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As networks move toward the next-generation 6G, Intent-based Management (IbM)
systems are increasingly adopted to simplify and automate network management by
translating high-level intents into low-level configurations. Within these
systems, agents play a critical role in monitoring current state of the
network, gathering data, and enforcing actions across the network to fulfill
the intent. However, ensuring secure and fine-grained authorization of agents
remains a significant challenge, especially in dynamic and multi-tenant
environments. Traditional models such as Role-Based Access Control (RBAC),
Attribute-Based Access Control (ABAC) and Relational-Based Access Control
(RelBAC) often lack the flexibility to accommodate the evolving context and
granularity required by intentbased operations. In this paper, we propose an
enhanced authorization framework that integrates contextual and functional
attributes with agent roles to achieve dynamic, policy-driven access control.
By analyzing agent functionalities, our approach ensures that agents are
granted only the minimal necessary privileges towards knowledge graphs.

</details>


### [12] [A Probabilistic Computing Approach to the Closest Vector Problem for Lattice-Based Factoring](https://arxiv.org/abs/2510.19390)
*Max O. Al-Hasso,Marko von der Leyen*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The closest vector problem (CVP) is a fundamental optimization problem in
lattice-based cryptography and its conjectured hardness underpins the security
of lattice-based cryptosystems. Furthermore, Schnorr's lattice-based factoring
algorithm reduces integer factoring (the foundation of current cryptosystems,
including RSA) to the CVP. Recent work has investigated the inclusion of a
heuristic CVP approximation `refinement' step in the lattice-based factoring
algorithm, using quantum variational algorithms to perform the heuristic
optimization. This coincides with the emergence of probabilistic computing as a
hardware accelerator for randomized algorithms including tasks in combinatorial
optimization. In this work we investigate the application of probabilistic
computing to the heuristic optimization task of CVP approximation refinement in
lattice-based factoring. We present the design of a probabilistic computing
algorithm for this task, a discussion of `prime lattice' parameters, and
experimental results showing the efficacy of probabilistic computing for
solving the CVP as well as its efficacy as a subroutine for lattice-based
factoring. The main results found that (a) this approach is capable of finding
the maximal available CVP approximation refinement in time linear in problem
size and (b) probabilistic computing used in conjunction with the lattice
parameters presented can find the composite prime factors of a semiprime number
using up to 100x fewer lattice instances than similar quantum and classical
methods.

</details>


### [13] [From See to Shield: ML-Assisted Fine-Grained Access Control for Visual Data](https://arxiv.org/abs/2510.19418)
*Mete Harun Akcay,Buse Gul Atli,Siddharth Prakash Rao,Alexandros Bakas*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As the volume of stored data continues to grow, identifying and protecting
sensitive information within large repositories becomes increasingly
challenging, especially when shared with multiple users with different roles
and permissions. This work presents a system architecture for trusted data
sharing with policy-driven access control, enabling selective protection of
sensitive regions while maintaining scalability. The proposed architecture
integrates four core modules that combine automated detection of sensitive
regions, post-correction, key management, and access control. Sensitive regions
are secured using a hybrid scheme that employs symmetric encryption for
efficiency and Attribute-Based Encryption for policy enforcement. The system
supports efficient key distribution and isolates key storage to strengthen
overall security. To demonstrate its applicability, we evaluate the system on
visual datasets, where Privacy-Sensitive Objects in images are automatically
detected, reassessed, and selectively encrypted prior to sharing in a data
repository. Experimental results show that our system provides effective PSO
detection, increases macro-averaged F1 score (5%) and mean Average Precision
(10%), and maintains an average policy-enforced decryption time of less than 1
second per image. These results demonstrate the effectiveness, efficiency and
scalability of our proposed solution for fine-grained access control.

</details>


### [14] [Monitoring LLM-based Multi-Agent Systems Against Corruptions via Node Evaluation](https://arxiv.org/abs/2510.19420)
*Chengcan Wu,Zhixin Zhang,Mingqian Xu,Zeming Wei,Meng Sun*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) have become a
popular paradigm of AI applications. However, trustworthiness issues in MAS
remain a critical concern. Unlike challenges in single-agent systems, MAS
involve more complex communication processes, making them susceptible to
corruption attacks. To mitigate this issue, several defense mechanisms have
been developed based on the graph representation of MAS, where agents represent
nodes and communications form edges. Nevertheless, these methods predominantly
focus on static graph defense, attempting to either detect attacks in a fixed
graph structure or optimize a static topology with certain defensive
capabilities. To address this limitation, we propose a dynamic defense paradigm
for MAS graph structures, which continuously monitors communication within the
MAS graph, then dynamically adjusts the graph topology, accurately disrupts
malicious communications, and effectively defends against evolving and diverse
dynamic attacks. Experimental results in increasingly complex and dynamic MAS
environments demonstrate that our method significantly outperforms existing MAS
defense mechanisms, contributing an effective guardrail for their trustworthy
applications. Our code is available at
https://github.com/ChengcanWu/Monitoring-LLM-Based-Multi-Agent-Systems.

</details>


### [15] [Transmitter Identification via Volterra Series Based Radio Frequency Fingerprint](https://arxiv.org/abs/2510.19440)
*Rundong Jiang,Jun Hu,Zhiyuan Xie,Yunqi Song,Shiyou Xu*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The growing number of wireless devices increases the need for secure network
access. Radio Frequency Fingerprinting (RFF), a physical-layer authentication
method, offers a promising solution as it requires no cryptography and resists
spoofing. However, existing RFF approaches often lack a unified theory and
effective feature extraction. Many methods use handcrafted signal features or
direct neural network classification, leading to limited generalization and
interpretability. In this work, we model the transmitter as a black box and
analyze its impact on transmitted signals. By treating the deviation from an
ideal signal as hardware-induced distortion, we represent the received signal
using a Volterra series, using its kernels to capture linear and nonlinear
hardware traits. To manage the high dimensionality of these kernels, we
approximate them via wavelet decomposition and estimate coefficients through
least-squares fitting. The resulting wavelet coefficients provide compact yet
informative hardware representations, which are classified using a
complex-valued neural network. Experiments on a public LoRa dataset show
state-of-the-art performance, with over 98% accuracy in static channels and
above 90% under multipath and Doppler effects. The proposed approach improves
both interpretability and generalization across varying channel conditions.

</details>


### [16] [AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on Edge Devices](https://arxiv.org/abs/2510.19462)
*Zhonghao Zhan,Amir Al Sadi,Krinos Li,Hamed Haddadi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we study security of Model Context Protocol (MCP) agent
toolchains and their applications in smart homes. We introduce AegisMCP, a
protocol-level intrusion detector. Our contributions are: (i) a minimal attack
suite spanning instruction-driven escalation, chain-of-tool exfiltration,
malicious MCP server registration, and persistence; (ii) NEBULA-Schema
(Network-Edge Behavioral Learning for Untrusted LLM Agents), a reusable
protocol-level instrumentation that represents MCP activity as a streaming
heterogeneous temporal graph over agents, MCP servers, tools, devices, remotes,
and sessions; and (iii) a CPU-only streaming detector that fuses novelty,
session-DAG structure, and attribute cues for near-real-time edge inference,
with optional fusion of local prompt-guardrail signals. On an emulated
smart-home testbed spanning multiple MCP stacks and a physical bench, AegisMCP
achieves sub-second per-window model inference and end-to-end alerting. The
latency of AegisMCP is consistently sub-second on Intel N150-class edge
hardware, while outperforming traffic-only and sequence baselines; ablations
confirm the importance of DAG and install/permission signals. We release code,
schemas, and generators for reproducible evaluation.

</details>


### [17] [Cross-Chain Sealed-Bid Auctions Using Confidential Compute Blockchains](https://arxiv.org/abs/2510.19491)
*Jonas Gebele,Timm Mutzel,Burak Oez,Florian Matthes*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sealed-bid auctions ensure fair competition and efficient allocation but are
often deployed on centralized infrastructure, enabling opaque manipulation.
Public blockchains eliminate central control, yet their inherent transparency
conflicts with the confidentiality required for sealed bidding. Prior attempts
struggle to reconcile privacy, verifiability, and scalability without relying
on trusted intermediaries, multi-round protocols, or expensive cryptography. We
present a sealed-bid auction protocol that executes sensitive bidding logic on
a Trusted Execution Environment (TEE)-backed confidential compute blockchain
while retaining settlement and enforcement on a public chain. Bidders commit
funds to enclave-generated escrow addresses, ensuring confidentiality and
binding commitments. After the deadline, any party can trigger resolution: the
confidential blockchain determines the winner through verifiable off-chain
computation and issues signed settlement transactions for execution on the
public chain. Our design provides security, privacy, and scalability without
trusted third parties or protocol modifications. We implement it on SUAVE with
Ethereum settlement, evaluate its scalability and trust assumptions, and
demonstrate deployment with minimal integration on existing infrastructure

</details>


### [18] [Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption Parameter Optimisation](https://arxiv.org/abs/2510.19537)
*Mahitha Pulivathi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep learning is widely applied to modern problems through neural networks,
but the growing computational and energy demands of these models have driven
interest in more efficient approaches. Spiking Neural Networks (SNNs), the
third generation of neural networks, mimic the brain's event-driven behaviour,
offering improved performance and reduced power use. At the same time, concerns
about data privacy during cloud-based model execution have led to the adoption
of cryptographic methods. This article introduces BioEncryptSNN, a spiking
neural network based encryption-decryption framework for secure and
noise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN
converts ciphertext into spike trains and exploits temporal neural dynamics to
model encryption and decryption, optimising parameters such as key length,
spike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048,
and DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x
faster encryption and decryption than PyCryptodome's AES implementation. The
framework demonstrates scalability and adaptability across symmetric and
asymmetric ciphers, positioning SNNs as a promising direction for secure,
energy-efficient computing.

</details>


### [19] [CircuitGuard: Mitigating LLM Memorization in RTL Code Generation Against IP Leakage](https://arxiv.org/abs/2510.19676)
*Nowfel Mashnoor,Mohammad Akyash,Hadi Kamali,Kimia Azar*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have achieved remarkable success in generative
tasks, including register-transfer level (RTL) hardware synthesis. However,
their tendency to memorize training data poses critical risks when proprietary
or security-sensitive designs are unintentionally exposed during inference.
While prior work has examined memorization in natural language, RTL introduces
unique challenges: In RTL, structurally different implementations (e.g.,
behavioral vs. gate-level descriptions) can realize the same hardware, leading
to intellectual property (IP) leakage (full or partial) even without verbatim
overlap. Conversely, even small syntactic variations (e.g., operator precedence
or blocking vs. non-blocking assignments) can drastically alter circuit
behavior, making correctness preservation especially challenging. In this work,
we systematically study memorization in RTL code generation and propose
CircuitGuard, a defense strategy that balances leakage reduction with
correctness preservation. CircuitGuard (1) introduces a novel RTL-aware
similarity metric that captures both structural and functional equivalence
beyond surface-level overlap, and (2) develops an activation-level steering
method that identifies and attenuates transformer components most responsible
for memorization. Our empirical evaluation demonstrates that CircuitGuard
identifies (and isolates) 275 memorization-critical features across layers
18-28 of Llama 3.1-8B model, achieving up to 80% reduction in semantic
similarity to proprietary patterns while maintaining generation quality.
CircuitGuard further shows 78-85% cross-domain transfer effectiveness, enabling
robust memorization mitigation across circuit categories without retraining.

</details>


### [20] [Exploring the Effect of DNN Depth on Adversarial Attacks in Network Intrusion Detection Systems](https://arxiv.org/abs/2510.19761)
*Mohamed ElShehaby,Ashraf Matrawy*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Adversarial attacks pose significant challenges to Machine Learning (ML)
systems and especially Deep Neural Networks (DNNs) by subtly manipulating
inputs to induce incorrect predictions. This paper investigates whether
increasing the layer depth of deep neural networks affects their robustness
against adversarial attacks in the Network Intrusion Detection System (NIDS)
domain. We compare the adversarial robustness of various deep neural networks
across both \ac{NIDS} and computer vision domains (the latter being widely used
in adversarial attack experiments). Our experimental results reveal that in the
NIDS domain, adding more layers does not necessarily improve their performance,
yet it may actually significantly degrade their robustness against adversarial
attacks. Conversely, in the computer vision domain, adding more layers exhibits
a more modest impact on robustness. These findings can guide the development of
robust neural networks for (NIDS) applications and highlight the unique
characteristics of network security domains within the (ML) landscape.

</details>


### [21] [Under Pressure: Security Analysis and Process Impacts of a Commercial Smart Air Compressor](https://arxiv.org/abs/2510.19772)
*Jad Zarzour,Matthew Jablonski*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The integration of Industrial Internet of Things (IIoT) devices into
manufacturing environments has accelerated the transition to Industry 4.0, but
has also introduced new cybersecurity risks. This paper conducts a
comprehensive security analysis of a commercial smart air compressor, revealing
critical vulnerabilities including hardcoded credentials, unauthenticated APIs,
and an insecure update mechanism. It includes a formal threat model,
demonstrates practical attack scenarios in a testbed environment, and evaluates
their subsequent impact on an industrial process, leading to denial of service
and the corruption of critical process telemetry. In addition, an analysis of
the device's supply chain reveals how product integration from multiple vendors
and limited security considerations can expose a device to threats. The
findings underscore the necessity of incorporating cybersecurity principles
into both IIoT device design and supply chain governance to enhance resilience
against emerging industrial cyber threats.

</details>
