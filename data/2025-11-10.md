<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 18]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Jailbreaking in the Haystack](https://arxiv.org/abs/2511.04707)
*Rishi Rajesh Shah,Chen Henry Wu,Shashwat Saxena,Ziqian Zhong,Alexander Robey,Aditi Raghunathan*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in long-context language models (LMs) have enabled
million-token inputs, expanding their capabilities across complex tasks like
computer-use agents. Yet, the safety implications of these extended contexts
remain unclear. To bridge this gap, we introduce NINJA (short for
Needle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by
appending benign, model-generated content to harmful user goals. Critical to
our method is the observation that the position of harmful goals play an
important role in safety. Experiments on standard safety benchmark, HarmBench,
show that NINJA significantly increases attack success rates across
state-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral,
and Gemini. Unlike prior jailbreaking methods, our approach is low-resource,
transferable, and less detectable. Moreover, we show that NINJA is
compute-optimal -- under a fixed compute budget, increasing context length can
outperform increasing the number of trials in best-of-N jailbreak. These
findings reveal that even benign long contexts -- when crafted with careful
goal positioning -- introduce fundamental vulnerabilities in modern LMs.

</details>


### [2] [SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking](https://arxiv.org/abs/2511.04711)
*Wenyuan Yang,Yichen Sun,Changzheng Chen,Zhixuan Chu,Jiaheng Zhang,Yiming Li,Dacheng Tao*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large-scale vision-language models, especially CLIP, have demonstrated
remarkable performance across diverse downstream tasks. Soft prompts, as
carefully crafted modules that efficiently adapt vision-language models to
specific tasks, necessitate effective copyright protection. In this paper, we
investigate model copyright protection by auditing whether suspicious
third-party models incorporate protected soft prompts. While this can be viewed
as a special case of model ownership auditing, our analysis shows that existing
techniques are ineffective due to prompt learning's unique characteristics.
Non-intrusive auditing is inherently prone to false positives when independent
models share similar data distributions with victim models. Intrusive
approaches also fail: backdoor methods designed for CLIP cannot embed
functional triggers, while extending traditional DNN backdoor techniques to
prompt learning suffers from harmfulness and ambiguity challenges. We find that
these failures in intrusive auditing stem from the same fundamental reason:
watermarking operates within the same decision space as the primary task yet
pursues opposing objectives. Motivated by these findings, we propose sequential
watermarking for soft prompts (SWAP), which implants watermarks into a
different and more complex space. SWAP encodes watermarks through a specific
order of defender-specified out-of-distribution classes, inspired by the
zero-shot prediction capability of CLIP. This watermark, which is embedded in a
more complex space, keeps the original prediction label unchanged, making it
less opposed to the primary task. We further design a hypothesis-test-guided
verification protocol for SWAP and provide theoretical analyses of success
conditions. Extensive experiments on 11 datasets demonstrate SWAP's
effectiveness, harmlessness, and robustness against potential adaptive attacks.

</details>


### [3] [P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models](https://arxiv.org/abs/2511.04716)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cognitive diagnosis models (CDMs) are pivotal for creating fine-grained
learner profiles in modern intelligent education platforms. However, these
models are trained on sensitive student data, raising significant privacy
concerns. While membership inference attacks (MIA) have been studied in various
domains, their application to CDMs remains a critical research gap, leaving
their privacy risks unquantified. This paper is the first to systematically
investigate MIA against CDMs. We introduce a novel and realistic grey box
threat model that exploits the explainability features of these platforms,
where a model's internal knowledge state vectors are exposed to users through
visualizations such as radar charts. We demonstrate that these vectors can be
accurately reverse-engineered from such visualizations, creating a potent
attack surface. Based on this threat model, we propose a profile-based MIA
(P-MIA) framework that leverages both the model's final prediction
probabilities and the exposed internal knowledge state vectors as features.
Extensive experiments on three real-world datasets against mainstream CDMs show
that our grey-box attack significantly outperforms standard black-box
baselines. Furthermore, we showcase the utility of P-MIA as an auditing tool by
successfully evaluating the efficacy of machine unlearning techniques and
revealing their limitations.

</details>


### [4] [Trustworthiness Calibration Framework for Phishing Email Detection Using Large Language Models](https://arxiv.org/abs/2511.04728)
*Daniyal Ganiuly,Assel Smaiyl*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Phishing emails continue to pose a persistent challenge to online
communication, exploiting human trust and evading automated filters through
realistic language and adaptive tactics. While large language models (LLMs)
such as GPT-4 and LLaMA-3-8B achieve strong accuracy in text classification,
their deployment in security systems requires assessing reliability beyond
benchmark performance. To address this, this study introduces the
Trustworthiness Calibration Framework (TCF), a reproducible methodology for
evaluating phishing detectors across three dimensions: calibration,
consistency, and robustness. These components are integrated into a bounded
index, the Trustworthiness Calibration Index (TCI), and complemented by the
Cross-Dataset Stability (CDS) metric that quantifies stability of
trustworthiness across datasets. Experiments conducted on five corpora, such as
SecureMail 2025, Phishing Validation 2024, CSDMC2010, Enron-Spam, and Nazario,
using DeBERTa-v3-base, LLaMA-3-8B, and GPT-4 demonstrate that GPT-4 achieves
the strongest overall trust profile, followed by LLaMA-3-8B and
DeBERTa-v3-base. Statistical analysis confirms that reliability varies
independently of raw accuracy, underscoring the importance of trust-aware
evaluation for real-world deployment. The proposed framework establishes a
transparent and reproducible foundation for assessing model dependability in
LLM-based phishing detection.

</details>


### [5] [GPT-5 at CTFs: Case Studies From Top-Tier Cybersecurity Events](https://arxiv.org/abs/2511.04860)
*Reworr,Artem Petrov,Dmitrii Volkov*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: OpenAI and DeepMind's AIs recently got gold at the IMO math olympiad and ICPC
programming competition. We show frontier AI is similarly good at hacking by
letting GPT-5 compete in elite CTF cybersecurity competitions.
  In one of this year's hardest events, it outperformed 93% of humans finishing
25th: between the world's #3-ranked team (24th place) and #7-ranked team (26th
place).
  This report walks through our methodology, results, and their implications,
and dives deep into 3 problems and solutions we found particularly interesting.

</details>


### [6] [Bit-Flipping Attack Exploration and Countermeasure in 5G Network](https://arxiv.org/abs/2511.04882)
*Joon Kim,Chengwei Duan,Sandip Ray*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 5G communication technology has become a vital component in a wide range of
applications due to its unique advantages such as high data rate and low
latency. While much of the existing research has focused on optimizing its
efficiency and performance, security considerations have not received
comparable attention, potentially leaving critical vulnerabilities unexplored.
In this work, we investigate the vulnerability of 5G systems to bit-flipping
attacks, which is an integrity attack where an adversary intercepts 5G network
traffic and modifies specific fields of an encrypted message without
decryption, thus mutating the message while remaining valid to the receiver.
Notably, these attacks do not require the attacker to know the plaintext, and
only the semantic meaning or position of certain fields would be enough to
effect targeted modifications. We conduct our analysis on OpenAirInterface
(OAI), an open-source 5G platform that follows the 3GPP Technical
Specifications, to rigorously test the real-world feasibility and impact of
bit-flipping attacks under current 5G encryption mechanisms. Finally, we
propose a keystream-based shuffling defense mechanism to mitigate the effect of
such attacks by raising the difficulty of manipulating specific encrypted
fields, while introducing no additional communication overhead compared to the
NAS Integrity Algorithm (NIA) in 5G. Our findings reveal that enhancements to
5G security are needed to better protect against attacks that alter data during
transmission at the network level.

</details>


### [7] [Zero Trust Security Model Implementation in Microservices Architectures Using Identity Federation](https://arxiv.org/abs/2511.04925)
*Rethish Nair Rajendran,Sathish Krishna Anumula,Dileep Kumar Rai,Sachin Agrawal*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The microservice bombshells that have been linked with the microservice
expansion have altered the application architectures, offered agility and
scalability in terms of complexity in security trade-offs. Feeble legacy-based
perimeter-based policies are unable to offer safeguard to distributed workloads
and temporary interaction among and in between the services. The article itself
is a case on the need of the Zero Trust Security Model of micro services
ecosystem, particularly, the fact that human and workloads require identity
federation. It is proposed that the solution framework will be based on
industry-standard authentication and authorization and end-to-end trust
identity technologies, including Authorization and OpenID connect (OIDC),
Authorization and OAuth 2.0 token exchange, and Authorization and SPIFFE/ SPIRE
workload identities. Experimental evaluation is a unique demonstration of a
superior security position of making use of a smaller attack surface, harmony
policy enforcement, as well as interoperability across multi- domain
environments. The research results overlay that the federated identity combined
with the Zero Trust basics not only guarantee the rules relating to
authentication and authorization but also fully complies with the latest
DevSecOps standards of microservice deployment, which is automated, scaled, and
resilient. The current project offers a stringent roadmap to the organizations
that desire to apply Zero Trust in cloud-native technologies but will as well
guarantee adherence and interoperability.

</details>


### [8] [The Future of Fully Homomorphic Encryption System: from a Storage I/O Perspective](https://arxiv.org/abs/2511.04946)
*Lei Chen,Erci Xu,Yiming Sun,Shengyu Fan,Xianglong Deng,Guiming Shi,Guang Fan,Liang Kong,Yilan Zhu,Shoumeng Yan,Mingzhe Zhang*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fully Homomorphic Encryption (FHE) allows computations to be performed on
encrypted data, significantly enhancing user privacy. However, the I/O
challenges associated with deploying FHE applications remains understudied. We
analyze the impact of storage I/O on the performance of FHE applications and
summarize key lessons from the status quo. Key results include that storage I/O
can degrade the performance of ASICs by as much as 357$\times$ and reduce GPUs
performance by up to 22$\times$.

</details>


### [9] [Chasing One-day Vulnerabilities Across Open Source Forks](https://arxiv.org/abs/2511.05097)
*Romain Lefeuvre,Charly Reux,Stefano Zacchiroli,Olivier Barais,Benoit Combemale*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Tracking vulnerabilities inherited from third-party open-source components is
a well-known challenge, often addressed by tracing the threads of dependency
information. However, vulnerabilities can also propagate through forking: a
repository forked after the introduction of a vulnerability, but before it is
patched, may remain vulnerable in the fork well after being fixed in the
original project. Current approaches for vulnerability analysis lack the
commit-level granularity needed to track vulnerability introductions and fixes
across forks, potentially leaving one-day vulnerabilities undetected. This
paper presents a novel approach to help developers identify one-day
vulnerabilities in forked repositories. Leveraging the global graph of public
code, as captured by the Software Heritage archive, the approach propagates
vulnerability information at the commit level and performs automated impact
analysis. This enables automatic detection of forked projects that have not
incorporated fixes, leaving them potentially vulnerable. Starting from 7162
repositories that, according to OSV, include vulnerable commits in their
development histories, we identify 2.2 M forks, containing at least one
vulnerable commit. Then we perform a strict filtering, allowing us to find 356
___vulnerability, fork___ pairs impacting active and popular GitHub forks, we
manually evaluate 65 pairs, finding 3 high-severity vulnerabilities,
demonstrating the impact and applicability of this approach.

</details>


### [10] [TRICK: Time and Range Integrity ChecK using Low Earth Orbiting Satellite for Securing GNSS](https://arxiv.org/abs/2511.05100)
*Arslan Mumtaz,Mridula Singh*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Global Navigation Satellite Systems (GNSS) provide Positioning, Navigation,
and Timing (PNT) information to over 4 billion devices worldwide. Despite its
pervasive use in safety critical and high precision applications, GNSS remains
vulnerable to spoofing attacks. Cryptographic enhancements, such as the use of
TESLA protocol in Galileo, to provide navigation message authentication do not
mitigate time of arrival manipulations. In this paper, we propose TRICK, a
primitive for secure positioning that closes this gap by introducing a
fundamentally new approach that only requires two way communications with a
single reference node along with multiple broadcast signals. Unlike classical
Verifiable Multilateration (VM), which requires establishing two way
communication with each reference nodes, our solution relies on only two
measurements with a trusted Low Earth Orbiting (LEO) satellite and combines
broadcast navigation signals. We rigorously prove that combining the LEO
satellite based two way range measurements and multiple one way ranges such as
from broadcast signals of GNSS into ellipsoidal constraint restores the same
guarantees as offered by VM whilst using minimal infrastructure and message
exchanges. Through detailed analysis, we show that our approach reliably
detects spoofing attempts while adding negligible computation overhead.

</details>


### [11] [Quantifying the Risk of Transferred Black Box Attacks](https://arxiv.org/abs/2511.05102)
*Disesdi Susanna Cox,Niklas Bunzel*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural networks have become pervasive across various applications, including
security-related products. However, their widespread adoption has heightened
concerns regarding vulnerability to adversarial attacks. With emerging
regulations and standards emphasizing security, organizations must reliably
quantify risks associated with these attacks, particularly regarding
transferred adversarial attacks, which remain challenging to evaluate
accurately. This paper investigates the complexities involved in resilience
testing against transferred adversarial attacks. Our analysis specifically
addresses black-box evasion attacks, highlighting transfer-based attacks due to
their practical significance and typically high transferability between neural
network models. We underline the computational infeasibility of exhaustively
exploring high-dimensional input spaces to achieve complete test coverage. As a
result, comprehensive adversarial risk mapping is deemed impractical. To
mitigate this limitation, we propose a targeted resilience testing framework
that employs surrogate models strategically selected based on Centered Kernel
Alignment (CKA) similarity. By leveraging surrogate models exhibiting both high
and low CKA similarities relative to the target model, the proposed approach
seeks to optimize coverage of adversarial subspaces. Risk estimation is
conducted using regression-based estimators, providing organizations with
realistic and actionable risk quantification.

</details>


### [12] [PhantomFetch: Obfuscating Loads against Prefetcher Side-Channel Attacks](https://arxiv.org/abs/2511.05110)
*Xingzhi Zhang,Buyi Lv,Yimin Lu,Kai Bu*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The IP-stride prefetcher has recently been exploited to leak secrets through
side-channel attacks. It, however, cannot be simply disabled for security with
prefetching speedup as a sacrifice. The state-of-the-art defense tries to
retain the prefetching effect by hardware modification. In this paper, we
present PhantomFetch as the first prefetching-retentive and hardware-agnostic
defense. It avoids potential remanufacturing cost and enriches applicability to
off-the-shelf devices. The key idea is to directly break the exploitable
coupling between trained prefetcher entries and the victim's secret-dependent
loads by obfuscating the sensitive load effects of the victim. The experiment
results show that PhantomFetch can secure the IP-stride prefetcher with only
negligible overhead.

</details>


### [13] [Confidentiality in a Card-Based Protocol Under Repeated Biased Shuffles](https://arxiv.org/abs/2511.05111)
*Do Hyun Kim,Ahmet Cetinkaya*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we provide a probabilistic analysis of the confidentiality in
a card-based protocol. We focus on Bert den Boer's original Five Card Trick to
develop our approach. Five Card Trick was formulated as a secure two-party
computation method, where two players use colored cards with identical backs to
calculate the logical AND operation on the bits that they choose. In this
method, the players first arrange the cards privately, and then shuffle them
through a random cut. Finally, they reveal the shuffled arrangement to
determine the result of the operation. An unbiased random cut is essential to
prevent players from exposing their chosen bits to each other. However, players
typically choose to move cards within the deck even though not moving any cards
should be equally likely. This unconscious behavior results in a biased,
nonuniform shuffling-distribution in the sense that some arrangements of cards
are slightly more probable after the cut. Such a nonuniform distribution
creates an opportunity for a malicious player to gain advantage in guessing the
other player's choice. We provide the conditional probabilities of such guesses
as a way to quantify the information leakage. Furthermore, we utilize the
eigenstructure of a Markov chain to derive tight bounds on the number of times
the biased random cuts must be repeated to reduce the leakage to an acceptable
level. We also discuss the generalization of our approach to the setting where
shuffling is conducted by a malicious player.

</details>


### [14] [Cybersecurity AI in OT: Insights from an AI Top-10 Ranker in the Dragos OT CTF 2025](https://arxiv.org/abs/2511.05119)
*Víctor Mayoral-Vilches,Luis Javier Navarrete-Lozano,Francesco Balassone,María Sanz-Gómez,Cristóbal Ricardo Veas Chávez,Maite del Mundo de Torres*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Operational Technology (OT) cybersecurity increasingly relies on rapid
response across malware analysis, network forensics, and reverse engineering
disciplines. We examine the performance of Cybersecurity AI (CAI), powered by
the \texttt{alias1} model, during the Dragos OT CTF 2025 -- a 48-hour
industrial control system (ICS) competition with more than 1,000 teams. Using
CAI telemetry and official leaderboard data, we quantify CAI's trajectory
relative to the leading human-operated teams. CAI reached Rank~1 between
competition hours 7.0 and 8.0, crossed 10,000 points at 5.42~hours
(1,846~pts/h), and completed 32 of the competition's 34 challenges before
automated operations were paused at hour~24 with a final score of 18,900 points
(6th place). The top-3 human teams solved 33 of 34 challenges, collectively
leaving only the 600-point ``Kiddy Tags -- 1'' unsolved; they were also the
only teams to clear the 1,000-point ``Moot Force'' binary. The top-5 human
teams averaged 1,347~pts/h to the same milestone, marking a 37\% velocity
advantage for CAI. We analyse time-resolved scoring, category coverage, and
solve cadence. The evidence indicates that a mission-configured AI agent can
match or exceed expert human crews in early-phase OT incident response while
remaining subject to practical limits in sustained, multi-day operations.

</details>


### [15] [A Secured Intent-Based Networking (sIBN) with Data-Driven Time-Aware Intrusion Detection](https://arxiv.org/abs/2511.05133)
*Urslla Uchechi Izuazu,Mounir Bensalem,Admela Jukan*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While Intent-Based Networking (IBN) promises operational efficiency through
autonomous and abstraction-driven network management, a critical unaddressed
issue lies in IBN's implicit trust in the integrity of intent ingested by the
network. This inherent assumption of data reliability creates a blind spot
exploitable by Man-in-the-Middle (MitM) attacks, where an adversary intercepts
and alters intent before it is enacted, compelling the network to orchestrate
malicious configurations. This study proposes a secured IBN (sIBN) system with
data driven intrusion detection method designed to secure legitimate user
intent from adversarial tampering. The proposed intent intrusion detection
system uses a ML model applied for network behavioral anomaly detection to
reveal temporal patterns of intent tampering. This is achieved by leveraging a
set of original behavioral metrics and newly engineered time-aware features,
with the model's hyperparameters fine-tuned through the randomized search
cross-validation (RSCV) technique. Numerical results based on real-world data
sets, show the effectiveness of sIBN, achieving the best performance across
standard evaluation metrics, in both binary and multi classification tasks,
while maintaining low error rates.

</details>


### [16] [SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for Secure and Efficient Software-Defined Networks](https://arxiv.org/abs/2511.05156)
*Azhar Hussain Mozumder,M. John Basha,Chayapathi A. R*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With more and more existing networks being transformed to Software-Defined
Networking (SDN), they need to be more secure and demand smarter ways of
traffic control. This work, SmartSecChain-SDN, is a platform that combines
machine learning based intrusion detection, blockchain-based storage of logs,
and application-awareness-based priority in SDN networks. To detect network
intrusions in a real-time, precision and low-false positives setup, the
framework utilizes the application of advanced machine learning algorithms,
namely Random Forest, XGBoost, CatBoost, and CNN-BiLSTM. SmartSecChain-SDN is
based on the Hyperledger Fabric, which is a permissioned blockchain technology,
to provide secure, scalable, and privacy-preserving storage and, thus,
guarantee that the Intrusion Detection System (IDS) records cannot be altered
and can be analyzed comprehensively. The system also has Quality of Service
(QoS) rules and traffic shaping based on applications, which enables
prioritization of critical services, such as VoIP, video conferencing, and
business applications, as well as de-prioritization of non-essential traffic,
such as downloads and updates. Mininet can simulate real-time SDN scenarios
because it is used to prototype whole architectures. It is also compatible with
controllers OpenDaylight and Ryu. It has tested the framework using the InSDN
dataset and proved that it can identify different kinds of cyberattacks and
handle bandwidth allocation efficiently under circumstances of resource
constraints. SmartSecChain-SDN comprehensively addresses SDN system protection,
securing and enhancing. The proposed study offers an innovative, extensible way
to improve cybersecurity, regulatory compliance, and the administration of
next-generation programmable networks.

</details>


### [17] [BLADE: Behavior-Level Anomaly Detection Using Network Traffic in Web Services](https://arxiv.org/abs/2511.05193)
*Zhibo Dong,Yong Huang,Shubao Sun,Wentao Cui,Zhihua Wang*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With their widespread popularity, web services have become the main targets
of various cyberattacks. Existing traffic anomaly detection approaches focus on
flow-level attacks, yet fail to recognize behavior-level attacks, which appear
benign in individual flows but reveal malicious purpose using multiple network
flows. To transcend this limitation, we propose a novel unsupervised traffic
anomaly detection system, BLADE, capable of detecting not only flow-level but
also behavior-level attacks in web services. Our key observation is that
application-layer operations of web services exhibit distinctive communication
patterns at the network layer from a multi-flow perspective. BLADE first
exploits a flow autoencoder to learn a latent feature representation and
calculates its reconstruction losses per flow. Then, the latent representation
is assigned a pseudo operation label using an unsupervised clustering method.
Next, an anomaly score is computed based on the reconstruction losses. Finally,
the triplets of timestamps, pseudo labels, and anomaly scores from multiple
flows are aggregated and fed into a one-class classifier to characterize the
behavior patterns of legitimate web operations, enabling the detection of
flow-level and behavior-level anomalies. BLADE is extensively evaluated on both
the custom dataset and the CIC-IDS2017 dataset. The experimental results
demonstrate BLADE's superior performance, achieving high F1 scores of 0.9732
and 0.9801, respectively, on the two datasets, and outperforming traditional
single-flow anomaly detection baselines.

</details>


### [18] [ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations](https://arxiv.org/abs/2511.05359)
*Amr Gomaa,Ahmed Salem,Sahar Abdelnabi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As language models evolve into autonomous agents that act and communicate on
behalf of users, ensuring safety in multi-agent ecosystems becomes a central
challenge. Interactions between personal assistants and external service
providers expose a core tension between utility and protection: effective
collaboration requires information sharing, yet every exchange creates new
attack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating
privacy and security risks in agent-agent interactions. ConVerse spans three
practical domains (travel, real estate, insurance) with 12 user personas and
over 864 contextually grounded attacks (611 privacy, 253 security). Unlike
prior single-agent settings, it models autonomous, multi-turn agent-to-agent
conversations where malicious requests are embedded within plausible discourse.
Privacy is tested through a three-tier taxonomy assessing abstraction quality,
while security attacks target tool use and preference manipulation. Evaluating
seven state-of-the-art models reveals persistent vulnerabilities; privacy
attacks succeed in up to 88% of cases and security breaches in up to 60%, with
stronger models leaking more. By unifying privacy and security within
interactive multi-agent contexts, ConVerse reframes safety as an emergent
property of communication.

</details>
