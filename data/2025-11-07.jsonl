{"id": "2511.03799", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03799", "abs": "https://arxiv.org/abs/2511.03799", "authors": ["Tatiana S. Parlanti", "Carlos A. Catania"], "title": "Temporal Analysis Framework for Intrusion Detection Systems: A Novel Taxonomy for Time-Aware Cybersecurity", "comment": "Submitted to Computer Networks (Special Issue on Cybersecurity\n  Attacks and Defenses in Trust-based Networks)", "summary": "Most intrusion detection systems still identify attacks only after\nsignificant damage has occurred, detecting late-stage tactics rather than early\nindicators of compromise. This paper introduces a temporal analysis framework\nand taxonomy for time-aware network intrusion detection. Through a systematic\nreview of over 40 studies published between 2020 and 2025, we classify NIDS\nmethods according to their treatment of time, from static per-flow analysis to\nmulti-window sequential modeling. The proposed taxonomy reveals that inter-flow\nsequential and temporal window-based methods provide the broadest temporal\ncoverage across MITRE ATT&CK tactics, enabling detection from Reconnaissance\nthrough Impact stages. Our analysis further exposes systematic bias in widely\nused datasets, which emphasize late-stage attacks and thus limit progress\ntoward early detection. This framework provides essential groundwork for\ndeveloping IDS capable of anticipating rather than merely reacting to cyber\nthreats, advancing the field toward truly proactive defense mechanisms."}
{"id": "2511.03816", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.03816", "abs": "https://arxiv.org/abs/2511.03816", "authors": ["Nikolaos Lykousas", "Constantinos Patsakis"], "title": "Just in Plain Sight: Unveiling CSAM Distribution Campaigns on the Clear Web", "comment": "Accepted for publication in eCrime 2025", "summary": "Child sexual abuse is among the most hideous crimes, yet, after the COVID-19\npandemic, there is a huge surge in the distribution of child sexual abuse\nmaterial (CSAM). Traditionally, the exchange of such material is performed on\nthe dark web, as it provides many privacy guarantees that facilitate illicit\ntrades. However, the introduction of end-to-end encryption platforms has\nbrought it to the deep web. In this work, we report our findings for a campaign\nof spreading child sexual abuse material on the clear web. The campaign\nutilized at least 1,026 web pages for at least 738,286 registered users. Our\nanalysis details the operation of such a campaign, showcasing how social\nnetworks are abused and the role of bots, but also the bypasses that are used.\nGoing a step further and exploiting operational faults in the campaign, we gain\ninsight into the demand for such content, as well as the dynamics of the user\nnetwork that supports it."}
{"id": "2511.03841", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.03841", "abs": "https://arxiv.org/abs/2511.03841", "authors": ["Yedidel Louck", "Ariel Stulman", "Amit Dvir"], "title": "Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation", "comment": null, "summary": "Multi-agent systems (MAS) powered by artificial intelligence (AI) are\nincreasingly foundational to complex, distributed workflows. Yet, the security\nof their underlying communication protocols remains critically under-examined.\nThis paper presents the first empirical, comparative security analysis of the\nofficial CORAL implementation and a high-fidelity, SDK-based ACP\nimplementation, benchmarked against a literature-based evaluation of A2A. Using\na 14 point vulnerability taxonomy, we systematically assess their defenses\nacross authentication, authorization, integrity, confidentiality, and\navailability. Our results reveal a pronounced security dichotomy: CORAL\nexhibits a robust architectural design, particularly in its transport-layer\nmessage validation and session isolation, but suffers from critical\nimplementation-level vulnerabilities, including authentication and\nauthorization failures at its SSE gateway. Conversely, ACP's architectural\nflexibility, most notably its optional JWS enforcement, translates into\nhigh-impact integrity and confidentiality flaws. We contextualize these\nfindings within current industry trends, highlighting that existing protocols\nremain insufficiently secure. As a path forward, we recommend a hybrid approach\nthat combines CORAL's integrated architecture with ACP's mandatory per-message\nintegrity guarantees, laying the groundwork for resilient, next-generation\nagent communications."}
{"id": "2511.03898", "categories": ["cs.CR", "cs.AI", "cs.CE", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03898", "abs": "https://arxiv.org/abs/2511.03898", "authors": ["Arup Datta", "Ahmed Aljohani", "Hyunsook Do"], "title": "Secure Code Generation at Scale with Reflexion", "comment": "Accepted for publication at the 2nd IEEE International Conference on\n  AI-powered Software (AIware 2025)", "summary": "Large language models (LLMs) are now widely used to draft and refactor code,\nbut code that works is not necessarily secure. We evaluate secure code\ngeneration using the Instruct Prime, which eliminated compliance-required\nprompts and cue contamination, and evaluate five instruction-tuned code LLMs\nusing a zero-shot baseline and a three-round reflexion prompting approach.\nSecurity is measured using the Insecure Code Detector (ICD), and results are\nreported by measuring Repair, Regression, and NetGain metrics, considering the\nprogramming language and CWE family. Our findings show that insecurity remains\ncommon at the first round: roughly 25-33% of programs are insecure at a\nzero-shot baseline (t0 ). Weak cryptography/config-dependent bugs are the\nhardest to avoid while templated ones like XSS, code injection, and hard-coded\nsecrets are handled more reliably. Python yields the highest secure rates; C\nand C# are the lowest, with Java, JS, PHP, and C++ in the middle. Reflexion\nprompting improves security for all models, improving average accuracy from\n70.74% at t0 to 79.43% at t3 , with the largest gains in the first round\nfollowed by diminishing returns. The trends with Repair, Regression, and\nNetGain metrics show that applying one to two rounds produces most of the\nbenefits. A replication package is available at\nhttps://doi.org/10.5281/zenodo.17065846."}
{"id": "2511.03971", "categories": ["cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.03971", "abs": "https://arxiv.org/abs/2511.03971", "authors": ["Victor Mattos", "João Henrique Schmidt", "Amit Bhaya", "Alan Oliveira de Sá", "Daniel Sadoc Menasché", "Gaurav Srivastava"], "title": "Design and Detection of Covert Man-in-the-Middle Cyberattacks on Water Treatment Plants", "comment": "Proceedings of the 2025 Workshop on Re-design Industrial Control\n  Systems with Security -- RICSS 2025 Workshop under the ACM Conference on\n  Computer and Communications Security (CCS)", "summary": "Cyberattacks targeting critical infrastructures, such as water treatment\nfacilities, represent significant threats to public health, safety, and the\nenvironment. This paper introduces a systematic approach for modeling and\nassessing covert man-in-the-middle (MitM) attacks that leverage system\nidentification techniques to inform the attack design. We focus on the\nattacker's ability to deploy a covert controller, and we evaluate\ncountermeasures based on the Process-Aware Stealthy Attack Detection (PASAD)\nanomaly detection method. Using a second-order linear time-invariant with time\ndelay model, representative of water treatment dynamics, we design and simulate\nstealthy attacks. Our results highlight how factors such as system noise and\ninaccuracies in the attacker's plant model influence the attack's stealthiness,\nunderscoring the need for more robust detection strategies in industrial\ncontrol environments."}
{"id": "2511.03995", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03995", "abs": "https://arxiv.org/abs/2511.03995", "authors": ["Shiyin Lin"], "title": "Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback", "comment": null, "summary": "Software fuzzing has become a cornerstone in automated vulnerability\ndiscovery, yet existing mutation strategies often lack semantic awareness,\nleading to redundant test cases and slow exploration of deep program states. In\nthis work, I present a hybrid fuzzing framework that integrates static and\ndynamic analysis with Large Language Model (LLM)-guided input mutation and\nsemantic feedback. Static analysis extracts control-flow and data-flow\ninformation, which is transformed into structured prompts for the LLM to\ngenerate syntactically valid and semantically diverse inputs. During execution,\nI augment traditional coverage-based feedback with semantic feedback\nsignals-derived from program state changes, exception types, and output\nsemantics-allowing the fuzzer to prioritize inputs that trigger novel program\nbehaviors beyond mere code coverage. I implement our approach atop AFL++,\ncombining program instrumentation with embedding-based semantic similarity\nmetrics to guide seed selection. Evaluation on real-world open-source targets,\nincluding libpng, tcpdump, and sqlite, demonstrates that our method achieves\nfaster time-to-first-bug, higher semantic diversity, and a competitive number\nof unique bugs compared to state-of-the-art fuzzers. This work highlights the\npotential of combining LLM reasoning with semantic-aware feedback to accelerate\nand deepen vulnerability discovery."}
{"id": "2511.04021", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.04021", "abs": "https://arxiv.org/abs/2511.04021", "authors": ["Sergio Demian Lerner", "Ariel Autoransky"], "title": "OTS-PC: OTS-based Payment Channels for the Lightning Network", "comment": null, "summary": "We present a new type of bidirectional payment channel based on One-Time\nSignatures on state sequence numbers. This new construction is simpler than the\nPoon-Dryja construction, but provides a number of benefits such as $O(1)$\nstorage per channel, minimal information leakage, and compatibility with\nLightning Network routing."}
{"id": "2511.04114", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04114", "abs": "https://arxiv.org/abs/2511.04114", "authors": ["Paul Badu Yakubu", "Lesther Santana", "Mohamed Rahouti", "Yufeng Xin", "Abdellah Chehri", "Mohammed Aledhari"], "title": "Automated and Explainable Denial of Service Analysis for AI-Driven Intrusion Detection Systems", "comment": "13 pages, 2 figures, 11 tables, IET Information Security", "summary": "With the increasing frequency and sophistication of Distributed Denial of\nService (DDoS) attacks, it has become critical to develop more efficient and\ninterpretable detection methods. Traditional detection systems often struggle\nwith scalability and transparency, hindering real-time response and\nunderstanding of attack vectors. This paper presents an automated framework for\ndetecting and interpreting DDoS attacks using machine learning (ML). The\nproposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to\nautomate the selection and optimization of ML models and features, reducing the\nneed for manual experimentation. SHapley Additive exPlanations (SHAP) is\nincorporated to enhance model interpretability, providing detailed insights\ninto the contribution of individual features to the detection process. By\ncombining TPOT's automated pipeline selection with SHAP interpretability, this\napproach improves the accuracy and transparency of DDoS detection. Experimental\nresults demonstrate that key features such as mean backward packet length and\nminimum forward packet header length are critical in detecting DDoS attacks,\noffering a scalable and explainable cybersecurity solution."}
{"id": "2511.04215", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04215", "abs": "https://arxiv.org/abs/2511.04215", "authors": ["Hongwei Yao", "Yun Xia", "Shuo Shao", "Haoran Shi", "Tong Qiao", "Cong Wang"], "title": "Black-Box Guardrail Reverse-engineering Attack", "comment": null, "summary": "Large language models (LLMs) increasingly employ guardrails to enforce\nethical, legal, and application-specific constraints on their outputs. While\neffective at mitigating harmful responses, these guardrails introduce a new\nclass of vulnerabilities by exposing observable decision patterns. In this\nwork, we present the first study of black-box LLM guardrail reverse-engineering\nattacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement\nlearning-based framework that leverages genetic algorithm-driven data\naugmentation to approximate the decision-making policy of victim guardrails. By\niteratively collecting input-output pairs, prioritizing divergence cases, and\napplying targeted mutations and crossovers, our method incrementally converges\ntoward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on\nthree widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3,\nand demonstrate that it achieves an rule matching rate exceeding 0.92 while\nrequiring less than $85 in API costs. These findings underscore the practical\nfeasibility of guardrail extraction and highlight significant security risks\nfor current LLM safety mechanisms. Our findings expose critical vulnerabilities\nin current guardrail designs and highlight the urgent need for more robust\ndefense mechanisms in LLM deployment."}
{"id": "2511.04261", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04261", "abs": "https://arxiv.org/abs/2511.04261", "authors": ["Ming Liu"], "title": "A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization", "comment": null, "summary": "The widespread deployment of high-resolution visual sensing systems, coupled\nwith the rise of foundation models, has amplified privacy risks in video-based\napplications. Differentially private pixelization offers mathematically\nguaranteed protection for visual data through grid-based noise addition, but\nchallenges remain in preserving task-relevant fidelity, achieving scalability,\nand enabling efficient real-time deployment. To address this, we propose a\nnovel parallel, region-adaptive pixelization framework that combines the\ntheoretical rigor of differential privacy with practical efficiency. Our method\nadaptively adjusts grid sizes and noise scales based on regional complexity,\nleveraging GPU parallelism to achieve significant runtime acceleration compared\nto the classical baseline. A lightweight storage scheme is introduced by\nretaining only essential noisy statistics, significantly reducing space\noverhead. Formal privacy analysis is provided under the Laplace mechanism and\nparallel composition theorem. Extensive experiments on the PETS, Venice-2, and\nPPM-100 datasets demonstrate favorable privacy-utility trade-offs and\nsignificant runtime/storage reductions. A face re-identification attack\nexperiment on CelebA further confirms the method's effectiveness in preventing\nidentity inference. This validates its suitability for real-time\nprivacy-critical applications such as elderly care, smart home monitoring,\ndriver behavior analysis, and crowd behavior monitoring."}
{"id": "2511.04409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04409", "abs": "https://arxiv.org/abs/2511.04409", "authors": ["Giacomo Zonneveld", "Giulia Rafaiani", "Massimo Battaglioni", "Marco Baldi"], "title": "Data Certification Strategies for Blockchain-based Traceability Systems", "comment": null, "summary": "The use of blockchains for data certification and traceability is now well\nestablished in both the literature and practical applications. However, while\nblockchain-based certification of individual data is clear and straightforward,\nthe use of blockchain to certify large amounts of data produced on a nearly\ncontinuous basis still poses some challenges. In such a case, in fact, it is\nfirst necessary to collect the data in an off-chain buffer, and then to\norganize it, e.g., via Merkle trees, in order to keep the size and quantity of\ncertification data to be written to the blockchain small. In this paper, we\nconsider a typical system for blockchain-based traceability of a production\nprocess, and propose and comparatively analyze some strategies for certifying\nthe data of such a process on blockchain, while maintaining the possibility of\nverifying their certification in a decentralized way."}
{"id": "2511.04440", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04440", "abs": "https://arxiv.org/abs/2511.04440", "authors": ["Pedro Pereira", "José Gouveia", "João Vitorino", "Eva Maia", "Isabel Praça"], "title": "Adversarially Robust and Interpretable Magecart Malware Detection", "comment": "5 pages, 2 figures", "summary": "Magecart skimming attacks have emerged as a significant threat to client-side\nsecurity and user trust in online payment systems. This paper addresses the\nchallenge of achieving robust and explainable detection of Magecart attacks\nthrough a comparative study of various Machine Learning (ML) models with a\nreal-world dataset. Tree-based, linear, and kernel-based models were applied,\nfurther enhanced through hyperparameter tuning and feature selection, to\ndistinguish between benign and malicious scripts. Such models are supported by\na Behavior Deterministic Finite Automaton (DFA) which captures structural\nbehavior patterns in scripts, helping to analyze and classify client-side\nscript execution logs. To ensure robustness against adversarial evasion\nattacks, the ML models were adversarially trained and evaluated using attacks\nfrom the Adversarial Robustness Toolbox and the Adaptative Perturbation Pattern\nMethod. In addition, concise explanations of ML model decisions are provided,\nsupporting transparency and user trust. Experimental validation demonstrated\nhigh detection performance and interpretable reasoning, demonstrating that\ntraditional ML models can be effective in real-world web security contexts."}
{"id": "2511.04472", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04472", "abs": "https://arxiv.org/abs/2511.04472", "authors": ["Evgenios Gkritsis", "Constantinos Patsakis", "George Stergiopoulos"], "title": "Exploiting Data Structures for Bypassing and Crashing Anti-Malware Solutions via Telemetry Complexity Attacks", "comment": null, "summary": "Anti-malware systems rely on sandboxes, hooks, and telemetry pipelines,\nincluding collection agents, serializers, and database backends, to monitor\nprogram and system behavior. We show that these data-handling components\nconstitute an exploitable attack surface that can lead to denial-of-analysis\n(DoA) states without disabling sensors or requiring elevated privileges. As a\nresult, we present \\textit{Telemetry Complexity Attacks} (TCAs), a new class of\nvulnerabilities that exploit fundamental mismatches between unbounded\ncollection mechanisms and bounded processing capabilities. Our method\nrecursively spawns child processes to generate specially crafted, deeply\nnested, and oversized telemetry that stresses serialization and storage\nboundaries, as well as visualization layers, for example, JSON/BSON depth and\nsize limits. Depending on the product, this leads to truncated or missing\nbehavioral reports, rejected database inserts, serializer recursion and size\nerrors, and unresponsive dashboards. In all of these cases, malicious activity\nis normally executed; however, depending on the examined solution, it is not\nrecorded and/or not presented to the analysts. Therefore, instead of evading\nsensors, we break the pipeline that stores the data captured by the sensors.\n  We evaluate our technique against twelve commercial and open-source malware\nanalysis platforms and endpoint detection and response (EDR) solutions. Seven\nproducts fail in different stages of the telemetry pipeline; two vendors\nassigned CVE identifiers (CVE-2025-61301 and CVE-2025-61303), and others issued\npatches or configuration changes. We discuss root causes and propose mitigation\nstrategies to prevent DoA attacks triggered by adversarial telemetry."}
{"id": "2511.04508", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04508", "abs": "https://arxiv.org/abs/2511.04508", "authors": ["Raunak Somani", "Aswani Kumar Cherukuri"], "title": "Large Language Models for Cyber Security", "comment": null, "summary": "This paper studies the integration off Large Language Models into\ncybersecurity tools and protocols. The main issue discussed in this paper is\nhow traditional rule-based and signature based security systems are not enough\nto deal with modern AI powered cyber threats. Cybersecurity industry is\nchanging as threats are becoming more dangerous and adaptive in nature by\nlevering the features provided by AI tools. By integrating LLMs into these\ntools and protocols, make the systems scalable, context-aware and intelligent.\nThus helping it to mitigate these evolving cyber threats. The paper studies the\narchitecture and functioning of LLMs, its integration into Encrypted prompts to\nprevent prompt injection attacks. It also studies the integration of LLMs into\ncybersecurity tools using a four layered architecture. At last, the paper has\ntried to explain various ways of integration LLMs into traditional Intrusion\nDetection System and enhancing its original abilities in various dimensions.\nThe key findings of this paper has been (i)Encrypted Prompt with LLM is an\neffective way to mitigate prompt injection attacks, (ii) LLM enhanced cyber\nsecurity tools are more accurate, scalable and adaptable to new threats as\ncompared to traditional models, (iii) The decoupled model approach for LLM\nintegration into IDS is the best way as it is the most accurate way."}
{"id": "2511.04550", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04550", "abs": "https://arxiv.org/abs/2511.04550", "authors": ["Dhruv Deepak Agarwal", "Aswani Kumar Cherukuri"], "title": "Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments", "comment": null, "summary": "The growth of cloud computing has revolutionized data processing and storage\ncapacities to another levels of scalability and flexibility. But in the\nprocess, it has created a huge challenge of security, especially in terms of\nsafeguarding sensitive data. Classical security practices, including encryption\nat rest and during transit, fail to protect data in use and expose it to\nvarious possible breaches. In response to this problem , Confidential Computing\nhas been a tool ,seeking to secure data in processing by usage of\nhardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's\nSoftware Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts\nwithin the processor, where data is kept confidential ,intact and secure , even\nwith malicious software or compromised operating systems. In this research, we\nhave explored the architecture and security features of TEEs like Intel SGX and\nARM TrustZone, and their effectiveness in improving cloud data security. From a\nthorough literature survey ,we have analyzed the deployment strategies,\nperformance indicators, and practical uses of these TEEs for the same purpose.\nIn addition, we have discussed the issues regarding deployment, possible\nweaknesses, scalability issues, and integration issues. Our results focuses on\nthe central position of TEEs in strengthening and advancing cloud security\ninfrastructures, pointing towards their ability to create a secure foundation\nfor Confidential Computing."}
