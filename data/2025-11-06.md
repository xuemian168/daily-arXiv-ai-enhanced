<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 16]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Quantum-Classical Hybrid Encryption Framework Based on Simulated BB84 and AES-256: Design and Experimental Evaluation](https://arxiv.org/abs/2511.02836)
*Hector E Mozo*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents the design, implementation, and evaluation of a hybrid
encryption framework that combines quantum key distribution, specifically a
simulated BB84 protocol, with AES-256 encryption. The system enables secure
file encryption by leveraging quantum principles for key generation and
classical cryptography for data protection. It introduces integrity validation
mechanisms, including HMAC verification and optional post-quantum digital
signatures, ensuring robustness even in the presence of quantum-capable
adversaries. The entire architecture is implemented in Python, with modular
components simulating quantum key exchange, encryption, and secure packaging.
Experimental results include visual testing of various attack scenarios, such
as key tampering, HMAC failure, and file corruption, demonstrating the
effectiveness and resilience of the approach. The proposed solution serves as a
practical foundation for quantum-aware cybersecurity systems.

</details>


### [2] [AI Agents with Decentralized Identifiers and Verifiable Credentials](https://arxiv.org/abs/2511.02841)
*Sandro Rodriguez Garzon,Awid Vaziry,Enis Mert Kuzu,Dennis Enrique Gehrmann,Buse Varkan,Alexander Gaballa,Axel Küpper*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: LLM-based AI agents still lack the technical means to automatically build
nuanced and differentiated trust in other agents at the beginning of an
agent-to-agent dialogue. But autonomous and interoperable trust establishing
becomes a fundamental prerequisite once agents start to operate beyond isolated
environments and engage in dialogues across individual or organizational
boundaries. A promising way to fill this gap in Agentic AI is to equip agents
with long-lived digital identities and introduce tamper-proof and flexible
identity-bound attestations of agents, provisioned by commonly trusted third
parties and designed for cross-domain verifiability. This article presents a
conceptual framework and a prototypical multi-agent system, where each agent is
endowed with a self-sovereign digital identity. It combines a unique and
ledger-anchored Decentralized Identifier (DID) of an agent with a set of
third-party issued Verifiable Credentials (VCs). This enables agents at the
start of a dialog to prove ownership of their self-controlled DIDs for
authentication purposes and to establish various cross-domain trust
relationships through the spontaneous exchange of their self-hosted DID-bound
VCs. A comprehensive evaluation of the prototypical implementation demonstrates
technical feasibility but also reveals limitations once an agent's LLM is in
sole charge to control the respective security procedures.

</details>


### [3] [Proof-of-Spiking-Neurons(PoSN): Neuromorphic Consensus for Next-Generation Blockchains](https://arxiv.org/abs/2511.02868)
*M. Z. Haider,M. U Ghouri,Tayyaba Noreen,M. Salman*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Blockchain systems face persistent challenges of scalability, latency, and
energy inefficiency. Existing consensus protocols such as Proof-of-Work (PoW)
and Proof-of-Stake (PoS) either consume excessive resources or risk
centralization. This paper proposes \textit{Proof-of-Spiking-Neurons (PoSN)}, a
neuromorphic consensus protocol inspired by spiking neural networks. PoSN
encodes transactions as spike trains, elects leaders through competitive firing
dynamics, and finalizes blocks via neural synchronization, enabling parallel
and event-driven consensus with minimal energy overhead. A hybrid system
architecture is implemented on neuromorphic platforms, supported by simulation
frameworks such as Nengo and PyNN. Experimental results show significant gains
in energy efficiency, throughput, and convergence compared to PoB and PoR. PoSN
establishes a foundation for sustainable, adaptive blockchains suitable for
IoT, edge, and large-scale distributed systems.

</details>


### [4] [Lightweight Session-Key Rekeying Framework for Secure IoT-Edge Communication](https://arxiv.org/abs/2511.02924)
*Haranath Rakshit,Rajkumar Bhandari,Subhasis Banerjee*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proliferation of Internet of Things (IoT) networks demands security
mechanisms that protect constrained devices without the computational cost of
public-key cryptography. Conventional Pre-Shared Key (PSK) encryption, while
efficient, remains vulnerable due to static key reuse, replay attacks, and the
lack of forward secrecy. This paper presents the Dynamic Session Enhanced Key
Protocol (DSEKP) - a lightweight session-key rekeying framework, a fully
symmetric extension to PSK that derives per-session AES-GCM keys using the
HMAC-based Key Derivation Function (HKDF-SHA256) and authenticates session
establishment through an HMAC proof in a single init-ack exchange. DSEKP was
implemented on an ESP32 IoT sensor node and a Raspberry Pi 5 edge server
communicating through a Mosquitto MQTT broker, and benchmarked against a static
PSK baseline over more than 6,500 encrypted packets per configuration. The
results demonstrate nearly identical throughput and reliability, with moderate
overhead - mean latency increased by 27% and payload size by 10% - while
delivering per-session forward secrecy and built-in replay protection. These
findings confirm that dynamic symmetric rekeying can substantially strengthen
IoT-Edge links with minimal computational and bandwidth cost, offering a
practical migration path from static PSK to session-aware, scalable, and
reproducible IoT security.

</details>


### [5] [PrivyWave: Privacy-Aware Wireless Sensing of Heartbeat](https://arxiv.org/abs/2511.02993)
*Yixuan Gao,Tanvir Ahmed,Zekun Chang,Thijs Roumen,Rajalakshmi Nandakumar*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wireless sensing technologies can now detect heartbeats using radio frequency
and acoustic signals, raising significant privacy concerns. Existing privacy
solutions either protect from all sensing systems indiscriminately preventing
any utility or operate post-data collection, failing to enable selective access
where authorized devices can monitor while unauthorized ones cannot. We present
a key-based physical obfuscation system, PrivyWave, that addresses this
challenge by generating controlled decoy heartbeat signals at
cryptographically-determined frequencies. Unauthorized sensors receive a
mixture of real and decoy signals that are indistinguishable without the secret
key, while authorized sensors use the key to filter out decoys and recover
accurate measurements. Our evaluation with 13 participants demonstrates
effective protection across both sensing modalities: for mmWave radar,
unauthorized sensors show 21.3 BPM mean absolute error while authorized sensors
maintain a much smaller 5.8 BPM; for acoustic sensing, unauthorized error
increases to 42.0 BPM while authorized sensors achieve 9.7 BPM. The system
operates across multiple sensing modalities without per-modality customization
and provides cryptographic obfuscation guarantees. Performance benchmarks show
robust protection across different distances (30-150 cm), orientations
(120{\deg} field of view), and diverse indoor environments, establishing
physical-layer obfuscation as a viable approach for selective privacy in
pervasive health monitoring.

</details>


### [6] [Exploratory Analysis of Cyberattack Patterns on E-Commerce Platforms Using Statistical Methods](https://arxiv.org/abs/2511.03020)
*Fatimo Adenike Adeniya*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cyberattacks on e-commerce platforms have grown in sophistication,
threatening consumer trust and operational continuity. This research presents a
hybrid analytical framework that integrates statistical modelling and machine
learning for detecting and forecasting cyberattack patterns in the e-commerce
domain. Using the Verizon Community Data Breach (VCDB) dataset, the study
applies Auto ARIMA for temporal forecasting and significance testing, including
a Mann-Whitney U test (U = 2579981.5, p = 0.0121), which confirmed that holiday
shopping events experienced significantly more severe cyberattacks than
non-holiday periods. ANOVA was also used to examine seasonal variation in
threat severity, while ensemble machine learning models (XGBoost, LightGBM, and
CatBoost) were employed for predictive classification. Results reveal recurrent
attack spikes during high-risk periods such as Black Friday and holiday
seasons, with breaches involving Personally Identifiable Information (PII)
exhibiting elevated threat indicators. Among the models, CatBoost achieved the
highest performance (accuracy = 85.29%, F1 score = 0.2254, ROC AUC = 0.8247).
The framework uniquely combines seasonal forecasting with interpretable
ensemble learning, enabling temporal risk anticipation and breach-type
classification. Ethical considerations, including responsible use of sensitive
data and bias assessment, were incorporated. Despite class imbalance and
reliance on historical data, the study provides insights for proactive
cybersecurity resource allocation and outlines directions for future real-time
threat detection research.

</details>


### [7] [Bayesian Advantage of Re-Identification Attack in the Shuffle Model](https://arxiv.org/abs/2511.03213)
*Pengcheng Su,Haibo Cheng,Ping Wang*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The shuffle model, which anonymizes data by randomly permuting user messages,
has been widely adopted in both cryptography and differential privacy. In this
work, we present the first systematic study of the Bayesian advantage in
re-identifying a user's message under the shuffle model. We begin with a basic
setting: one sample is drawn from a distribution $P$, and $n - 1$ samples are
drawn from a distribution $Q$, after which all $n$ samples are randomly
shuffled. We define $\beta_n(P, Q)$ as the success probability of a
Bayes-optimal adversary in identifying the sample from $P$, and define the
additive and multiplicative Bayesian advantages as $\mathsf{Adv}_n^{+}(P, Q) =
\beta_n(P,Q) - \frac{1}{n}$ and $\mathsf{Adv}_n^{\times}(P, Q) = n \cdot
\beta_n(P,Q)$, respectively.
  We derive exact analytical expressions and asymptotic characterizations of
$\beta_n(P, Q)$, along with evaluations in several representative scenarios.
Furthermore, we establish (nearly) tight mutual bounds between the additive
Bayesian advantage and the total variation distance.
  Finally, we extend our analysis beyond the basic setting and present, for the
first time, an upper bound on the success probability of Bayesian attacks in
shuffle differential privacy. Specifically, when the outputs of $n$ users--each
processed through an $\varepsilon$-differentially private local randomizer--are
shuffled, the probability that an attacker successfully re-identifies any
target user's message is at most $e^{\varepsilon}/n$.

</details>


### [8] [Smartphone User Fingerprinting on Wireless Traffic](https://arxiv.org/abs/2511.03229)
*Yong Huang,Zhibo Dong,Xiaoguang Yang,Dalong Zhang,Qingxian Wang,Zhihua Wang*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Due to the openness of the wireless medium, smartphone users are susceptible
to user privacy attacks, where user privacy information is inferred from
encrypted Wi-Fi wireless traffic. Existing attacks are limited to recognizing
mobile apps and their actions and cannot infer the smartphone user identity, a
fundamental part of user privacy. To overcome this limitation, we propose
U-Print, a novel attack system that can passively recognize smartphone apps,
actions, and users from over-the-air MAC-layer frames. We observe that
smartphone users usually prefer different add-on apps and in-app actions,
yielding different changing patterns in Wi-Fi traffic. U-Print first extracts
multi-level traffic features and exploits customized temporal convolutional
networks to recognize smartphone apps and actions, thus producing users'
behavior sequences. Then, it leverages the silhouette coefficient method to
determine the number of users and applies the k-means clustering to profile and
identify smartphone users. We implement U-Print using a laptop with a Kali
dual-band wireless network card and evaluate it in three real-world
environments. U-Print achieves an overall accuracy of 98.4% and an F1 score of
0.983 for user inference. Moreover, it can correctly recognize up to 96% of
apps and actions in the closed world and more than 86% in the open world.

</details>


### [9] [Death by a Thousand Prompts: Open Model Vulnerability Analysis](https://arxiv.org/abs/2511.03247)
*Amy Chang,Nicholas Conley,Harish Santhanalakshmi Ganesan,Adam Swanda*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Open-weight models provide researchers and developers with accessible
foundations for diverse downstream applications. We tested the safety and
security postures of eight open-weight large language models (LLMs) to identify
vulnerabilities that may impact subsequent fine-tuning and deployment. Using
automated adversarial testing, we measured each model's resilience against
single-turn and multi-turn prompt injection and jailbreak attacks. Our findings
reveal pervasive vulnerabilities across all tested models, with multi-turn
attacks achieving success rates between 25.86\% and 92.78\% -- representing a
$2\times$ to $10\times$ increase over single-turn baselines. These results
underscore a systemic inability of current open-weight models to maintain
safety guardrails across extended interactions. We assess that alignment
strategies and lab priorities significantly influence resilience:
capability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher
multi-turn susceptibility, whereas safety-oriented designs such as Google Gemma
3 exhibit more balanced performance.
  The analysis concludes that open-weight models, while crucial for innovation,
pose tangible operational and ethical risks when deployed without layered
security controls. These findings are intended to inform practitioners and
developers of the potential risks and the value of professional AI security
solutions to mitigate exposure. Addressing multi-turn vulnerabilities is
essential to ensure the safe, reliable, and responsible deployment of
open-weight LLMs in enterprise and public domains. We recommend adopting a
security-first design philosophy and layered protections to ensure resilient
deployments of open-weight models.

</details>


### [10] [Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs](https://arxiv.org/abs/2511.03271)
*Yize Liu,Yunyun Hou,Aina Sui*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have been widely deployed across various
applications, yet their potential security and ethical risks have raised
increasing concerns. Existing research employs red teaming evaluations,
utilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs.
However, these approaches often lack exploration of successful dialogue
trajectories within the attack space, and they tend to overlook the
considerable overhead associated with the attack process. To address these
limitations, this paper first introduces a theoretical model based on
dynamically weighted graph topology, abstracting the multi-turn attack process
as a path planning problem. Based on this framework, we propose ABC, an
enhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a
collaborative search mechanism with employed, onlooker, and scout bees. This
algorithm significantly improves the efficiency of optimal attack path search
while substantially reducing the average number of queries required. Empirical
evaluations on three open-source and two proprietary language models
demonstrate the effectiveness of our approach, achieving attack success rates
above 90\% across the board, with a peak of 98\% on GPT-3.5-Turbo, and
outperforming existing baselines. Furthermore, it achieves comparable success
with only 26 queries on average, significantly reducing red teaming overhead
and highlighting its superior efficiency.

</details>


### [11] [Two thousand years of the oracle problem. Insights from Ancient Delphi on the future of blockchain oracles](https://arxiv.org/abs/2511.03319)
*Giulio Caldarelli,Massimiliano Ornaghi*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The oracle problem refers to the inability of an agent to know if the
information coming from an oracle is authentic and unbiased. In ancient times,
philosophers and historians debated on how to evaluate, increase, and secure
the reliability of oracle predictions, particularly those from Delphi, which
pertained to matters of state. Today, we refer to data carriers for automatic
machines as oracles, but establishing a secure channel between these oracles
and the real world still represents a challenge. Despite numerous efforts, this
problem remains mostly unsolved, and the recent advent of blockchain oracles
has added a layer of complexity because of the decentralization of blockchains.
This paper conceptually connects Delphic and modern blockchain oracles,
developing a comparative framework. Leveraging blockchain oracle taxonomy,
lexical analysis is also performed on 167 Delphic queries to shed light on the
relationship between oracle answer quality and question type. The presented
framework aims first at revealing commonalities between classical and
computational oracles and then at enriching the oracle analysis within each
field. This study contributes to the computer science literature by proposing
strategies to improve the reliability of blockchain oracles based on insights
from Delphi and to classical literature by introducing a framework that can
also be applied to interpret and classify other ancient oracular mechanisms.

</details>


### [12] [LaMoS: Enabling Efficient Large Number Modular Multiplication through SRAM-based CiM Acceleration](https://arxiv.org/abs/2511.03341)
*Haomin Li,Fangxin Liu,Chenyang Guan,Zongwu Wang,Li Jiang,Haibing Guan*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Barrett's algorithm is one of the most widely used methods for performing
modular multiplication, a critical nonlinear operation in modern privacy
computing techniques such as homomorphic encryption (HE) and zero-knowledge
proofs (ZKP). Since modular multiplication dominates the processing time in
these applications, computational complexity and memory limitations
significantly impact performance. Computing-in-Memory (CiM) is a promising
approach to tackle this problem. However, existing schemes currently suffer
from two main problems: 1) Most works focus on low bit-width modular
multiplication, which is inadequate for mainstream cryptographic algorithms
such as elliptic curve cryptography (ECC) and the RSA algorithm, both of which
require high bit-width operations; 2) Recent efforts targeting large number
modular multiplication rely on inefficient in-memory logic operations,
resulting in high scaling costs for larger bit-widths and increased latency. To
address these issues, we propose LaMoS, an efficient SRAM-based CiM design for
large-number modular multiplication, offering high scalability and area
efficiency. First, we analyze the Barrett's modular multiplication method and
map the workload onto SRAM CiM macros for high bit-width cases. Additionally,
we develop an efficient CiM architecture and dataflow to optimize large-number
modular multiplication. Finally, we refine the mapping scheme for better
scalability in high bit-width scenarios using workload grouping. Experimental
results show that LaMoS achieves a $7.02\times$ speedup and reduces high
bit-width scaling costs compared to existing SRAM-based CiM designs.

</details>


### [13] [Federated Anonymous Blocklisting across Service Providers and its Application to Group Messaging](https://arxiv.org/abs/2511.03486)
*David Soler,Carlos Dafonte,Manuel Fernández-Veiga,Ana Fernández Vilas,Francisco J. Nóvoa*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Instant messaging has become one of the most used methods of communication
online, which has attracted significant attention to its underlying
cryptographic protocols and security guarantees. Techniques to increase privacy
such as End-to-End Encryption and pseudonyms have been introduced. However,
online spaces such as messaging groups still require moderation to prevent
misbehaving users from participating in them, particularly in anonymous
contexts.. In Anonymous Blocklisting (AB) schemes, users must prove during
authentication that none of their previous pseudonyms has been blocked,
preventing misbehaving users from creating new pseudonyms. In this work we
propose an alternative \textit{Federated Anonymous Blocklisting} (FAB) in which
the centralised Service Provider is replaced by small distributed Realms, each
with its own blocklist. Realms can establish trust relationships between each
other, such that when users authenticate to a realm, they must prove that they
are not banned in any of its trusted realms. We provide an implementation of
our proposed scheme; unlike existing AB constructions, the performance of ours
does not depend on the current size of the blocklist nor requires processing
new additions to the blocklist. We also demonstrate its applicability to
real-world messaging groups by integrating our FAB scheme into the Messaging
Layer Security protocol.

</details>


### [14] [Security and Privacy Management of IoT Using Quantum Computing](https://arxiv.org/abs/2511.03538)
*Jaydip Sen*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The convergence of the Internet of Things (IoT) and quantum computing is
redefining the security paradigm of interconnected digital systems. Classical
cryptographic algorithms such as RSA, Elliptic Curve Cryptography (ECC), and
Advanced Encryption Standard (AES) have long provided the foundation for
securing IoT communication. However, the emergence of quantum algorithms such
as Shor's and Grover's threatens to render these techniques vulnerable,
necessitating the development of quantum-resilient alternatives. This chapter
examines the implications of quantum computing for IoT security and explores
strategies for building cryptographically robust systems in the post-quantum
era. It presents an overview of Post-Quantum Cryptographic (PQC) families,
including lattice-based, code-based, hash-based, and multivariate approaches,
analyzing their potential for deployment in resource-constrained IoT
environments. In addition, quantum-based methods such as Quantum Key
Distribution (QKD) and Quantum Random Number Generators (QRNGs) are discussed
for their ability to enhance confidentiality and privacy through physics-based
security guarantees. The chapter also highlights issues of privacy management,
regulatory compliance, and standardization, emphasizing the need for
collaborative efforts across academia, industry, and governance. Overall, it
provides a comprehensive perspective on security IoT ecosystems against quantum
threats and ensures resilience in the next generation of intelligent networks.

</details>


### [15] [Watermarking Large Language Models in Europe: Interpreting the AI Act in Light of Technology](https://arxiv.org/abs/2511.03641)
*Thomas Souverain*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: To foster trustworthy Artificial Intelligence (AI) within the European Union,
the AI Act requires providers to mark and detect the outputs of their
general-purpose models. The Article 50 and Recital 133 call for marking methods
that are ''sufficiently reliable, interoperable, effective and robust''. Yet,
the rapidly evolving and heterogeneous landscape of watermarks for Large
Language Models (LLMs) makes it difficult to determine how these four standards
can be translated into concrete and measurable evaluations. Our paper addresses
this challenge, anchoring the normativity of European requirements in the
multiplicity of watermarking techniques. Introducing clear and distinct
concepts on LLM watermarking, our contribution is threefold. (1) Watermarking
Categorisation: We propose an accessible taxonomy of watermarking methods
according to the stage of the LLM lifecycle at which they are applied - before,
during, or after training, and during next-token distribution or sampling. (2)
Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping
each criterion with state-of-the-art evaluations on robustness and
detectability of the watermark, and of quality of the LLM. Since
interoperability remains largely untheorised in LLM watermarking research, we
propose three normative dimensions to frame its assessment. (3) Watermarking
Comparison: We compare current watermarking methods for LLMs against the
operationalised European criteria and show that no approach yet satisfies all
four standards. Encouraged by emerging empirical tests, we recommend further
research into watermarking directly embedded within the low-level architecture
of LLMs.

</details>


### [16] [Whisper Leak: a side-channel attack on Large Language Models](https://arxiv.org/abs/2511.03675)
*Geoff McDonald,Jonathan Bar Or*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) are increasingly deployed in sensitive domains
including healthcare, legal services, and confidential communications, where
privacy is paramount. This paper introduces Whisper Leak, a side-channel attack
that infers user prompt topics from encrypted LLM traffic by analyzing packet
size and timing patterns in streaming responses. Despite TLS encryption
protecting content, these metadata patterns leak sufficient information to
enable topic classification. We demonstrate the attack across 28 popular LLMs
from major providers, achieving near-perfect classification (often >98% AUPRC)
and high precision even at extreme class imbalance (10,000:1 noise-to-target
ratio). For many models, we achieve 100% precision in identifying sensitive
topics like "money laundering" while recovering 5-20% of target conversations.
This industry-wide vulnerability poses significant risks for users under
network surveillance by ISPs, governments, or local adversaries. We evaluate
three mitigation strategies - random padding, token batching, and packet
injection - finding that while each reduces attack effectiveness, none provides
complete protection. Through responsible disclosure, we have collaborated with
providers to implement initial countermeasures. Our findings underscore the
need for LLM providers to address metadata leakage as AI systems handle
increasingly sensitive information.

</details>
